<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Joren&#39;s</title>
    <link>https://jorenjoestar.github.io/post/</link>
    <description>Recent content in Posts on Joren&#39;s</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 12 Apr 2021 19:56:56 +0200</lastBuildDate>
    
	    <atom:link href="https://jorenjoestar.github.io/post/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Pixel Art Filtering</title>
      <link>https://jorenjoestar.github.io/post/pixel_art_filtering/</link>
      <pubDate>Mon, 12 Apr 2021 19:56:56 +0200</pubDate>
      
      <guid>https://jorenjoestar.github.io/post/pixel_art_filtering/</guid>
      <description>





&lt;figure&gt;

  &lt;a data-fancybox=&#34;&#34; href=&#34;pixel_art_filtering.png&#34; &gt;

&lt;img src=&#34;pixel_art_filtering.png&#34; &gt;
&lt;/a&gt;


&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;An example of non integer scaling of pixel art.&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;h1 id=&#34;overview&#34;&gt;Overview&lt;/h1&gt;
&lt;p&gt;Pixel art is living a beautiful renaissance these last years, with more and more studios embracing its visuals and more artists going back to this unique way of describing visuals in a game.&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;p&gt;One of the most annoying problem we are seeing, especially since we don&amp;rsquo;t have all the CRT TVs that &amp;lsquo;apply their filters&amp;rsquo;, is the pixel &amp;lsquo;shimmering&amp;rsquo; happening when scaling or moving a pixel art image with non-integer values.&lt;/p&gt;
&lt;p&gt;This article aims to be a light introduction to the problem and more a practical testbed to experiment with filtering. I found that just using Shadertoy was not enough, and I would like to give programmers a more advanced testbed that they can modify to improve their games!&lt;/p&gt;
&lt;h1 id=&#34;summarytldr&#34;&gt;Summary/TLDR&lt;/h1&gt;
&lt;p&gt;First of all we will state what is the problem we are trying to solve, even though enough posts already talked about that.
There is an intuition that is at the base of all the filters, so it is important to have that in mind.&lt;/p&gt;
&lt;p&gt;Then we will go through each filter I found around, with a simple explanation and link to the original article and code. Hopefully it will be easy to follow!&lt;/p&gt;
&lt;p&gt;Finally some informations about the included source code, so you can experiment with Pixel Art Filtering.&lt;/p&gt;
&lt;p&gt;Enjoy!&lt;/p&gt;
&lt;h1 id=&#34;the-problem&#34;&gt;The Problem&lt;/h1&gt;
&lt;p&gt;What we are trying to fix is to &lt;strong&gt;find the relationship between pixel on the screen and pixel of the texture, or texels, to perceptually preserve the original texture appearance&lt;/strong&gt;.&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;p&gt;One key component here is that we want to apply any kind of transform to the &lt;em&gt;sprite/mesh&lt;/em&gt; that will use this texture and still preserve the texture appearance.&lt;!-- raw HTML omitted --&gt;
Something that can be done withouth further venturing into this realm is to use both integer-only camera movement increments, and scale to only integer number. This works only for sprite based games, and it can suffice if you don&amp;rsquo;t add any zoom or rotation to the game.&lt;!-- raw HTML omitted --&gt;
Many indie games, that are beautifully 2D and sprite based, can simply do that if no zoom (thus scaling) or rotation is applied.&lt;/p&gt;
&lt;p&gt;But if you are wanting to add something more dynamic then it can become a problem!&lt;/p&gt;
&lt;h2 id=&#34;examples-samurai-showdown-and-children-of-morta&#34;&gt;Examples: Samurai Showdown and Children of Morta&lt;/h2&gt;
&lt;p&gt;Already back in the day scaling and rotation were a problem, and artifacts were visible.&lt;!-- raw HTML omitted --&gt;
I can think of Samurai Showdown games when zooming out the camera, and in the quick action of the game, despite the purposely quick zoom, you can see pixel shimmering around.&lt;/p&gt;
&lt;p&gt;A more recent example, that received a lot of attention from &lt;a href=&#34;https://hero.handmade.network/episode/chat/chat018/&#34;&gt;Handmade Hero&lt;/a&gt;, is &lt;a href=&#34;https://childrenofmorta.com/&#34;&gt;Children of Morta&lt;/a&gt; (very nice game, go and play it if you haven&amp;rsquo;t!).&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Disclaimer: it is not my intention to talk bad about the game, just to show an example that already suffered for this problem, and maybe, at the end of the article, have a testbed to try different solutions!&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;As you can see also from videos of the game, zooming out (especially done with a slow speed) show the pixel shimmering that causes the problem.&lt;/p&gt;
&lt;p&gt;For some (unknown to me) reason, some shaders use the term &amp;lsquo;Fat Pixel&amp;rsquo; to refer to this problem, and it will help you finding some solutions on Shadertoy as well!&lt;/p&gt;
&lt;h2 id=&#34;pixels-and-texels-and-fat-pixels&#34;&gt;Pixels and Texels (and Fat Pixels)&lt;/h2&gt;
&lt;p&gt;To simplify the problem, we will look at sprite based games, so no 3D rotations, but the solution can be generalized to 3D as well.&lt;/p&gt;
&lt;p&gt;I found &lt;a href=&#34;https://colececil.io/blog/2017/scaling-pixel-art-without-destroying-it/&#34;&gt;this article&lt;/a&gt; to have the easiest explanation of the problem we are trying to solve, but I will restate it so it is clear visually inside this article as well.&lt;/p&gt;
&lt;p&gt;The appearance we want to preserve is the one of a Pixel Art texture, so we want pixel of the texture, that we will call &lt;strong&gt;Texels&lt;/strong&gt; to be distinguishable from each other.&lt;!-- raw HTML omitted --&gt;
We thus need to apply some sort of filtering to the texture when rendering it on the screen.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s see a simple case: an integer scale:&lt;/p&gt;






&lt;figure&gt;

  &lt;a data-fancybox=&#34;&#34; href=&#34;pixel_art_scaling_01.png&#34; &gt;

&lt;img src=&#34;pixel_art_scaling_01.png&#34; &gt;
&lt;/a&gt;


&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;2X Scale.&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;Here is clear that the pixels will be 1 to 1 with the texels, thus maintaining the pixel art visuals. &lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: using &lt;strong&gt;bilinear&lt;/strong&gt; will add blurriness at the edges though, so normally integer scaling and translation need a &lt;strong&gt;neighbour/nearest&lt;/strong&gt; filter.&lt;/p&gt;
&lt;p&gt;And now let&amp;rsquo;s see a non integer scale with some translation applied as well:&lt;/p&gt;






&lt;figure&gt;

  &lt;a data-fancybox=&#34;&#34; href=&#34;pixel_art_scaling_02.png&#34; &gt;

&lt;img src=&#34;pixel_art_scaling_02.png&#34; &gt;
&lt;/a&gt;


&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;1.5X Scale and Translation.&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;The situation is worst. Some pixels are &lt;strong&gt;full&lt;/strong&gt; while some others are &lt;strong&gt;edges&lt;/strong&gt;. I tried to highlight the original texture (a simple quad) with grey outline and color the pixels in the fully filled pixels.&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;p&gt;We see that only 4 pixels are fully colored, the others all need some sort of filter for the edges.&lt;/p&gt;
&lt;p&gt;Finally, some scale and rotation as well:&lt;/p&gt;






&lt;figure&gt;

  &lt;a data-fancybox=&#34;&#34; href=&#34;pixel_art_scaling_03.png&#34; &gt;

&lt;img src=&#34;pixel_art_scaling_03.png&#34; &gt;
&lt;/a&gt;


&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;1.5X Scale, Translation and Rotation.&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;This is the most difficult situation. Only 3 pixels are full and everything else needs a proper edge management.&lt;/p&gt;
&lt;p&gt;It is clear (I hope!) that using only &lt;strong&gt;bilinear&lt;/strong&gt; filter is not enough: the fact that each pixel can always take up 4 samples smudges everything, and we lose exactly what we want: sharp pixel art!&lt;/p&gt;
&lt;p&gt;Same for &lt;strong&gt;neighbour/nearest&lt;/strong&gt;: on fully contained pixels-in-texels it works, but on edges it is straight wrong. This causes non-square texels to fill the image.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;We need a combination of both!&lt;/strong&gt;&lt;/p&gt;
&lt;h1 id=&#34;the-intuition&#34;&gt;The Intuition&lt;/h1&gt;
&lt;p&gt;The idea behind the filtering is simple: apply &lt;strong&gt;neighbour/nearest&lt;/strong&gt; filter on pixels that are fully inside a texel, and use &lt;strong&gt;bilinear&lt;/strong&gt; with custom weights at the edges!&lt;/p&gt;
&lt;p&gt;This is what is all about.&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;p&gt;The tricky part is to come out with some custom weights for the bilinear filter to work out, and that is why there are so many different filters.&lt;/p&gt;
&lt;p&gt;We will now see the different filters included in the testbed.
Nothing that I wrote, so I will include links to the original material and you can see the awesomeness of the authors!&lt;/p&gt;
&lt;h1 id=&#34;the-filters&#34;&gt;The Filters&lt;/h1&gt;
&lt;p&gt;Here we analyze the different filters proposed and separate their code.
All the shaders are into the &lt;strong&gt;DataDrivenRendering/data/articles/PixelArtFiltering/pixel_art_filtering.hfx&lt;/strong&gt; file.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;NOTE!&lt;/strong&gt;: textures are sampled with Bilinear filtering and Alpha Blending is enabled, so that edges can be smoother. This is very important for the final results!&lt;/p&gt;
&lt;p&gt;All the filters will give back a modified UV that will leverage the bilinear sampling.&lt;/p&gt;
&lt;h2 id=&#34;nearest&#34;&gt;Nearest&lt;/h2&gt;
&lt;p&gt;Even though is not a part of the &amp;lsquo;solution&amp;rsquo;, it is interesting to see how we can obtain manually the nearest filter coordinates, despite having enabled bilinear filtering.&lt;/p&gt;
&lt;p&gt;Taken directly from the &lt;a href=&#34;https://www.khronos.org/registry/OpenGL/specs/gl/glspec46.core.pdf&#34;&gt;OpenGL Specification&lt;/a&gt; (page 281):&lt;/p&gt;






&lt;figure&gt;

  &lt;a data-fancybox=&#34;&#34; href=&#34;opengl_nearest_formula.png&#34; &gt;

&lt;img src=&#34;opengl_nearest_formula.png&#34; &gt;
&lt;/a&gt;


&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;OpenGL nearest formula.&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;In the footer, the idea we are using is explained:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Implementations may instead round the texture layer using the nearly equivalent computation |value + 1/2|.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;We need to search the Manhattan distance from the texel center, thus using &lt;code&gt;floor(pixel) + 0.5&lt;/code&gt; works perfectly.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;vec2 uv_nearest( vec2 uv, ivec2 texture_size ) {
    vec2 pixel = uv * texture_size;
    pixel = floor(pixel) + .5;

    return pixel / texture_size;
}
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;csantos&#34;&gt;CSantos&lt;/h2&gt;
&lt;p&gt;Claudio Santos (&lt;a href=&#34;https://github.com/csantosbh&#34;&gt;github&lt;/a&gt;) in his blog already in 2014 tackled the problem, as we can see from the following blog posts:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://csantosbh.wordpress.com/2014/01/25/manual-texture-filtering-for-pixelated-games-in-webgl/&#34;&gt;manual-texture-filtering-for-pixelated-games-in-webgl&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://csantosbh.wordpress.com/2014/02/05/automatically-detecting-the-texture-filter-threshold-for-pixelated-magnifications/&#34;&gt;automatically-detecting-the-texture-filter-threshold-for-pixelated-magnifications&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;He was searching for a way to modify the UV closer to the &lt;strong&gt;texel seam&lt;/strong&gt;, and came up with his own way.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;In order to have smooth transitions between texels, this offset should be replaced by a function that increases linearly at the margin of the texel, remains constant at its “blocky” region (with a value of 0.5) and then increases to 1.0 on the opposite margin of the texel.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;He mathematically found the 2 functions to add close to the &amp;lsquo;minimum&amp;rsquo; seam (towards the 0 of the texel) and towards the &amp;lsquo;maximum&amp;rsquo; seam (towards 1):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;clamp( .5 / alpha * pixels_fract, 0, .5 )&lt;/li&gt;
&lt;li&gt;clamp( .5 / alpha * (pixels_fract - 1) + .5, 0, .5 )&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In the second blog post, he found also that using &lt;strong&gt;fwidth&lt;/strong&gt; on the texel coordinates give you a resolution independent value that can be used to have a more consistent look:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;vec2 uv_cstantos( vec2 uv, vec2 res ) {
    vec2 pixels = uv * res;

    // Updated to the final article
    vec2 alpha = 0.7 * fwidth(pixels);
    vec2 pixels_fract = fract(pixels);
    vec2 pixels_diff = clamp( .5 / alpha * pixels_fract, 0, .5 ) +
                       clamp( .5 / alpha * (pixels_fract - 1) + .5, 0, .5 );
    pixels = floor(pixels) + pixels_diff;
    return pixels / res;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;We will see in many other filters that the usage of &lt;a href=&#34;https://www.khronos.org/registry/OpenGL-Refpages/gl4/html/fwidth.xhtml&#34;&gt;fwidth&lt;/a&gt; is crucial to work with resolution independent filtering.&lt;/p&gt;
&lt;p&gt;For more informations on &lt;strong&gt;fwidth&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.khronos.org/registry/OpenGL-Refpages/gl4/html/fwidth.xhtml&#34;&gt;https://www.khronos.org/registry/OpenGL-Refpages/gl4/html/fwidth.xhtml&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://computergraphics.stackexchange.com/questions/61/what-is-fwidth-and-how-does-it-work&#34;&gt;https://computergraphics.stackexchange.com/questions/61/what-is-fwidth-and-how-does-it-work&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.ronja-tutorials.com/post/046-fwidth/&#34;&gt;https://www.ronja-tutorials.com/post/046-fwidth/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;cole-cecil&#34;&gt;Cole Cecil&lt;/h2&gt;
&lt;p&gt;In a similar way, Cole Cecil in &lt;a href=&#34;https://colececil.io/blog/2017/scaling-pixel-art-without-destroying-it/&#34;&gt;this article&lt;/a&gt; creates two different functions that define the steepness of the function that interpolation amount.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;vec2 uv_colececil( vec2 uv, ivec2 texture_size ) {
    vec2 pixel = uv * texture_size;

    vec2 locationWithinTexel = fract(pixel);
    // Calculate the inverse of texels_per_pixel so we multiply here instead of dividing.
    vec2 interpolationAmount = clamp(locationWithinTexel * locals.texels_per_pixel, 0, .5) +
                               clamp((locationWithinTexel - 1) * locals.texels_per_pixel + .5, 0, .5);

    return (floor(pixel) + interpolationAmount) / texture_size;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The &amp;lsquo;texels_per_pixel&amp;rsquo; variable is calculated on the CPU, and it is basically a ratio between the camera render target size and the screen size, including the possible zoom of it.&lt;/p&gt;
&lt;p&gt;In the original post from the author it can be found in the comment section.&lt;/p&gt;
&lt;p&gt;I write it down here as reference:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;static f32 calculate_texels_per_pixel( f32 camera_width, f32 camera_height, f32 camera_zoom, f32 screen_width, f32 screen_height ) {
    f32 texels_per_pixel = 1.f;

    const f32 camera_aspect_ratio = camera_width / camera_height;
    const f32 screen_aspect_ratio = screen_width / screen_height;

    if ( screen_aspect_ratio &amp;gt; camera_aspect_ratio ) {
        texels_per_pixel = camera_height / screen_height;
    }
    else {
        texels_per_pixel = camera_width / screen_width;
    }
    // Zoom is inverted compared to ColeCecil post, so we keep same calculation here but in the shader we multiply.
    return texels_per_pixel / camera_zoom;
}
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;rnavega&#34;&gt;RNavega&lt;/h2&gt;
&lt;p&gt;The last filter accompained by a blog post of some sort is from Rodrigo Navega, in the &lt;a href=&#34;https://love2d.org/forums/viewtopic.php?t=89442&#34;&gt;Love2D forum&lt;/a&gt; and the &lt;a href=&#34;https://github.com/RNavega/PixelArt-Antialias-Love2D/blob/master/main.lua&#34;&gt;shader code&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;After the previous filters the mindset is similar, so showing the code should be simpler. We are still calculating the weights based on the distance from the edge, the difference here is that it outputs also an alpha value to be used in conjunction with the texture alpha.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// The default size, in pixels, of the antialiasing filter. The default is 1.0 for a mathematically perfect
// antialias. But if you want, you can increase this to 1.5, 2.0, 3.0 and such to force a bigger antialias zone
// than normal, using more screen pixels.

float SMOOTH_SIZE = locals.filter_width;
float _HALF_SMOOTH = SMOOTH_SIZE / 2.0;

vec2 uv_aa_dist( vec2 uv, vec2 res, out float alpha ) {

    vec2 pixels = uv * res;

    const vec2 nearest_edge = floor( pixels + 0.5 );
    const vec2 edge_distance = (pixels - nearest_edge) * locals.camera_scale;
    const vec2 factor = clamp( edge_distance / vec2(_HALF_SMOOTH), -1.0, 1.0 );

    pixels = (nearest_edge + 0.5 * factor );

    const vec2 center_offset = abs(uv - vec2(0.5));
    vec2 alpha_distance = ((center_offset - 0.5) * res * locals.camera_scale + _HALF_SMOOTH) / SMOOTH_SIZE;
    alpha_distance = clamp( alpha_distance, 0, 1 );
    alpha = 1.0 - max(alpha_distance.x, alpha_distance.y);

    return pixels / res;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Remembering that we are using alpha blending as well, we can use this value to output a smoother edge.&lt;!-- raw HTML omitted --&gt;
Also to note that the smooth size can be driven by the filter width in the demo, to experiment with the visuals.&lt;/p&gt;
&lt;p&gt;Here the factor is calculated based on the edge distance from the center texel and clamped between -1 and 1.&lt;/p&gt;
&lt;h2 id=&#34;klems&#34;&gt;Klems&lt;/h2&gt;
&lt;p&gt;Klems decide to use a smoothstep based &lt;a href=&#34;https://www.shadertoy.com/view/MllBWf&#34;&gt;approach&lt;/a&gt; in the shader:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;vec2 uv_klems( vec2 uv, ivec2 texture_size ) {
            
    vec2 pixels = uv * texture_size + 0.5;
    
    // tweak fractional value of the texture coordinate
    vec2 fl = floor(pixels);
    vec2 fr = fract(pixels);
    vec2 aa = fwidth(pixels) * 0.75;

    fr = smoothstep( vec2(0.5) - aa, vec2(0.5) + aa, fr);
    
    return (fl + fr - 0.5) / texture_size;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;It again use &lt;strong&gt;fwidth&lt;/strong&gt; approach to calculate the factor, and use the fractional value to smoothstep between the 2 values that will be used near the edges.&lt;/p&gt;
&lt;h2 id=&#34;inigo-quilez-3&#34;&gt;Inigo Quilez (&amp;lt;3)&lt;/h2&gt;
&lt;p&gt;From the comments in the &lt;a href=&#34;https://www.shadertoy.com/view/MllBWf&#34;&gt;Klems filter&lt;/a&gt;, the incredible Inigo comes up with another filter:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;vec2 uv_iq( vec2 uv, ivec2 texture_size ) {
    vec2 pixel = uv * texture_size;

    vec2 seam = floor(pixel + 0.5);
    vec2 dudv = fwidth(pixel);
    pixel = seam + clamp( (pixel - seam) / dudv, -0.5, 0.5);
    
    return pixel / texture_size;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The variable names are quite explicit, but the idea is to again start from the seam of the texture and modify the final uv based on the distance from the seam.&lt;/p&gt;
&lt;h2 id=&#34;blocky&#34;&gt;Blocky&lt;/h2&gt;
&lt;p&gt;This is very similar to IQ filter, just using different math:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// https://www.shadertoy.com/view/ltfXWS
// samples from a linearly-interpolated texture to produce an appearance similar to
// nearest-neighbor interpolation, but with resolution-dependent antialiasing
// 
// this function&#39;s interface is exactly the same as texture&#39;s, aside from the &#39;res&#39;
// parameter, which represents the resolution of the texture &#39;tex&#39;.
// basically calculates the lengths of (a.x, b.x) and (a.y, b.y) at the same time
vec2 v2len(in vec2 a, in vec2 b) {
    return sqrt( a * a + b * b );
}

vec2 uv_blocky( in vec2 uv, in ivec2 res ) {
    vec2 pixels = uv * res; // enter texel coordinate space.
    
    vec2 seam = floor(pixels + .5); // find the nearest seam between texels.
    
    // here&#39;s where the magic happens. scale up the distance to the seam so that all
    // interpolation happens in a one-pixel-wide space.
    pixels = (pixels - seam) / v2len(dFdx(pixels), dFdy(pixels)) + seam;
    
    pixels = clamp(pixels, seam - .5, seam + .5); // clamp to the center of a texel.
    
    return pixels / res;// convert back to 0..1 coordinate space.
}
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;bgolus-anti-aliasing&#34;&gt;BGolus: Anti-Aliasing&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://twitter.com/bgolus/&#34;&gt;Ben Golus&lt;/a&gt; also wrote his own implementation &lt;a href=&#34;https://www.shadertoy.com/view/ltBfRD&#34;&gt;here&lt;/a&gt; with two variations as well!&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;vec2 uv_aa_linear( vec2 uv, vec2 res, float width ) {
    vec2 pixels = uv * res;
    
    vec2 pixels_floor = floor(pixels + 0.5);
    vec2 pixels_fract = clamp( (pixels - pixels_floor) / fwidth(pixels) / width, -0.5, 0.5);

    return (pixels_floor + pixel_fract) / res;
}

vec2 uv_aa_smoothstep( vec2 uv, vec2 res, float width ) {
    vec2 pixels = uv * res;
    
    vec2 pixels_floor = floor(pixels + 0.5);
    vec2 pixels_fract = fract(pixels + 0.5);
    vec2 pixels_aa = fwidth(pixels) * width * 0.5;
    pixels_fract = smoothstep( vec2(0.5) - pixels_aa, vec2(0.5) + pixels_aa, pixels_fract );
    
    return (pixels_floor + pixels_fract - 0.5) / res;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;They both use a width to define how big is the area covered by the &lt;em&gt;anti-aliasing&lt;/em&gt; on the edges, and in the demo it is a tweakable value (default to 1.5).&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;p&gt;The first variation it scales using &lt;strong&gt;fwidth&lt;/strong&gt; but also modifies the value with the width, giving the possibility of a more fine tuned control over the edge appearance &lt;code&gt;(pixels - pixels_floor) / fwidth(pixels) / width&lt;/code&gt;. This is a &lt;strong&gt;unique feature&lt;/strong&gt; of his filters!&lt;/p&gt;
&lt;p&gt;The second variation has both the smoothstep as a way of filtering the UV based on the distance from the center of the texel, and a fwidth tunable with the width again as value to move the sampling coordinate. Note that if width is 0, pixel_fract is 0.5, thus being the center of the texel, and in the final conversion back it is taken in consideration.&lt;/p&gt;
&lt;h2 id=&#34;fat-pixel&#34;&gt;Fat Pixel&lt;/h2&gt;
&lt;p&gt;This is the shader that was mentioned by Casey Muratori in his &lt;a href=&#34;https://hero.handmade.network/episode/chat/chat018/&#34;&gt;video&lt;/a&gt; and for me started all this research culminating in this article!
The original source code is &lt;a href=&#34;https://www.shadertoy.com/view/ltBGWc&#34;&gt;here&lt;/a&gt; but again I post the code straight away:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;vec2 uv_fat_pixel( vec2 uv, ivec2 texture_size ) {
    vec2 pixel = uv * texture_size;

    vec2 fat_pixel = floor(pixel) + 0.5;
    // subpixel aa algorithm (COMMENT OUT TO COMPARE WITH POINT SAMPLING)
    fat_pixel += 1 - clamp((1.0 - fract(pixel)) * locals.texels_per_pixel, 0, 1);
        
    return fat_pixel / texture_size;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Using the same texels_per_pixel number calculated as for the Cole Cecil shader, we basically move the UV based on the distance to the edge. &lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;p&gt;Note that texels_per_pixel if camera and scene have the same size it becomes just the &lt;strong&gt;camera zoom&lt;/strong&gt; - so we are choosing the weight from edge scaled by the zoom factor of the camera.&lt;/p&gt;
&lt;h2 id=&#34;todo-the-maister&#34;&gt;TODO: The Maister&lt;/h2&gt;
&lt;p&gt;There is a final filter that I wanted to check, but I will come at it later. I wanted to write about it briefly because there is the most mathematical approach and thus can shed some light also an all the other filters!&lt;/p&gt;
&lt;p&gt;The most mathematical approach is by &lt;a href=&#34;https://twitter.com/Themaister&#34;&gt;Hans Kristian&lt;/a&gt; in which he does an analysis of the problem from a signal theory point of view. &lt;a href=&#34;https://themaister.net/blog&#34;&gt;His blog&lt;/a&gt; is full of great posts, so go check it out!&lt;/p&gt;
&lt;p&gt;The posts that we will see are the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://themaister.net/blog/2018/08/25/pseudo-bandlimited-pixel-art-filtering-in-3d-a-mathematical-derivation/&#34;&gt;pseudo-bandlimited-pixel-art-filtering-in-3d-a-mathematical-derivation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://themaister.net/blog/2018/08/29/why-coverage-based-pixel-art-filtering-is-terrible/&#34;&gt;why-coverage-based-pixel-art-filtering-is-terrible&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;They are an in-depth signal based analysis of the problem, even though the author kindly added &lt;a href=&#34;https://github.com/Themaister/Granite/blob/master/assets/shaders/inc/bandlimited_pixel_filter.h&#34;&gt;source code as well&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I will check the shader code in the future, for now the blog post is what really gives a hand at understanding the other filters.&lt;/p&gt;
&lt;h1 id=&#34;the-testbed&#34;&gt;The Testbed&lt;/h1&gt;
&lt;p&gt;With the accompanying source code there is included also some graphics to already test the idea presented here.&lt;!-- raw HTML omitted --&gt;
I&amp;rsquo;ve used two textures, that were free to use made available by the amazing &lt;a href=&#34;https://twitter.com/ansimuz&#34;&gt;Luis Zuno&lt;/a&gt; found through his &lt;a href=&#34;https://ansimuz.itch.io/&#34;&gt;itch.io page&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;It should be pretty straightforward to modify the shaders and test your own ideas, so I hope you will come up with new filters!&lt;/p&gt;
&lt;p&gt;All the filters are in &lt;strong&gt;DataDrivenRendering/data/articles/PixelArtFiltering/pixel_art_filtering.hfx&lt;/strong&gt; file.&lt;/p&gt;
&lt;p&gt;The source is in my &lt;a href=&#34;https://github.com/JorenJoestar/DataDrivenRendering&#34;&gt;github repository&lt;/a&gt; both in data/articles/PixelArtfiltering and source/articles/PixelArtFiltering where you can find the shaders and the code. There are basically only two files (pixel_art_filtering.hfx and pixel_art_filtering_app.cpp) that you need to modify to experiment with this concepts.&lt;/p&gt;
&lt;h2 id=&#34;scene-setup&#34;&gt;Scene Setup&lt;/h2&gt;
&lt;p&gt;The scene is composed of an animated sprite and a background.&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;p&gt;There are different options to zoom in and out and translate, to test all possible scenarios.&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;ve added also a simple CRT filter to be toggled after the scene is rendered.&lt;/p&gt;
&lt;p&gt;Also, sampling is always bilinear.&lt;/p&gt;
&lt;p&gt;You can also toggle &lt;strong&gt;premultiplied alpha&lt;/strong&gt;, so you see that not having any alpha blending will result in shimmering edges, another big problem not really mentioned around.&lt;/p&gt;
&lt;h1 id=&#34;links-and-previous-work&#34;&gt;Links and Previous Work&lt;/h1&gt;
&lt;p&gt;Here I want to link all the previous posts about the subject for quick reference:&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://csantosbh.wordpress.com/2014/01/25/manual-texture-filtering-for-pixelated-games-in-webgl/&#34;&gt;https://csantosbh.wordpress.com/2014/01/25/manual-texture-filtering-for-pixelated-games-in-webgl/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://csantosbh.wordpress.com/2014/02/05/automatically-detecting-the-texture-filter-threshold-for-pixelated-magnifications/&#34;&gt;https://csantosbh.wordpress.com/2014/02/05/automatically-detecting-the-texture-filter-threshold-for-pixelated-magnifications/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://colececil.io/blog/2017/scaling-pixel-art-without-destroying-it/&#34;&gt;https://colececil.io/blog/2017/scaling-pixel-art-without-destroying-it/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://themaister.net/blog/2018/08/25/pseudo-bandlimited-pixel-art-filtering-in-3d-a-mathematical-derivation/&#34;&gt;https://themaister.net/blog/2018/08/25/pseudo-bandlimited-pixel-art-filtering-in-3d-a-mathematical-derivation/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://love2d.org/forums/viewtopic.php?t=89442&#34;&gt;https://love2d.org/forums/viewtopic.php?t=89442&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/RNavega/PixelArt-Antialias-Love2D/blob/master/main.lua&#34;&gt;https://github.com/RNavega/PixelArt-Antialias-Love2D/blob/master/main.lua&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Also &lt;a href=&#34;https://www.shadertoy.com/&#34;&gt;ShaderToy&lt;/a&gt; is a source of many other filters included in the demo.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.shadertoy.com/view/MllBWf&#34;&gt;https://www.shadertoy.com/view/MllBWf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.shadertoy.com/view/ltfXWS&#34;&gt;https://www.shadertoy.com/view/ltfXWS&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.shadertoy.com/view/4dlXzB&#34;&gt;https://www.shadertoy.com/view/4dlXzB&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.shadertoy.com/view/ltcGDX&#34;&gt;https://www.shadertoy.com/view/ltcGDX&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.shadertoy.com/view/ltBGWc&#34;&gt;https://www.shadertoy.com/view/ltBGWc&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.shadertoy.com/view/ltBfRD&#34;&gt;https://www.shadertoy.com/view/ltBfRD&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;conclusions&#34;&gt;Conclusions&lt;/h1&gt;
&lt;p&gt;We saw different &lt;strong&gt;sampling filters&lt;/strong&gt; that resulted in different ways of leveraging the &lt;em&gt;bilinear filtering&lt;/em&gt; with some custom coordinates to obtain a mix of sharpness for inside pixels and smoothness on the edges.&lt;/p&gt;
&lt;p&gt;We also have now a easy to modify testbed to try different ideas and hopefully make your pixels (and your eyes) happy!&lt;/p&gt;
&lt;p&gt;As always, please comment, modify, improve, share the article and the code!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Rendering Astronomic Stars</title>
      <link>https://jorenjoestar.github.io/post/realistic_stars/realistic_stars/</link>
      <pubDate>Sat, 26 Dec 2020 11:54:39 +0100</pubDate>
      
      <guid>https://jorenjoestar.github.io/post/realistic_stars/realistic_stars/</guid>
      <description>&lt;h1 id=&#34;overview&#34;&gt;Overview&lt;/h1&gt;
&lt;p&gt;Since growing up I&amp;rsquo;ve always been fascinated by stars, and being exposed to anime like Sainy Seiya and Hokuto No Ken just fueled the passion.
My 4th year of high-school had a full year course on &amp;lsquo;geographical astronomy&amp;rsquo; - an in depth look at our planet and the stars from a scientific perspective.
Many years has passed (20+!) and I&amp;rsquo;ve never dwelved into these kind of topic.&lt;/p&gt;
&lt;p&gt;Then few years ago, while researching for rendering un Just Cause 4 I stumbled upon a couple of papers about realistic rendering of stars.
I did a working prototype in Unity but did not understood many things, and I had no time to look back into this.&lt;/p&gt;
&lt;p&gt;Then came Christmas time, with lockdown and such I finally had an excuse to dwelve deeper into this topic.
Also I am searching for little rendering demos I can use to test and cleanup my libraries to write code.&lt;/p&gt;
&lt;p&gt;A &lt;em&gt;HUGE&lt;/em&gt; shout to the author of &lt;a href=&#34;https://github.com/cgcostume/osghimmel&#34;&gt;SGHimmel&lt;/a&gt; - code that contains a much deeper and precise implementation.&lt;/p&gt;
&lt;p&gt;Mine is more a starting point and a small subset of what is needed to render realistic stars - the ones &lt;em&gt;visible with naked eye&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;There is a seminal paper that put all these informations in one place:&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://graphics.stanford.edu/~henrik/papers/nightsky/nightsky.pdf&#34;&gt;A Physically Based Night Sky Model&lt;/a&gt;.&lt;!-- raw HTML omitted --&gt;
This paper contains all the stars rendering informations (and much more, like Moon and Sun) and it is the real deal.&lt;/p&gt;
&lt;p&gt;A second paper also expanded that and gave us the SGHimmel code:&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.researchgate.net/publication/287031803_Single-pass_Rendering_of_Day_and_Night_Sky_Phenomena&#34;&gt;Single Pass Rendering of Day and Night Sky Phenomena&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;My only contribution is to distill the very complex informations in a few files of code, and maybe help someone else to start looking into this amazing world.&lt;/p&gt;
&lt;h1 id=&#34;astronomy&#34;&gt;Astronomy&lt;/h1&gt;
&lt;p&gt;Where do we start ?&lt;/p&gt;
&lt;h2 id=&#34;catalogs&#34;&gt;Catalogs&lt;/h2&gt;
&lt;p&gt;We need DATA.
In Astronomy, and for stars, there are the so called &amp;lsquo;&lt;em&gt;catalogs&lt;/em&gt;&amp;rsquo; - a collection of data relative to stars normally collected by hand (!) by astronomers from different sources.&lt;!-- raw HTML omitted --&gt;
A list of catalogs can be found here:&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://heasarc.gsfc.nasa.gov/docs/cgro/db-perl/W3Browse/w3table.pl?MissionHelp=star_catalog&#34;&gt;https://heasarc.gsfc.nasa.gov/docs/cgro/db-perl/W3Browse/w3table.pl?MissionHelp=star_catalog&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&amp;hellip; catalogs types and story ?&lt;/p&gt;
&lt;p&gt;Amongst all the catalogs the most beginner friendly to use is the &lt;a href=&#34;http://tdc-www.harvard.edu/catalogs/bsc5.html&#34;&gt;&lt;em&gt;Yale Bright Stars Catalog&lt;/em&gt;&lt;/a&gt;.&lt;!-- raw HTML omitted --&gt;
This catalog was created around 1908 and different was updated until &amp;lsquo;recently&amp;rsquo;.&lt;!-- raw HTML omitted --&gt;
It contains all the stars that are visible with naked eye from Earth - 9100 objects - normally visible if the have a visual magnitude of more than 6.5.&lt;!-- raw HTML omitted --&gt;
The online version is both a binary based one and a text based one.&lt;!-- raw HTML omitted --&gt;
I decided to use the binary version, but possibly it will change in the future.&lt;/p&gt;
&lt;h2 id=&#34;star-entry&#34;&gt;Star Entry&lt;/h2&gt;
&lt;p&gt;Now that we chose a catalog let&amp;rsquo;s see what we really need to properly place and visualize a star.&lt;!-- raw HTML omitted --&gt;
Using the binary version shows the minimum necessary data that can be used, and in this case following &lt;a href=&#34;http://tdc-www.harvard.edu/catalogs/bsc5.entry.html&#34;&gt;this&lt;/a&gt; link:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Right Ascension and Declination&lt;/li&gt;
&lt;li&gt;Spectral Type&lt;/li&gt;
&lt;li&gt;Visual Magnitude&lt;/li&gt;
&lt;li&gt;Proper Motion&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Before dwelving into this, an &lt;em&gt;incredibly important&lt;/em&gt; thing to consider is &lt;em&gt;WHEN&lt;/em&gt; the catalog is compiled - more specifically what &lt;em&gt;time reference point&lt;/em&gt; is used in the catalog.&lt;/p&gt;
&lt;h3 id=&#34;epoch-julian-dates-and-j2000&#34;&gt;Epoch, Julian Dates and J2000&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;TLDR&lt;/strong&gt;: convert from Gregorian Calendar to Julian Date to properly rotate stars.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Long explanation:&lt;/strong&gt;
Between different astronomers different &lt;em&gt;epochs&lt;/em&gt; were used in different calendars, thus referencing different catalogs had problems in understanding which reference system was used.&lt;!-- raw HTML omitted --&gt;
As some of you may know, depending on your culture you could use different calendars as well!&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;p&gt;For astronomy related things, a common &amp;lsquo;time reference point&amp;rsquo; was decided by the &lt;a href=&#34;https://www.iau.org/&#34;&gt;International Astronomical Union&lt;/a&gt;, and this is the &lt;strong&gt;Julian Calendar&lt;/strong&gt; with the precise moment called &lt;em&gt;J2000&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Different &amp;lsquo;reference points&amp;rsquo; were used, and in 1984 the IAU switched from the J1950 to the J2000 epoch.&lt;/p&gt;
&lt;p&gt;Specifically an &lt;strong&gt;epoch&lt;/strong&gt; is a moment in time that is used as central reference point to calculate positions and motions of celestial objects.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;J2000&lt;/strong&gt; thus is the date of January 1, 2000 at 12:00 Terrestrial Time in the Gregorian Calendar at the Greenwich meridian, and all the positional data in the catalog is relative to this moment.&lt;/p&gt;
&lt;p&gt;There are plenty of conversions between Gregorian Calendar and Julian Calendar, and in the code provided there will be some links also to some pages with the math involved.&lt;/p&gt;
&lt;h3 id=&#34;right-ascension-and-declination&#34;&gt;Right Ascension and Declination&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;TLDR&lt;/strong&gt;: stars &amp;lsquo;latitude and longitude&amp;rsquo; to place them.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Long explanation:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Now that we have a reference time, we can finally use the Right Ascension and Declination data.&lt;/p&gt;
&lt;p&gt;A very simple explanation of Right Ascension and Declination is that they are the celestial equivalent to latitude and longitude on earth, but they reference the &lt;strong&gt;celestial sphere&lt;/strong&gt; - an ideal sphere centered in the Earth center and &lt;strong&gt;not&lt;/strong&gt; following the Earth axis inclination.&lt;/p&gt;






&lt;figure&gt;

  &lt;a data-fancybox=&#34;&#34; href=&#34;https://upload.wikimedia.org/wikipedia/commons/9/95/JostBurgi-MechanisedCelestialGlobe1594.jpg&#34; &gt;

&lt;img src=&#34;https://upload.wikimedia.org/wikipedia/commons/9/95/JostBurgi-MechanisedCelestialGlobe1594.jpg&#34; &gt;
&lt;/a&gt;


&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;Jost Burgi Celestial Sphere. Source: Wikipedia.&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;Both Right Ascension and Declination are relative to the &lt;strong&gt;Celestial Equator&lt;/strong&gt; - an ideal equator that has a different inclination than the natural Earth equator (due to its tilt axis).&lt;!-- raw HTML omitted --&gt;
Right Ascension thus is the eastward angular distance relative to the Celestial Equator, expressed in hours, minutes and seconds.&lt;!-- raw HTML omitted --&gt;
Declination instead is the north/south angle relative to the Celestial Equator, expressed in degrees (in the range -90, 90).&lt;/p&gt;
&lt;p&gt;All this combined defines the &lt;strong&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Equatorial_coordinate_system&#34;&gt;Equatorial Coordinate System&lt;/a&gt;&lt;/strong&gt;, used to locate celestial objects.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Right Ascension and Declination relative to J2000&lt;/strong&gt; are then the celestial &amp;lsquo;latitude and longitude&amp;rsquo; to locate a celestial object around the Earth, relative to a reference system that is not tilted with the axis but more &amp;lsquo;absolute&amp;rsquo;.&lt;/p&gt;
&lt;h3 id=&#34;spectral-type&#34;&gt;Spectral Type&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;TLDR&lt;/strong&gt;: convert from Spectral Type to RGB color.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Long explanation:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;To help organize stars they needed to categorize them based on some parameters.&lt;!-- raw HTML omitted --&gt;
In 1817 already Josepth Von FraunHofer started analyzing the &lt;em&gt;spectrum&lt;/em&gt; of the visible stars and in the following years, but it is with the work of &lt;strong&gt;Annie Cannon&lt;/strong&gt;, that catalogued &lt;em&gt;hundreds of thousands&lt;/em&gt; of stars, that spectrum-based classification became more common.&lt;/p&gt;
&lt;p&gt;There are two main spectral classifications, the &lt;a href=&#34;https://starparty.com/topics/astronomy/stars/the-morgan-keenan-system/&#34;&gt;Morgan-Keenan System&lt;/a&gt; and the &lt;a href=&#34;https://en.wikipedia.org/wiki/UBV_photometric_system&#34;&gt;UBV or Johnson-Morgan-system&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Interestingly enough the &lt;em&gt;Yale Bright Star Catalog&lt;/em&gt; contains the &lt;em&gt;MK Spectral Type&lt;/em&gt; in the binary format, and the &lt;em&gt;BV&lt;/em&gt; index in the text format.&lt;/p&gt;
&lt;p&gt;I ended up creating a list of MK types to colors in the code, starting from these:&lt;/p&gt;
&lt;p&gt;Spectral Type to temperature
&lt;a href=&#34;https://www.handprint.com/ASTRO/specclass.html&#34;&gt;https://www.handprint.com/ASTRO/specclass.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Temperature to color
&lt;a href=&#34;http://www.vendian.org/mncharity/dir3/blackbody/UnstableURLs/bbr_color.html&#34;&gt;http://www.vendian.org/mncharity/dir3/blackbody/UnstableURLs/bbr_color.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;As an alternative I could have parse the text version and using the BV indices, possibly I&amp;rsquo;ll do that and cross reference colors to see if the are exact.&lt;/p&gt;
&lt;p&gt;There is also this incredibly useful post about all this:&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://stackoverflow.com/questions/21977786/star-b-v-color-index-to-apparent-rgb-color&#34;&gt;https://stackoverflow.com/questions/21977786/star-b-v-color-index-to-apparent-rgb-color&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The key information here&lt;/strong&gt; is that once we read the &lt;em&gt;Spectral Type&lt;/em&gt; of each star, we have a table that converts it to an RGB value.&lt;/p&gt;
&lt;h3 id=&#34;visual-magnitude&#34;&gt;Visual Magnitude&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;TLDR:&lt;/strong&gt; magnitude shows how visible is a star.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Long explanation:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;This is the part in which I still don&amp;rsquo;t feel confident about what is really happening, but I&amp;rsquo;ll try to give the better explanation of what I understood.&lt;!-- raw HTML omitted --&gt;
It will possibly be subject to changes in the code!&lt;/p&gt;
&lt;p&gt;In the seminal paper a correlation between the &lt;em&gt;Magnitude&lt;/em&gt; and the &lt;em&gt;Glaring&lt;/em&gt; is done, with the Glaring coming from another very important paper on visual perception, defining Glare as the sum of the flare and bloom optical phenomena happening to our eyes &lt;a href=&#34;https://www.researchgate.net/publication/2593999_Physically-Based_Glare_Effects_for_Digital_Images&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;We are trying to create a correlation between the Magnitude of a star and how big is seen in the screen, and this is a pretty accurate description of what happens to us when seeing &amp;lsquo;brighter stars&amp;rsquo;.&lt;/p&gt;
&lt;p&gt;We have 2 ways to achieve this:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Output a pixel color intensity that works with tonemapping and engages the bloom&lt;/li&gt;
&lt;li&gt;Make the star bigger based on magnitude.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The second approach is the one used here, but I would like to experiment also with the other option.&lt;/p&gt;
&lt;p&gt;In the second paper (Single Pass &amp;hellip;) there are some equations that correlate pixel intensity with visual magnitude AND &amp;lsquo;how big&amp;rsquo; the stars appear to the same magnitude.&lt;/p&gt;
&lt;p&gt;We will see more in detail in the code how to use those.&lt;/p&gt;
&lt;h3 id=&#34;proper-motion&#34;&gt;Proper Motion&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;TLDR:&lt;/strong&gt; adjust right ascension and declination with this per-year changes.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Long explanation:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The final data relative to the stars is the proper motion.&lt;!-- raw HTML omitted --&gt;
Proper motion can be simply defined as the yearly move of a star in Equatorial Coordinate System.&lt;!-- raw HTML omitted --&gt;
Most of the stars visible with naked eye are so distant that their motion is not as diverse as the J2000 position specified, but few (the closest ones) need a more precise calculation.&lt;/p&gt;
&lt;p&gt;Taking in account &lt;em&gt;proper motion&lt;/em&gt; will give the most precise star positioning of all.&lt;/p&gt;
&lt;h1 id=&#34;coding&#34;&gt;Coding&lt;/h1&gt;
&lt;p&gt;After this lenghty introduction in astronomy we can finally see the code!&lt;!-- raw HTML omitted --&gt;
The repository is still &lt;a href=&#34;https://github.com/JorenJoestar/DataDrivenRendering&#34;&gt;DataDrivenRendering&lt;/a&gt; - but all the code and data is contained under the StarApplication folders in source/articles and data/articles!&lt;!-- raw HTML omitted --&gt;
I am working on improving my framework so I can experiment faster and faster.&lt;/p&gt;
&lt;p&gt;As already wrote before, one of the biggest problem was retrieving the data and understanding its meaning!&lt;/p&gt;
&lt;h2 id=&#34;project-structure&#34;&gt;Project Structure&lt;/h2&gt;
&lt;p&gt;Data: &lt;a href=&#34;https://github.com/JorenJoestar/DataDrivenRendering/tree/master/data/articles/StarRendering&#34;&gt;https://github.com/JorenJoestar/DataDrivenRendering/tree/master/data/articles/StarRendering&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Source: &lt;a href=&#34;https://github.com/JorenJoestar/DataDrivenRendering/tree/master/source/Articles/StarRendering&#34;&gt;https://github.com/JorenJoestar/DataDrivenRendering/tree/master/source/Articles/StarRendering&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;All the relevant code is in star_map_application.h/.cpp.&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;h2 id=&#34;star-data-parsing&#34;&gt;Star Data Parsing&lt;/h2&gt;
&lt;p&gt;We chose the &lt;strong&gt;Yale Bright Star Catalog&lt;/strong&gt;, and there are two versions here (&lt;a href=&#34;http://tdc-www.harvard.edu/software/catalogs/bsc5.html):&#34;&gt;http://tdc-www.harvard.edu/software/catalogs/bsc5.html):&lt;/a&gt; one binary and one text.&lt;!-- raw HTML omitted --&gt;
I chose to use the binary one, even though I could change idea and revise this code and article.&lt;/p&gt;
&lt;p&gt;The binary is pretty easy to parse, with a caveat: you need an alignment of 1 to correctly parse the data!&lt;!-- raw HTML omitted --&gt;
The parsing structures are just 2, one for the header and one for each star entry:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://tdc-www.harvard.edu/software/catalogs/bsc5.header.html&#34;&gt;http://tdc-www.harvard.edu/software/catalogs/bsc5.header.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://tdc-www.harvard.edu/software/catalogs/bsc5.entry.html&#34;&gt;http://tdc-www.harvard.edu/software/catalogs/bsc5.entry.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Once we parse from the file we have all our stars with &lt;em&gt;right ascension, declination and visual magnitude&lt;/em&gt; ready for us!&lt;/p&gt;
&lt;h2 id=&#34;constellation-data-parsing&#34;&gt;Constellation Data Parsing&lt;/h2&gt;
&lt;p&gt;Constellations are another set of data that needs to be relative to a specific &lt;strong&gt;catalog&lt;/strong&gt;.&lt;!-- raw HTML omitted --&gt;
I found this website that presents the constellation lines in a text format:&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://cdsarc.u-strasbg.fr/viz-bin/Cat?VI/49&#34;&gt;http://cdsarc.u-strasbg.fr/viz-bin/Cat?VI/49&lt;/a&gt;&lt;!-- raw HTML omitted --&gt;
&lt;a href=&#34;https://github.com/hemel-waarnemen-com/Constellation-lines&#34;&gt;https://github.com/hemel-waarnemen-com/Constellation-lines&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The problem is that the file contains the constellations as a series of line (line strips) that you need to continuously draw &lt;em&gt;like a pen not leaving the paper&lt;/em&gt;.&lt;!-- raw HTML omitted --&gt;
I decided to convert this in a list of segments, so I have to parse the text file and make the conversion.&lt;/p&gt;
&lt;p&gt;There are a couple of caveats here:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Constellations can be present more than once, the they have 2 non contiguous lines.&lt;/li&gt;
&lt;li&gt;Parsing is done 2 times, first to calculate offsets of final segments (especially for the constellations with more lines), second to actually parse the data.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This is also an interesting use of the hydra_lexer - backbone of the HFX language.&lt;!-- raw HTML omitted --&gt;
In this demo it is already used but in following ones I&amp;rsquo;ll update it more and more.&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    // Read constellation file
    char* constellation_data = hydra::file_read_into_memory( &amp;quot;..\\data\\articles\\StarRendering\\constellations_lines.txt&amp;quot;, nullptr, false, *allocator );
    // Allocate raw memory and entries for the data parsed.
    // Not elegant, but functioning.
    DataBuffer data_buffer;
    data_buffer_init( &amp;amp;data_buffer, 10000, 10000 * 4 );

    Lexer lexer;
    lexer_init( &amp;amp;lexer, constellation_data, &amp;amp;data_buffer );

    // First parse: calculate offsets and total size of indices array.
    uint32_t data_size = 0;
    bool parsing = true;

    // An example entry:
    // Ant   4 4273 4104 3871 3765
    // Hash is used as line comment.
    //
    while ( parsing ) {

        Token token;
        lexer_next_token( &amp;amp;lexer, token );

        switch ( token.type ) {

            case Token::Token_Hash:
            {
                // Skip the line
                lexer_goto_next_line( &amp;amp;lexer );

                break;
            }

            case Token::Token_Identifier:
            {
                // Ant   4 4273 4104 3871 3765
                // Read name
                char name[ 4 ];
                name[ 0 ] = toupper( token.text.text[ 0 ] );
                name[ 1 ] = toupper( token.text.text[ 1 ] );
                name[ 2 ] = toupper( token.text.text[ 2 ] );
                name[ 3 ] = 0;

                int32_t constellation_index = Constellations::get_index( &amp;amp;constellations, name );

                // Read segment count
                lexer_expect_token( &amp;amp;lexer, token, Token::Token_Number );

                uint32_t count = atoi( token.text.text );
                constellations.entries[ constellation_index ].count += count - 1; // This is segments count
                data_size += count - 1; // Segments count

                // Just advance the token to the next line.
                for ( uint32_t i = 0; i &amp;lt; count; ++i ) {
                    lexer_next_token( &amp;amp;lexer, token );
                }

                break;
            }

            case Token::Type::Token_EndOfStream:
            {
                parsing = false;
                break;
            }
        }
    }
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The most interesting part for me is seeing the parsing loop and having a lexer/tokenizer as a personal tool is a MUST!&lt;!-- raw HTML omitted --&gt;
Constellations contains a map from the name to the entry.&lt;!-- raw HTML omitted --&gt;
The second parse just reads the actual star numbers and puts them in the correct place.&lt;!-- raw HTML omitted --&gt;
Not sure it is interesting code to read here.&lt;!-- raw HTML omitted --&gt;
We now have a list of segments, and thus 2 points, for each constellation, in a contiguous block of memory.&lt;/p&gt;
&lt;p&gt;Next is&amp;hellip;&lt;/p&gt;
&lt;h2 id=&#34;temperature-to-color&#34;&gt;Temperature to Color&lt;/h2&gt;
&lt;p&gt;In the binary data we parsed from the Catalog we have the &lt;strong&gt;Spectral Type&lt;/strong&gt; of a star, a letter+number identification system to classify a star.&lt;!-- raw HTML omitted --&gt;
To properly calculate the color of a star we need to do the following:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Read the star &lt;em&gt;Spectral Type&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Convert the &lt;em&gt;Spectral Type&lt;/em&gt; to &lt;em&gt;Temperature&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Convert &lt;em&gt;Temperature&lt;/em&gt; to &lt;em&gt;RGB color&lt;/em&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Taking the data form the links in the MK part of the article, we parse the &lt;em&gt;Temperature to Color&lt;/em&gt; data from a file containing the &lt;strong&gt;black bodies color data&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Again some non-interesting parsing code, but the entries are like this:&lt;/p&gt;
&lt;p&gt;1000 K   2deg  0.6499 0.3474  2.472e+06    1.0000 0.0337 0.0000  255  51   0  #ff3300
1000 K  10deg  0.6472 0.3506  2.525e+06    1.0000 0.0401 0.0000  255  56   0  #ff3800&lt;/p&gt;
&lt;p&gt;It uses 2 different CIE specifications for colors, and we use the 10deg (the second one) of each entry.&lt;/p&gt;
&lt;p&gt;We then have a table (hand written from the links above) that links &lt;em&gt;Spectral Types&lt;/em&gt; to temperature:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;struct Range {
    uint32_t        min;
    uint32_t        max;
};

// Morgan-Keenan classification
// https://starparty.com/topics/astronomy/stars/the-morgan-keenan-system/

// Letters are for star categories.
// Numbers (0..9) are for further subdivision: 0 hottest, 9 colder.

static const uint32_t           k_max_star_types = &#39;z&#39; - &#39;a&#39;;

// Temperature ranges (in Kelvin) of the different MK spectral types.
static const Range              k_star_temperature_ranges[ k_max_star_types ] = {
    // A0-A9            B                   C                 D                 E           F               G
    { 7300, 10000 }, { 10000, 30000 }, { 2400, 3200 }, { 100000, 1000000 }, { 0, 0 }, { 6000, 7300 }, { 5300, 6000 }, { 0, 0 }, { 0, 0 },
    //  J          K                    L           M                           O           P           Q        R          S               T
    { 0, 0 }, { 3800, 5300 }, { 1300, 2100 }, { 2500, 3800 }, { 0, 0 }, { 30000, 40000 }, { 0, 0 }, { 0, 0 }, { 0, 0 }, { 2400, 3500 }, { 600, 1300 },
    // U         V          W              X            Y
    { 0, 0 }, { 0, 0 }, { 25000, 40000 }, { 0, 0 }, { 0, 600 }
};
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;We finally have all conversion from Spectral Types to Color! Ole&#39;!&lt;/p&gt;
&lt;h2 id=&#34;gregorianjulian-date-conversion&#34;&gt;Gregorian/Julian date conversion&lt;/h2&gt;
&lt;p&gt;Again some code that is mostly taking formulas from the net!&lt;!-- raw HTML omitted --&gt;
In the &lt;em&gt;Catalog&lt;/em&gt; we are using the &lt;strong&gt;Right Ascension and Declination&lt;/strong&gt; of each star is expressed relative to the Julian Date 2000.&lt;/p&gt;
&lt;p&gt;The only really interesting thing here is the fact that you need to use a double - a float will loose the difference for hour and less in the days!&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;//
// From https://en.wikipedia.org/wiki/Julian_day
//
// Gregorian Calendar Date to Julian Day Number conversion

// This is the reference Julian Date used in current astronomy.
static const int32_t j2000 = 2451545;

//
// Julian Day Number calculations.
// https://en.wikipedia.org/wiki/Julian_day
// https://aa.quae.nl/en/reken/juliaansedag.html
// https://core2.gsfc.nasa.gov/time/julian.txt
// http://www.cs.utsa.edu/~cs1063/projects/Spring2011/Project1/jdn-explanation.html
static int32_t calculate_julian_day_number( int32_t year, int32_t month, int32_t day ) {

    // Formula coming from Wikipedia.
    int32_t a = ( month - 14 ) / 12;
    int32_t jdn =  ( 1461 * (year + 4800 + a)) / 4 +
                    ( 367 * ( month - 2 - 12 *  a ) ) / 12 - 
                    ( 3 * ( ( year + 4900 + a ) / 100 ) ) / 4 +
                    day - 32075;

    // Other formula found online:
    /*int m, y, leap_days;
    a = ( ( 14 - month ) / 12 );
    m = ( month - 3 ) + ( 12 * a );
    y = year + 4800 - a;
    leap_days = ( y / 4 ) - ( y / 100 ) + ( y / 400 );
    int32_t jdn2 = day + ( ( ( 153 * m ) + 2 ) / 5 ) + ( 365 * y ) + leap_days - 32045;*/

    return jdn;
}

//
// Julian Date
//
static double calculate_julian_date( int32_t year, int32_t month, int32_t day, int32_t hour, int32_t minute, int32_t second ) {
    int32_t jdn = calculate_julian_day_number( year, month, day );

    double jd = jdn + (( hour - 12.0 ) / 24.0) + (minute / 1440.0) + (second / 86400.0);
    return jd;
}

//
// Julian centuries since January 1, 2000, used to rotate the stars.
//
static double calculate_julian_century_date( int32_t year, int32_t month, int32_t day, int32_t hour, int32_t minute, int32_t second ) {
    double jd = calculate_julian_date( year, month, day, hour, minute, second );
    return ( jd - j2000 ) / 36525.0;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;NOTE!!!&lt;/strong&gt;&lt;!-- raw HTML omitted --&gt;
The Julian date we are calculating is &lt;strong&gt;RELATIVE TO J2000&lt;/strong&gt;! Super important!&lt;/p&gt;
&lt;h2 id=&#34;star-placement&#34;&gt;Star Placement&lt;/h2&gt;
&lt;p&gt;This is the real deal.&lt;!-- raw HTML omitted --&gt;
I myself used the seminal papers on the subject that express the formulat to calculate the placement of a star in the &lt;em&gt;Celestial Sphere&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;There are two component on this:&lt;/p&gt;
&lt;h3 id=&#34;conversion-from-right-ascension-and-declination-to-equatorial-coordinates&#34;&gt;Conversion from &lt;em&gt;Right Ascension and Declination&lt;/em&gt; to Equatorial Coordinates.&lt;/h3&gt;
&lt;p&gt;The most important thing to remember here is that the &lt;strong&gt;data coming from the catalog&lt;/strong&gt; is expressed at &lt;strong&gt;J2000&lt;/strong&gt; date.&lt;!-- raw HTML omitted --&gt;
Let&amp;rsquo;s convert RA and D:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;//
// Convert to euclidean coordinates
//
static void convert_to_euclidean( float right_ascension, float declination, float radial_distance, float&amp;amp; out_x, float&amp;amp; out_y, float&amp;amp; out_z ) {
    const float cosd = cosf( declination );

    out_x = radial_distance * sinf( right_ascension ) * cosd;
    out_y = radial_distance * cosf( right_ascension ) * cosd;
    out_z = radial_distance * sinf( declination );
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This will put the star in place at the date of &lt;strong&gt;J2000&lt;/strong&gt; or January 1, 2000 at 12:00 Terrestrial Time in the Gregorian Calendar!&lt;!-- raw HTML omitted --&gt;
We need to calculate the rotation from J2000 to our current time and location.&lt;/p&gt;
&lt;h3 id=&#34;latitude-longitude-and-date-to-rotation&#34;&gt;Latitude, Longitude and Date to Rotation&lt;/h3&gt;
&lt;p&gt;This is the missing link.&lt;!-- raw HTML omitted --&gt;
As already noted above, the data coming from the Catalog is the position of the stars at &lt;strong&gt;J2000&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;There are some conversions to do from latitude and longitude, and these formulas are a mix coming from the papers I mentioned at the beginnig and simple conversion.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;float longitude_radians = glm_rad( longitude );
float latitude_radians = glm_rad( latitude );

// Calculate rotation matrix based on time, latitude and longitude
// T is time in julian century, as used in the paper.
double T = calculate_julian_century_date( year, month, day, hour, minute, second );
double local_mean_sidereal_time = 4.894961f + 230121.675315f * T + longitude_radians;

// Exploration of different rotations
versors rotation_y = glms_quatv( latitude_radians - GLM_PI_2f, { 0, 1, 0 } );
versors rotation_z = glms_quatv( -local_mean_sidereal_time, { 0, 0, 1 } );

static bool rotation_order_invert = false;

versors final_rotation = rotation_order_invert ? glms_quat_mul( rotation_y, rotation_z ) : glms_quat_mul( rotation_z, rotation_y );
if ( apply_precession ) {
    versors precession_rotation_z = glms_quatv( 0.01118f, { 0, 0, 1 } );
    versors precession = glms_quat_mul( glms_quat_mul( precession_rotation_z, glms_quatv( -0.00972, {1, 0, 0} ) ), precession_rotation_z );

    final_rotation = glms_quat_mul( final_rotation, precession );
}

mat4s star_rotation_matrix = glms_quat_mat4( final_rotation );

&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The ugliness in this code is that I had some reference system problems somewhere, so I put some variables to understand what was happening.&lt;!-- raw HTML omitted --&gt;
This is true code, you see everything :)&lt;/p&gt;
&lt;p&gt;Starting from &lt;strong&gt;latitude and longitude and date&lt;/strong&gt; we arrive at a rotation matrix to apply to the stars!&lt;/p&gt;
&lt;p&gt;Applying precession is taking in consideration the precession and nutation phenomena, again something that the brillian paper &amp;lsquo;A Physically Based Night Sky&amp;rsquo; gives some formula.&lt;!-- raw HTML omitted --&gt;
I admit not having still a deep understaning on how they arrived at that conclusion, but for sure I have a good starting point now (and hopefully you do as well!).&lt;/p&gt;
&lt;p&gt;The final position of the star is &lt;strong&gt;star_rotation_matrix * vec4(position.xyz, 1)&lt;/strong&gt;, with the position calculated as the Equatorial Coordinate at J2000, and the Star Rotation as the additional rotation taking in consideration Latitude, Longitude and date.&lt;/p&gt;
&lt;h2 id=&#34;star-rendering-hydra-for-the-win&#34;&gt;Star Rendering: Hydra for the win!&lt;/h2&gt;
&lt;p&gt;We are using the new Hydra framework - this time having a 80% working Vulkan backend.&lt;!-- raw HTML omitted --&gt;
I am working a bit on having HFX shader language extension as more and more something that I can rely to clearly prototype and explore ideas.&lt;!-- raw HTML omitted --&gt;
The HFX file that renders everything defines also almost everything, from the shader to the vertex layout to the resource types used.&lt;/p&gt;
&lt;p&gt;There is a bit of magic as well here - something I found reading the second paper, &amp;lsquo;Single Pass Rendering of Day and Night Sky Phenomena&amp;rsquo; - so the math is coming from there.
I am missing the scintillation, scattering and the daylight removal when it is day, even though for this demo is not important.&lt;!-- raw HTML omitted --&gt;
From this you can see the difference between a demo and a feature in a game: when developing this as a feature, you should consider the interaction with all the other rendering systems, the tonemapping, luts, any kind of clouds, sun and moon rendering, and such.&lt;!-- raw HTML omitted --&gt;
This is crucial!&lt;/p&gt;
&lt;p&gt;From a top down view of the rendering, we are basically drawing billboards that use the visual magnitude both for size and alpha.&lt;!-- raw HTML omitted --&gt;
Overdraw fest!!!&lt;/p&gt;
&lt;p&gt;Here is the shader used. As you can see you can specify &lt;em&gt;vertex layout and render states as well&lt;/em&gt; - something I &lt;strong&gt;LOVE&lt;/strong&gt; to see with shaders. They are an integral part of the rendering!&lt;/p&gt;
&lt;p&gt;With an HFX file now you can define totally a Vulkan Pipeline, so it is a great tool.&lt;!-- raw HTML omitted --&gt;
The code has reload of shaders, so you can experiment faster!&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;shader stars {

    layout {
        list Local {
            cbuffer ViewConstants ViewConstants;
        }

        vertex main3D {
            binding 0 32 instance
            attribute float4 Position 0 0 0
            attribute float4 ColorData 0 1 16
        }

    }

    render_states {
        state alpha {
            Cull None
            ZTest Always
            ZWrite Off
            BlendMode Alpha
        }

    }
    
    glsl to_screen {

        #pragma include &amp;quot;Platform.h&amp;quot;

        layout (std140, binding=0) uniform ViewConstants {
            mat4                    view_projection_matrix;
            mat4                    star_rotation_matrix;

            vec4                    camera_up;
            vec4                    camera_right;

            vec4                    data;       // x = min_radius, y = glare scale, z = radius scale, w = distance scale
        };

        #if defined VERTEX
        layout (location = 0) in  vec4 position;
        layout (location = 1) in  vec4 color_data;

        layout (location = 0) out vec4 vTexCoord;
        layout (location = 1) out vec3 vColor;

        // Per vertex positions and uvs of a quad
        vec3 positions[6]       = vec3[6]( vec3(-0.5,-0.5,0), vec3(0.5,-0.5,0), vec3(0.5, 0.5, 0), vec3(0.5, 0.5, 0), vec3(-0.5,0.5,0), vec3(-0.5,-0.5,0) );
        vec2 uvs[6]             = vec2[6]( vec2(0.0, 1.0),    vec2(1.0, 1.0),   vec2(1.0, 0.0), vec2(1.0, 0.0), vec2(0.0, 0.0), vec2(0.0, 1.0) );

        const float _35OVER13PI = 0.85698815511020565414014334123662;

        void main() {

            // Calculate color based on magnitude
            // Following paper &amp;quot;Single Pass Rendering of Day and Night Sky Phenomena&amp;quot;
            float m = position.w;
            float m_a = 7.0f;       // Average apparent magnitude

            float delta_m = pow(2.512, m_a - m);

        	// Magic from the papers. Investigate the WHY of this.
            float i_t = delta_m * _35OVER13PI;
            i_t *= 4e-7 / (data.x * data.x);  // resolution correlated 
            i_t = min(1.167, i_t);  // volume of smoothstep (V_T)

            // Day-Twilight-Night-Intensity Mapping (Butterworth-Filter)
            //float b = 1.0 / sqrt(1 + pow(sun.z + 1.14, 32));
            //i_t *= b;

            if ( i_t &amp;lt; 0.01 )
                return;

            float i_g = pow(2.512, m_a - (m + 0.167)) - 1;
            vec3 v_t = vec3(i_t);

            // v_k
            const float glare_scale = data.y;
            const float v_k = max(data.x, sqrt(i_g) * 2e-2 * glare_scale);

            // TODO: Scattering and Scintillation
            //v_t -= E_ext;
            vTexCoord.w = v_k / data.x;

            //
            vColor = mix( color_data.xyz, vec3( 0.66, 0.78, 1.00 ), 0.66 );
            vColor *= v_t;
            vColor = max(vec3(0.0), vColor);

            const uint vertex_index = gl_VertexID % 6;

            vTexCoord.xy = positions[vertex_index].xy * vec2(-1, 1);

            float particle_size = v_k * data.z;
            vec3 scaled_billboard = vTexCoord.x * particle_size * camera_right.xyz + vTexCoord.y * particle_size * camera_up.xyz;
    
            vec4 final_position = star_rotation_matrix * vec4(position.xyz, 1) + vec4(scaled_billboard.xyz, 1);

            gl_Position = view_projection_matrix * vec4(final_position.xyz, 1.0f);

        }
        #endif // VERTEX

        #if defined FRAGMENT

        layout (location = 0) in vec4 vTexCoord;
        layout (location = 1) in vec3 vColor;

        layout (location = 0) out vec4 outColor;

        void main() {
            float x = vTexCoord.x;
            float y = vTexCoord.y;

            float zz = (1 - x * x - y * y);
            if ( zz &amp;lt; 0.0 )
                discard;

            float k = vTexCoord.w;
            float l = length(vec2(x, y));

            const float radius_scale = data.w;
            const float glare_scale = data.y;
            float t = 1 - smoothstep(0.0, 1.0, l * k / radius_scale);
            float g = 1 - pow(l, glare_scale / 64.0);

            float intensity = max(t, g);
            outColor = vec4(intensity * vColor, intensity);
        }
        #endif // FRAGMENT
    }
    pass stars_to_screen {
        stage = final
        resources = Local
        vertex_layout = main3D
        vertex = to_screen
        fragment = to_screen
        render_states = alpha
    }
}

&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;A simplified version of the rendering code is here, but I like how this is becoming. Feedback is really appreciated :)&lt;/p&gt;
&lt;p&gt;The instance buffer contains the Euclidean positions of each star with the visual magnitude as well.&lt;!-- raw HTML omitted --&gt;
We are drawing straight into the swapchain, and I use the abstraction of &amp;lsquo;resource list&amp;rsquo; similar to the &amp;lsquo;descriptor sets&amp;rsquo; coming from Vulkan. They are just a &amp;hellip;list of resources.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;CommandBuffer* gpu_commands = update.gpu_commands;
gpu_commands-&amp;gt;clear( sort_key, 0, 0, 0, 1 );
gpu_commands-&amp;gt;clear_depth_stencil( sort_key++, 1.0f, 0 );

// Draw the stars! ////////////////////////////
gpu_commands-&amp;gt;bind_pass( sort_key++, update.gpu_device-&amp;gt;get_swapchain_pass() );
gpu_commands-&amp;gt;set_scissor( sort_key++, nullptr );	// Default framebuffer/render target sizes
gpu_commands-&amp;gt;set_viewport( sort_key++, nullptr );

gpu_commands-&amp;gt;bind_vertex_buffer( sort_key++, star_instance_buffer, 0, 0 );
gpu_commands-&amp;gt;bind_pipeline( sort_key++, star_rendering_pipeline );
gpu_commands-&amp;gt;bind_resource_list( sort_key++, &amp;amp;star_resource_list, 1, nullptr, 0 );
gpu_commands-&amp;gt;draw( sort_key++, TopologyType::Triangle, 0, 6, 0, star_count_to_render );
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;And that&amp;rsquo;s it for the rendering!
We basically draw the Celestial Sphere - we miss taking in consideration the night/day transition depending where we are, or the moon and sun.&lt;/p&gt;
&lt;h1 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;We had a dive into how to render stars using real-life astronomical data.&lt;!-- raw HTML omitted --&gt;
The real deal is finding the proper data, and trying to understand how to use it.&lt;!-- raw HTML omitted --&gt;
There are still some things that I don&amp;rsquo;t understand myself, but at least if you are curious about this topic this could be a good starting point.&lt;/p&gt;
&lt;p&gt;I hope to have time to understand things deeper soon and correct any error.&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;p&gt;Hydra library is also evolving to something more and more usable for demo, I am trying to keep the code relatively small and clear, I&amp;rsquo;ll continue with other demos about this.&lt;!-- raw HTML omitted --&gt;
I like the idea of something very concise - so you can focus only on the details you need.&lt;/p&gt;
&lt;p&gt;Next will be the Atmospheric Scattering demo from the amazing &lt;a href=&#34;https://twitter.com/SebHillaire&#34;&gt;Sebastien Hillaire&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Happy new year and may the stars shine upon your path!&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Improving Productivity in Terminals with Aliases</title>
      <link>https://jorenjoestar.github.io/post/productivity_terminal/productivity_terminal/</link>
      <pubDate>Mon, 13 Apr 2020 10:43:00 -0400</pubDate>
      
      <guid>https://jorenjoestar.github.io/post/productivity_terminal/productivity_terminal/</guid>
      <description>&lt;p&gt;After reading the &lt;a href=&#34;https://www.netlify.com/blog/2020/04/12/speed-up-productivity-with-terminal-aliases/&#34;&gt;great article by Sarah Drasner&lt;/a&gt; on productivity I wanted to share some other improvements that I use in my daily work and personal coding life.&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;p&gt;I am developing mostly rendering and other game-related code, so my OS is Windows 10.&lt;!-- raw HTML omitted --&gt;
I have a background in using Linux-only for work at the beginning of my career, so bash customization and Vim were too useful to be overlooked!&lt;/p&gt;
&lt;p&gt;For Windows I started using &lt;a href=&#34;https://cmder.net/&#34;&gt;Cmder&lt;/a&gt; few years ago, but I should check also the revamped powershell.&lt;!-- raw HTML omitted --&gt;
What I love about Cmder is that it gives you most of Unix/Linux scripts into Windows.&lt;!-- raw HTML omitted --&gt;
And with that it comes also an &amp;lsquo;alias&amp;rsquo; file, in the path &lt;em&gt;%CMDER_ROOT%\config\user_aliases.cmd&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Here are some group of aliases I use to speed up my productivity!&lt;/p&gt;
&lt;h1 id=&#34;knowing-your-aliases&#34;&gt;Knowing your aliases&lt;/h1&gt;
&lt;p&gt;First of all some commands to know and edit your aliases.&lt;/p&gt;
&lt;p&gt;I tend to write aliases with acronyms for faster typing.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ma=cat %CMDER_ROOT%\config\user_aliases.cmd

ea=vim %CMDER_ROOT%\config\user_aliases.cmd
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;M.A. stands for &lt;em&gt;My Aliases&lt;/em&gt;, while E.A. &lt;em&gt;Edit Aliases&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;This is the base - when I forget an alias I just type &lt;em&gt;ma&lt;/em&gt; and I have all my list!&lt;/p&gt;
&lt;h1 id=&#34;jumping-around&#34;&gt;Jumping around&lt;/h1&gt;
&lt;p&gt;Navigation is the first type of enhancement I recommend.&lt;!-- raw HTML omitted --&gt;
This is HUGE for me and incredibly simple:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;..=cd ..
..2=cd ../..
..3=cd ../../..
..4=cd ../../../..
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Navigate to parent folders in a much faster way!&lt;/p&gt;
&lt;p&gt;The second one is actually&amp;hellip;&lt;em&gt;jumps&lt;/em&gt; (thinking of ASM instructions)!&lt;!-- raw HTML omitted --&gt;
When I identify some folders that I access often, I add these kind of lines:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;jc= cd /D C:\Coding
jp= cd /D C:\Users\Gabriel\Documents\Visual Studio 2017\Projects
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Again aliases.
&lt;em&gt;Jump Coding&lt;/em&gt; and &lt;em&gt;Jump Projects&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Notice the argument /D to use the absolute path - needed when you have paths in other folders.&lt;/p&gt;
&lt;h1 id=&#34;file-listing&#34;&gt;File listing&lt;/h1&gt;
&lt;p&gt;Again another simple trick, and you can add more variations to your needs.&lt;!-- raw HTML omitted --&gt;
&lt;em&gt;ls&lt;/em&gt; is the &lt;em&gt;dir&lt;/em&gt; command of Linux/Unix, and is another foundation.&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ls=ls --show-control-chars -F --color $*
ll=ls --show-control-chars -F -l --color $*
lr=ls --show-control-chars -F -lrt --color $*
la=ls --show-control-chars -F -a --color $*
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Coloring is necessary to know what is a folder and what a file, something that should be enabled by default in my opinion.
Also notice the &amp;lsquo;$*&amp;rsquo; at the end - it means to append all the argument that you want to pass &lt;em&gt;after&lt;/em&gt; the alias!&lt;/p&gt;
&lt;h1 id=&#34;text-editing&#34;&gt;Text editing&lt;/h1&gt;
&lt;p&gt;I mainly use Sublime Text and occasionally VIM, so here are some &lt;em&gt;aliases&lt;/em&gt; as well:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;vi=vim $*
vimrc=vim %CMDER_ROOT%\vendor\msysgit\share\vim\vimrc

subl=&amp;quot;C:\Program Files\Sublime Text 3\sublime_text.exe&amp;quot; $*
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;With the alias &lt;em&gt;subl&lt;/em&gt; you can open any file into Sublime Text. Very handy combination Cmder + Sublime Text!&lt;/p&gt;
&lt;p&gt;Also quickly editing your &lt;em&gt;vimrc&lt;/em&gt; file is a need for VIM users.&lt;/p&gt;
&lt;h1 id=&#34;grepping&#34;&gt;Grepping&lt;/h1&gt;
&lt;p&gt;I honestly completely forgot to add the &lt;em&gt;color&lt;/em&gt; option&amp;hellip;learning through sharing. Thank you &lt;a href=&#34;https://twitter.com/sarah_edo&#34;&gt;Sarah&lt;/a&gt; :)&lt;/p&gt;
&lt;p&gt;Added the color option, these are the two variations of grep I use the most:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;grep=grep --color $*

gric=grep --color -Iir $*
gril=grep --color -Iirl $*
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;em&gt;gric&lt;/em&gt; stands for &lt;em&gt;Grep Ignore Case Ignore Binary Recursive&lt;/em&gt; - more or less.&lt;!-- raw HTML omitted --&gt;
&lt;em&gt;gril&lt;/em&gt; is like &lt;em&gt;gric&lt;/em&gt;, but just lists file instead of content per file in the search. I use it to just check files.&lt;/p&gt;
&lt;p&gt;Quickly going through the options for &lt;em&gt;grep&lt;/em&gt;:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;-I: let you ignore binary files. Speed up searching quite a bit.&lt;/li&gt;
&lt;li&gt;-i: ignore case.&lt;/li&gt;
&lt;li&gt;-r: recursively search directories.&lt;/li&gt;
&lt;li&gt;-l: only list files, not content.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I&amp;rsquo;ll show you the difference.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s search for &lt;em&gt;&amp;lsquo;blipbuffer&amp;rsquo;&lt;/em&gt; into my HydraNes/src folder:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;grep --color -Iir blipbuffer *&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;We&amp;rsquo;ll loose color in the post, but this is the result:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;src/main.cpp:            if (nes-&amp;gt;apu.blipBuffer-&amp;gt;samples_avail()) {
src/main.cpp:                int32 readSamples = nes-&amp;gt;apu.blipBuffer-&amp;gt;read_samples(sampleBuffer, kBufferSize, false);
src/main.cpp:            const int32 availableSamples = nes-&amp;gt;apu.blipBuffer-&amp;gt;samples_avail();
src/main.cpp:                const int32 readSamples = nes-&amp;gt;apu.blipBuffer-&amp;gt;read_samples( bufferAddress, kBufferSize, false );
src/Nes.cpp:    if ( !blipBuffer ) {
src/Nes.cpp:        blipBuffer = new Blip_Buffer();
src/Nes.cpp:        blipBuffer-&amp;gt;clock_rate( CpuClockRate );
src/Nes.cpp:        blipBuffer-&amp;gt;sample_rate( SampleRate );
src/Nes.cpp:        externalApu-&amp;gt;output( blipBuffer );
src/Nes.cpp:    blipBuffer-&amp;gt;clear();
src/Nes.cpp:    blipBuffer-&amp;gt;clear();
src/Nes.cpp:        blipBuffer-&amp;gt;end_frame( count );
src/Nes.cpp:    //    //blipBuffer-&amp;gt;end_frame( remainingCycles );
src/Nes.h:#include &amp;quot;BlipBuffer/blip_buf.h&amp;quot;
src/Nes.h:            Blip_Buffer*            blipBuffer = nullptr;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Instead using the list only option:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;grep --color -Iirl blipbuffer *&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Gives you this result:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;src/main.cpp
src/Nes.cpp
src/Nes.h
&lt;/code&gt;&lt;/pre&gt;&lt;h1 id=&#34;git&#34;&gt;Git&lt;/h1&gt;
&lt;p&gt;This is another big one.
Git can have very verbose commands, so aliases save a lot of typing!&lt;!-- raw HTML omitted --&gt;
Again I add generic and very specific version of commands:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;gs=git status
gl=git log --oneline --all --graph --decorate $*

ga=git add &amp;quot;$*&amp;quot;
gcm=git commit -m &amp;quot;$*&amp;quot;
grmdir=git rm -r &amp;quot;$*&amp;quot;
grmf=git rm &amp;quot;$*&amp;quot;

gpso=git push -u origin &amp;quot;$*&amp;quot;
gpsom=git push -u origin master

gplo=git pull origin &amp;quot;$*&amp;quot;
gplom=git pull origin master

gru=git remote update

gsr=git status -uno -u

gt=git stash
gts=git stash show -p
gtl=git stash list
gta=git stash apply

gsps=git subtree push --previs= $*
gspl=git subtree pull --previs= $*
gspsh=git subtree push --prefix=source/hydra hydra master
gspsl=git subtree pull --prefix=source/hydra hydra master
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;See the difference between &lt;em&gt;gpso&lt;/em&gt; and &lt;em&gt;gpsom&lt;/em&gt; - the second one just using the &lt;em&gt;master&lt;/em&gt; branch.&lt;!-- raw HTML omitted --&gt;
&lt;em&gt;gpsom&lt;/em&gt; and &lt;em&gt;gplom&lt;/em&gt; are the ones I use the most and this again saves a lot of time.&lt;/p&gt;
&lt;p&gt;Same for the &lt;em&gt;subtree&lt;/em&gt; commands, showing how I update my code using the common libraries names as &lt;em&gt;hydra&lt;/em&gt;.&lt;!-- raw HTML omitted --&gt;
In this case - and this is more a git concept - when working with subtree I use a remote alias, added with &lt;code&gt;git remote add -f &#39;name&#39; https://....git&lt;/code&gt; .&lt;/p&gt;
&lt;p&gt;&lt;em&gt;gs&lt;/em&gt; is great to see what is the status of the current repository you are in.
&lt;em&gt;gl&lt;/em&gt; logs all the commits.
&lt;em&gt;ga&lt;/em&gt; adds the files and folders you write after the command.&lt;/p&gt;
&lt;h1 id=&#34;visual-studio-compiler&#34;&gt;Visual Studio Compiler&lt;/h1&gt;
&lt;p&gt;Some different aliases I use for Visual Studio:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;vs=&amp;quot;%VS140COMNTOOLS%..\IDE\devenv.exe&amp;quot; /edit &amp;quot;$*&amp;quot;

;= Needed to find MSBuild executable.
vcvars=&amp;quot;C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\vcvarsall.bat&amp;quot;

msb=MSBuild $1 /property:Configuration=$2 /property:Platform=$3
msbd=MSBuild $1 /property:Configuration=Debug /property:Platform=x64
msbr=MSBuild $1 /property:Configuration=Release /property:Platform=x64
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Again something as &lt;em&gt;msb&lt;/em&gt; can be used to build code from a Visual Studio Solution.
&lt;em&gt;msbd&lt;/em&gt; and &lt;em&gt;msbr&lt;/em&gt; are useful shortcuts for again commonly used configurations and platforms.&lt;/p&gt;
&lt;h1 id=&#34;conclusions&#34;&gt;Conclusions&lt;/h1&gt;
&lt;p&gt;There are many ways to improve productivity - and reducing the amount of stuff you have to write, for repetitive tasks, is very powerful.
Hope this helps and again thanks to &lt;a href=&#34;https://twitter.com/sarah_edo&#34;&gt;Sarah Drasner&lt;/a&gt; for the article that sparked the idea of writing this one!&lt;/p&gt;
&lt;p&gt;If anybody wants to add more, comment, feedback please write to me!
Gabriel&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Augmenting shader languages for modern rendering APIs</title>
      <link>https://jorenjoestar.github.io/post/shader_augment_for_pipelines/shader_augment_for_pipelines/</link>
      <pubDate>Mon, 16 Mar 2020 12:11:37 -0400</pubDate>
      
      <guid>https://jorenjoestar.github.io/post/shader_augment_for_pipelines/shader_augment_for_pipelines/</guid>
      <description>&lt;h1 id=&#34;overview&#34;&gt;Overview&lt;/h1&gt;
&lt;p&gt;In the last articles we looked at progressively building tools to move rendering code towards data.&lt;!-- raw HTML omitted --&gt;
We looked on how to create a simple &lt;strong&gt;lexer&lt;/strong&gt;, a simple &lt;strong&gt;parser&lt;/strong&gt; and a &lt;strong&gt;code generator&lt;/strong&gt;.&lt;!-- raw HTML omitted --&gt;
With those we were able to create a very simple language to &lt;strong&gt;augment&lt;/strong&gt; shaders.&lt;/p&gt;
&lt;p&gt;Why that ?&lt;/p&gt;
&lt;p&gt;There are few reasons:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Shader languages misses any way of linking multiple programs&lt;/li&gt;
&lt;li&gt;Shader languages misses any way to define render states&lt;/li&gt;
&lt;li&gt;CGFX and Microsoft FX are mostly dead&lt;/li&gt;
&lt;li&gt;Ability to use ANY shader language - and just add the infrastructure&lt;/li&gt;
&lt;li&gt;Ability to generate permutations without manually creating them&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Hydra FX aims to add all the missing features and becoming just an augmentation to ANY shader language.&lt;/p&gt;
&lt;p&gt;There is also a fundamental reason for me:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Define all the rendering informations needed as soon as possible!&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;With this reason then defining everything inside an HFX file, with the possibility of overriding some properties, it is paramount.&lt;/p&gt;
&lt;p&gt;This is by far a new concept, and with the newer Graphics APIs (Vulkan and D3D12) it is becoming more and more of a need.&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;p&gt;In this article we will see how we have all those features and add the missing ones. I will try to define everything in a more API-Independent way, so it can be adapted to any engine needs.&lt;/p&gt;
&lt;h1 id=&#34;why-we-need-shader-augmentation&#34;&gt;Why we need shader augmentation&lt;/h1&gt;
&lt;p&gt;The augmentation that I have in mind is needed for different reasons, not only if you are targeting the newer APIs.&lt;!-- raw HTML omitted --&gt;
Some of the reasons are the following:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Write the NECESSARY code. Nothing more.&lt;/li&gt;
&lt;li&gt;Logically group shaders in the same file.&lt;/li&gt;
&lt;li&gt;Describe a priori all the STATIC parts of rendering.&lt;/li&gt;
&lt;li&gt;Being more data driven, improve iteration time.&lt;/li&gt;
&lt;li&gt;Being more data driven, encourage rendering experimentation.&lt;/li&gt;
&lt;li&gt;Easiness of debugging.&lt;/li&gt;
&lt;li&gt;Encourages less hardcoded data.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;write-the-necessary-code-nothing-more&#34;&gt;Write the NECESSARY code. Nothing more.&lt;/h2&gt;
&lt;p&gt;As I wrote in previous articles writing code is our biggest power and liability.&lt;!-- raw HTML omitted --&gt;
Wasting time writing useless code is like slowly typing with one finger, without any clue of a design nor knowledge of the subject.&lt;!-- raw HTML omitted --&gt;
Of course this is very personal, but any time I have to reiterate some steps (in anything in my life) for no purpose but bad-design/bad-architecture/technical-debt it really makes me feel bad.&lt;!-- raw HTML omitted --&gt;
Again, it is like playing Diablo and clicking all the time to attack, instead of knowing that you can hold the mouse button!&lt;/p&gt;
&lt;p&gt;Finally to the topic: shader augmentation means moving to data what many times is expressed in code.&lt;!-- raw HTML omitted --&gt;
We can both have a data-driven rendering, or even generate code for us, or a combination of both.&lt;!-- raw HTML omitted --&gt;
There is not right or wrong, and this will change in the future!&lt;!-- raw HTML omitted --&gt;
The best solution is the one that solves your (incredibly well described) problem.&lt;/p&gt;
&lt;p&gt;Adding render states, vertex inputs, render graph informations let a simple text file to find its space into your awesome rendering quite easily.&lt;/p&gt;
&lt;h2 id=&#34;logically-group-shaders-in-the-same-file&#34;&gt;Logically group shaders in the same file.&lt;/h2&gt;
&lt;p&gt;Having to write separated files it can be ok, but many times having everything in one file (well divided) will be easier to logically connects the shader themselves.&lt;!-- raw HTML omitted --&gt;
Sometimes you can get lost into the combination of shaders quite easily.&lt;!-- raw HTML omitted --&gt;
And anyway you NEED to define which shaders are used together since the dawn of time.&lt;/p&gt;
&lt;p&gt;So put them into the same file!&lt;/p&gt;
&lt;h2 id=&#34;describe-a-priori-all-the-static-parts-of-rendering&#34;&gt;Describe a priori all the STATIC parts of rendering.&lt;/h2&gt;
&lt;p&gt;Knowing all the static parts of rendering can lead to offline analysis and build, statistics, and all kind of things you can think of.&lt;!-- raw HTML omitted --&gt;
It also serves to really have knowledge of the combinational explosion of rendering &lt;strong&gt;before&lt;/strong&gt; it arrives in your beloved renderer!&lt;!-- raw HTML omitted --&gt;
Sometimes you can group shaders together and improve speed and usability by just analysing how &lt;strong&gt;similar&lt;/strong&gt; some shaders are.&lt;/p&gt;
&lt;h2 id=&#34;being-more-data-driven-improve-iteration-time&#34;&gt;Being more data driven, improve iteration time.&lt;/h2&gt;
&lt;p&gt;If you think of reloading assets, then a shader reload will also load all the render stage associated.&lt;!-- raw HTML omitted --&gt;
If you want to bring it a step further, adding/removing passes, changing were in the &lt;em&gt;render graph&lt;/em&gt; the shaders are used can be an incredible tool to quickly prototype, optimize, develop ideas.&lt;/p&gt;
&lt;h2 id=&#34;being-more-data-driven-encourage-rendering-experimentation&#34;&gt;Being more data driven, encourage rendering experimentation.&lt;/h2&gt;
&lt;p&gt;You can also add some non-coding tools to augment a shader with all those data.&lt;!-- raw HTML omitted --&gt;
And again, defining this in data let&amp;rsquo;s you check relationship with the rest of the renderer more easily.&lt;/p&gt;
&lt;h2 id=&#34;easiness-of-debugging&#34;&gt;Easiness of debugging.&lt;/h2&gt;
&lt;p&gt;Data-drivenness means that data is always available.&lt;!-- raw HTML omitted --&gt;
In the example I am adding here, you can see how useful can be to even have a simple ImGui debug of a HFX file.&lt;!-- raw HTML omitted --&gt;
Bring that to a realtime renderer, and you can quickly debug rendering problems without having to use external tools like Pix, RenderDoc and such. These are wonderful tools, but I always love to have a defense before arriving there.&lt;/p&gt;
&lt;p&gt;An example is to debug on someone&amp;rsquo;s machine that does not have installed those tools.&lt;/p&gt;
&lt;p&gt;Same can be applied to performances, to quickly check performances in realtime.&lt;/p&gt;
&lt;p&gt;Tooling is essential to any developer, and should be developed with the technology itself.&lt;/p&gt;
&lt;h2 id=&#34;encourages-less-hardcoded-data&#34;&gt;Encourages less hardcoded data.&lt;/h2&gt;
&lt;p&gt;Nothing wrong to hardcoding data, and many times is necessary and useful.&lt;!-- raw HTML omitted --&gt;
But the question is: &lt;strong&gt;when&lt;/strong&gt; is necessary ?&lt;/p&gt;
&lt;p&gt;Having a common data format gives you the tools (see previous point) to analyze, compared to hardcoded.&lt;/p&gt;
&lt;h1 id=&#34;shader-augmentations&#34;&gt;Shader Augmentations&lt;/h1&gt;
&lt;p&gt;We will take a HFX shader and will see all the augmentations.&lt;!-- raw HTML omitted --&gt;
This is used in the &lt;a href=&#34;https://jorenjoestar.github.io/post/data_driven_rendering_pipeline/&#34;&gt;Render Pipeline Article&lt;/a&gt; and renders the GLTF assets:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;shader PBR {

    properties {
        albedo_texture(&amp;quot;Albedo&amp;quot;, 2D) = &amp;quot;&amp;quot;
        normals_texture(&amp;quot;Normals&amp;quot;, 2D) = &amp;quot;&amp;quot;
        metal_roughness_texture(&amp;quot;MetalRoughness&amp;quot;, 2D) = &amp;quot;&amp;quot;
        emissive_texture(&amp;quot;Emissive&amp;quot;, 2D) = &amp;quot;&amp;quot;
        occlusion_texture(&amp;quot;Occlusion&amp;quot;, 2D) = &amp;quot;&amp;quot;
        scale(&amp;quot;Scale&amp;quot;, Float) = 16.0
    }

    layout {
        vertex main3D {
            binding 0 16 vertex
            attribute float3 Position 0 0 0
            attribute ubyte4n Color 0 1 12
        }

        vertex main3DPosition {
            binding 0 12 vertex
            attribute float3 Position 0 0 0
        }

        vertex main3DPositionNormal {
            binding 0 12 vertex
            binding 1 12 vertex
            binding 3 64 instance
            attribute float3 Position 0 0 0
            attribute float3 Normal 1 1 0
            attribute float4 InstanceTransform 3 3 0
            attribute float4 InstanceTransform 3 4 16
            attribute float4 InstanceTransform 3 5 32
            attribute float4 InstanceTransform 3 6 48
        }

        vertex gbuffer {
            binding 0 12 vertex
            binding 1 12 vertex
            binding 2 8 vertex
            binding 3 64 instance
            attribute float3 Position 0 0 0
            attribute float3 Normal 1 1 0
            attribute float2 UV 2 2 0
            attribute float4 InstanceTransform 3 3 0
            attribute float4 InstanceTransform 3 4 16
            attribute float4 InstanceTransform 3 5 32
            attribute float4 InstanceTransform 3 6 48
        }

        list gbuffer {
            cbuffer ViewConstants ViewConstants;

            texture2D albedo;
            texture2D normals;
            texture2D metalRoughness;
            texture2D emissive;
            texture2D occlusion;

            sampler2D linear_sampler
        }
    }

    sampler_states {
        state linear_sampler {
            Filter MinMagMipLinear
            AddressU Clamp
            AddressV Clamp
        }
    }

    render_states {
        state main {
            Cull Back
            ZTest LEqual
            ZWrite On
        }

        state linesZTest {
            Cull None
            ZTest LEqual
            ZWrite Off
            BlendMode Alpha
        }
    }

    glsl GBuffer_V {

        #pragma include &amp;quot;Platform.h&amp;quot;

        layout (location = 0) in vec3 Position;
        layout (location = 1) in vec3 Normal;
        layout (location = 2) in vec2 UV;
        layout (location = 3) in mat4 instanceTransform;

        layout (std140, binding=0) uniform ViewConstants {
            mat4                    view_projection_matrix;
            mat4                    projection_matrix;
            vec4                    resolution;
        };

        out vec3 vertexNormal;
        out vec2 uv;
        out vec3 worldPosition;

        void main()
        {
            vertexNormal = (inverse(transpose((instanceTransform))) * vec4(Normal,0)).rgb;
            uv = UV;

            vec4 world_pos = instanceTransform * vec4(Position.xyz, 1.0f);
            worldPosition = world_pos.xyz;
            gl_Position = view_projection_matrix * world_pos;
        }
    }

    glsl GBuffer_F {

        #pragma include &amp;quot;Platform.h&amp;quot;
    
        layout (location = 0) out vec4 Out_Color;
        layout (location = 1) out vec4 Out_Normals;
        layout (location = 2) out vec4 Out_Properties0;
        //layout (location = 3) out vec4 Out_WorldPosition;

        layout(binding=0) uniform sampler2D albedo;
        layout(binding=1) uniform sampler2D normals;
        layout(binding=2) uniform sampler2D metalRoughness;
        layout(binding=3) uniform sampler2D emissive;
        layout(binding=4) uniform sampler2D occlusion;

        in vec3 vertexNormal;
        in vec2 uv;
        in vec3 worldPosition;

        void generate_TB_basis( out vec3 vT, out vec3 vB, vec2 texST, vec3 base_normal, vec3 sigma_x, vec3 sigma_y, float flip_sign )
        {
            vec2 dSTdx = dFdxFine ( texST ) , dSTdy = dFdyFine ( texST ) ;
            float det = dot ( dSTdx , vec2 ( dSTdy .y ,- dSTdy .x ));
            float sign_det = det &amp;lt;0 ? -1 : 1;

            // invC0 represents ( dXds , dYds ) ; but we don ’t divide by
            // determinant ( scale by sign instead )
            vec2 invC0 = sign_det * vec2 ( dSTdy .y , - dSTdx .y );

            vT = sigma_x * invC0 .x + sigma_y * invC0 .y;
            if( abs ( det ) &amp;gt; 0.0)
                vT = normalize ( vT );

            vB = ( sign_det * flip_sign ) * cross ( base_normal , vT );
        }

        void main()
        {
            // Calculate gradient base:
            vec3 base_normal = normalize(vertexNormal);

            vec3 position_derivate_x = dFdxFine( worldPosition );
            vec3 position_derivate_y = dFdyFine( worldPosition );

            vec3 sigma_x = position_derivate_x - dot( position_derivate_x, base_normal ) * base_normal;
            vec3 sigma_y = position_derivate_y - dot( position_derivate_y, base_normal ) * base_normal;
            float flip_sign = dot ( position_derivate_y, cross ( base_normal, position_derivate_x )) &amp;lt; 0 ? -1 : 1;

            vec3 tangent, bitangent;
            generate_TB_basis( tangent, bitangent, uv.xy, base_normal, sigma_x, sigma_y, flip_sign );

            vec3 tangent_normal = texture(normals, uv.xy).xyz * 2 - 1;

            vec3 normal = tangent * tangent_normal.x + bitangent * tangent_normal.y + base_normal * tangent_normal.z;
            normal = normalize(normal);

            vec3 emissive_color = texture(emissive, uv.xy).rgb;

            //Out_Normals = vec4(vertexNormal, 1);
            //Out_Normals = vec4(tangent_normal * 0.5 + 0.5, 1);
            Out_Normals = vec4(normal, emissive_color.r);

            vec3 color = texture(albedo, uv.xy).xyz;
            float occlusion = texture(occlusion, uv.xy).r;
            Out_Color = vec4(color, occlusion);

            // G = Rougthness, B = Metalness
            vec2 roughness_metal = texture(metalRoughness, uv.xy).yz;
            Out_Properties0 = vec4(roughness_metal.xy, emissive_color.gb);

            // TODO: remove! This is to test world space reconstruction!
            //Out_WorldPosition = vec4(worldPosition, 1);
        }
    }

    glsl PositionOnly {

        #pragma include &amp;quot;Platform.h&amp;quot;

        #if defined VERTEX

        layout (location = 0) in vec3 Position;

        uniform ViewConstants { 
            mat4                    view_projection_matrix;
            mat4                    projection_matrix;
            vec4                    resolution;
        };

        void main()
        {
            gl_Position = view_projection_matrix * vec4(Position.xyz, 1.0f);
        }
        out vec4 vTexCoord;

        #endif // VERTEX

        #if defined FRAGMENT

        layout (location = 0) out vec4 Out_Color;
        
        void main()
        {
            Out_Color = vec4(1,1,1,1);
        }
        #endif // FRAGMENT
    }

    glsl PositionNormals {

        #pragma include &amp;quot;Platform.h&amp;quot;

        #if defined VERTEX

        layout (location = 0) in vec3 Position;
        layout (location = 1) in vec3 Normal;
        layout (location = 3) in mat4 instanceTransform;

        layout (std140, binding=0) uniform ViewConstants { 
            mat4                    view_projection_matrix;
            mat4                    projection_matrix;
            vec4                    resolution;
        };

        out vec3 vertexNormal;

        void main()
        {
            vertexNormal = Normal;
            gl_Position = view_projection_matrix * instanceTransform * vec4(Position.xyz, 1.0f);
        }
        

        #endif // VERTEX

        #if defined FRAGMENT

        layout (location = 0) out vec4 Out_Color;
        layout (location = 1) out vec4 Out_Normals;
        in vec3 vertexNormal;
        
        void main()
        {
            Out_Normals = vec4(vertexNormal * 0.5 + 0.5, 1);

            vec3 L = vec3(-0.7, 0.7, 0 );
            float lambert_diffuse = max(0, dot(vertexNormal, L));
            Out_Color = vec4(lambert_diffuse.xxx, 1);
        }
        #endif // FRAGMENT
    }

    pass GBuffer {
        resources = gbuffer
        render_states = main
        vertex_layout = gbuffer
        vertex = GBuffer_V
        fragment = GBuffer_F
    }

    pass PositionN {
        render_states = main
        vertex_layout = main3DPositionNormal
        vertex = PositionNormals
        fragment = PositionNormals
    }

    pass PositionOnly {
        render_states = main
        vertex_layout = main3DPosition
        vertex = PositionOnly
        fragment = PositionOnly
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;1-linking-multiple-programs&#34;&gt;1: Linking Multiple Programs&lt;/h2&gt;
&lt;p&gt;This is a pretty simple task, and the first one to be tackled.&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;p&gt;In Vulkan all the Pipelines need all the shader used at creation, using an array of &lt;a href=&#34;https://www.khronos.org/registry/vulkan/specs/1.2-extensions/man/html/VkPipelineShaderStageCreateInfo.html&#34;&gt;VkPipelineStageCreationInfo&lt;/a&gt; for graphics, compute and ray-tracing.&lt;/p&gt;
&lt;p&gt;In D3D12, you have the &lt;a href=&#34;https://docs.microsoft.com/en-us/windows/win32/api/d3d12/ns-d3d12-d3d12_shader_bytecode&#34;&gt;ShaderBytecode&lt;/a&gt; used in the pipelines, but not as arrays (just member of the various creation structs).&lt;/p&gt;
&lt;p&gt;From a functionality perspective, they are EQUAL. It makes sense - a &lt;strong&gt;Pipeline&lt;/strong&gt; is the description of all the static part of a GPU pipeline, and shaders are amongst the most important part of it.&lt;/p&gt;
&lt;p&gt;You can see it in the &amp;lsquo;pass&amp;rsquo; section of the HFX file:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pass PositionOnly {
    vertex = PositionOnly
    fragment = PositionOnly
    ...
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;For a compute pipeline is even simpler, and dispatch size can be added as well:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pass DeferredCompute {
    compute = DeferredCompute
    dispatch = 32, 32, 1
    ...
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Even just with something like this it is easy to organize different shaders.&lt;/p&gt;
&lt;h2 id=&#34;2-define-render-states&#34;&gt;2: Define Render States&lt;/h2&gt;
&lt;p&gt;Following the previous point, Pipelines need also (almost) all the render states (depth/stencil, alpha, raster, &amp;hellip;) to be defined.&lt;!-- raw HTML omitted --&gt;
This was one of the main features of CGFX and Microsoft&amp;rsquo;s FX - and still now is incredibly useful.&lt;!-- raw HTML omitted --&gt;
Unity&amp;rsquo;s ShaderLab also incorporates render states.&lt;/p&gt;
&lt;p&gt;I decided to separate render states on their own group:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;render_states {
    state main {
        Cull Back
        ZTest LEqual
        ZWrite On
    }

    state linesZTest {
        Cull None
        ZTest LEqual
        ZWrite Off
        BlendMode Alpha
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Here two different render states are defined.&lt;!-- raw HTML omitted --&gt;
In this case a render states defines depth/stencil, blend and rasterization.&lt;/p&gt;
&lt;p&gt;A great addition to that is to add the possibility of inherit/override render states.&lt;!-- raw HTML omitted --&gt;
For example in a Transparent pass, the blend state could be defined in the Render Pass data, and be inherited explicitly here.&lt;/p&gt;
&lt;p&gt;Also very important is the definition of &lt;strong&gt;input assembly&lt;/strong&gt; - how the vertices are fed into the &lt;em&gt;vertex program&lt;/em&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;layout {
    vertex main3D {
        binding 0 16 vertex
        attribute float3 Position 0 0 0
        attribute ubyte4n Color 0 1 12
    }

    vertex main3DPosition {
        binding 0 12 vertex
        attribute float3 Position 0 0 0
    }

    vertex main3DPositionNormal {
        binding 0 12 vertex
        binding 1 12 vertex
        binding 3 64 instance
        attribute float3 Position 0 0 0
        attribute float3 Normal 1 1 0
        attribute float4 InstanceTransform 3 3 0
        attribute float4 InstanceTransform 3 4 16
        attribute float4 InstanceTransform 3 5 32
        attribute float4 InstanceTransform 3 6 48
    }

    vertex gbuffer {
        binding 0 12 vertex
        binding 1 12 vertex
        binding 2 8 vertex
        binding 3 64 instance
        attribute float3 Position 0 0 0
        attribute float3 Normal 1 1 0
        attribute float2 UV 2 2 0
        attribute float4 InstanceTransform 3 3 0
        attribute float4 InstanceTransform 3 4 16
        attribute float4 InstanceTransform 3 5 32
        attribute float4 InstanceTransform 3 6 48
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Here we can see some instancing use case, just to show the flexibility of writing this code.&lt;!-- raw HTML omitted --&gt;
The bytes offset could be removed as well.&lt;/p&gt;
&lt;h2 id=&#34;3-use-any-shader-language&#34;&gt;3: Use ANY Shader Language&lt;/h2&gt;
&lt;p&gt;The best way to diffuse these augmentation is to change the less possible the shader languate itself.&lt;!-- raw HTML omitted --&gt;
This is because you want to be portable, and when having different platform it can be paramount even to define shaders with different languages into the same file, and switch based on platforms.&lt;!-- raw HTML omitted --&gt;
This is becoming less and less of a need (see HLSL working on Vulkan) but there could be some special cases.&lt;!-- raw HTML omitted --&gt;
Would it be great to fix those special cases by writing platform specific shader fragments without any of your internal rendering code changing ?&lt;/p&gt;
&lt;p&gt;The choise here is to use a keyword to identify the type of language and then simply write the code in that language.&lt;!-- raw HTML omitted --&gt;
This is &lt;em&gt;ideal&lt;/em&gt; to also incorporate code from previous codebases with a small amount of work.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s look at the GBuffer Vertex GLSL code:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;glsl GBuffer_V {

    #pragma include &amp;quot;Platform.h&amp;quot;

    layout (location = 0) in vec3 Position;
    layout (location = 1) in vec3 Normal;
    layout (location = 2) in vec2 UV;
    layout (location = 3) in mat4 instanceTransform;

    layout (std140, binding=0) uniform ViewConstants {
        mat4                    view_projection_matrix;
        mat4                    projection_matrix;
        vec4                    resolution;
    };

    out vec3 vertexNormal;
    out vec2 uv;
    out vec3 worldPosition;

    void main()
    {
        vertexNormal = (inverse(transpose((instanceTransform))) * vec4(Normal,0)).rgb;
        uv = UV;

        vec4 world_pos = instanceTransform * vec4(Position.xyz, 1.0f);
        worldPosition = world_pos.xyz;
        gl_Position = view_projection_matrix * world_pos;
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The only modification I did, and it is sadly necessary in GLSL, is to add the &amp;lsquo;#pragma include&amp;rsquo; custom parsing to add the include in the HFX compiler.&lt;/p&gt;
&lt;h2 id=&#34;4-resource-layouts-as-first-citizens&#34;&gt;4: Resource Layouts as First Citizens&lt;/h2&gt;
&lt;p&gt;A new addition of the new APIs, resource layouts are another great factor to take care of.&lt;!-- raw HTML omitted --&gt;
Architecturally they can be implemented in different ways, but I like the idea of having them &amp;lsquo;in your face&amp;rsquo; since the beginning!&lt;/p&gt;
&lt;p&gt;In the &lt;em&gt;layout&lt;/em&gt; section, you can define resources like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;list gbuffer {
    cbuffer ViewConstants ViewConstants;

    texture2D albedo;
    texture2D normals;
    texture2D metalRoughness;
    texture2D emissive;
    texture2D occlusion;

    sampler2D linear_sampler
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The name will be used in the pass section to define which resource list is used.&lt;!-- raw HTML omitted --&gt;
There can be multiple resource lists, normally they should be grouped per frequency (most frequent changes to least frequent ones) and can be separated by a comma for example.&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;p&gt;A small addition is to use externally specified resource list and code, like for &lt;strong&gt;starnest.hfx&lt;/strong&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pass main {
	...
	resources = &amp;quot;ShaderToy.Main&amp;quot;	
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This means that the pass named &amp;lsquo;main&amp;rsquo; will simply use the resources defined in &amp;lsquo;shadertoy.hfx&amp;rsquo; - resource list called main.&lt;/p&gt;
&lt;h2 id=&#34;5-permutations&#34;&gt;5: Permutations&lt;/h2&gt;
&lt;p&gt;This is the most tedious of the tasks, and also one of the most dangerous.&lt;!-- raw HTML omitted --&gt;
Permutations explosion is a well known problem, and there are different ways of tackling this. If you don&amp;rsquo;t have a shader augmentation a good option is to write some scripts to help with generating the code.&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;p&gt;Otherwise if you have a shader augmentation and you define a &amp;lsquo;shader state&amp;rsquo;, you can define some &amp;lsquo;permutation flags&amp;rsquo;, and just add the defines when you compile shaders. Even in GLSL, you can do some easy string concatenation to add those defines, or use tools like GLSLang + SpirV to help.&lt;/p&gt;
&lt;p&gt;This becomes a cartesian product of all the &lt;em&gt;permutations/options groups&lt;/em&gt; and again can lead to a lot of created shader.&lt;!-- raw HTML omitted --&gt;
I am still investigating the best approach and I will update this article with the results, because I want to include them into HFX but avoid that to become a huge file - and worst to include unused permutations.&lt;/p&gt;
&lt;p&gt;So stay tuned as I will update this article with the solution I find!&lt;/p&gt;
&lt;h2 id=&#34;6-c-generated-helpers&#34;&gt;6: C++ Generated Helpers&lt;/h2&gt;
&lt;p&gt;As finishing touch, there are some informations that can be exposed in a c++ file.
&amp;hellip;&lt;/p&gt;
&lt;h1 id=&#34;included-code-shader-augmentation&#34;&gt;Included code: &amp;lsquo;Shader Augmentation&amp;rsquo;&lt;/h1&gt;
&lt;p&gt;The included code has a small application to compile and inspect HFX files.
&amp;hellip;&lt;/p&gt;
&lt;h1 id=&#34;conclusions&#34;&gt;Conclusions&lt;/h1&gt;
&lt;p&gt;I tried to explain the reasons of the different &lt;strong&gt;shader augmentations&lt;/strong&gt; and trying to focus more on the importance of not trying to create a new shading language, but instead empowering it with new informations.&lt;/p&gt;
&lt;p&gt;I can&amp;rsquo;t stress enough how important is to me to have an abstraction that is slightly on top of current shaders API - and create other systems to hide the complexities if needed.&lt;/p&gt;
&lt;p&gt;With HFX, I would like to &lt;em&gt;expand&lt;/em&gt; any language by adding all those features.&lt;!-- raw HTML omitted --&gt;
I wish this could become a used tool by many in their project, and really wish it will be the initial spark.&lt;/p&gt;
&lt;p&gt;Next in line is a revisiting of higher level of rendering, to arrive to explore different rendering techniques with the easiness that the data-driven approach should give.&lt;/p&gt;
&lt;p&gt;As always please comment, give me feedback, share and enjoy!&lt;/p&gt;
&lt;p&gt;Thanks for reading!
Gabriel&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Data Driven Rendering: Pipelines</title>
      <link>https://jorenjoestar.github.io/post/data_driven_rendering_pipeline/</link>
      <pubDate>Mon, 14 Oct 2019 10:43:49 -0400</pubDate>
      
      <guid>https://jorenjoestar.github.io/post/data_driven_rendering_pipeline/</guid>
      <description>&lt;h1 id=&#34;overview&#34;&gt;Overview&lt;/h1&gt;






&lt;figure&gt;

  &lt;a data-fancybox=&#34;&#34; href=&#34;GLTFHelmet.png&#34; &gt;

&lt;img src=&#34;GLTFHelmet.png&#34; &gt;
&lt;/a&gt;


&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;Model used in the demo.&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;Data Driven Rendering Series:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://jorenjoestar.github.io/post/writing_shader_effect_language_1/&#34;&gt;https://jorenjoestar.github.io/post/writing_shader_effect_language_1/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://jorenjoestar.github.io/post/writing_shader_effect_language_2/&#34;&gt;https://jorenjoestar.github.io/post/writing_shader_effect_language_2/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://jorenjoestar.github.io/post/writing_shader_effect_language_3/&#34;&gt;https://jorenjoestar.github.io/post/writing_shader_effect_language_3/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://jorenjoestar.github.io/post/data_driven_rendering_pipeline/&#34;&gt;https://jorenjoestar.github.io/post/data_driven_rendering_pipeline/&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;We finally arrived in the &lt;strong&gt;Rendering Pipeline&lt;/strong&gt; realm.&lt;!-- raw HTML omitted --&gt;
Some can write that it is useless, some can hate it.&lt;!-- raw HTML omitted --&gt;
Many have some sort of abstraction for it since ages, and others have to now that new APIs like &lt;strong&gt;Vulkan&lt;/strong&gt; and &lt;strong&gt;DX12&lt;/strong&gt; have it as an explicit part of their design (finally!).&lt;/p&gt;
&lt;p&gt;After we built a basic Material System in the previous article (&lt;a href=&#34;https://jorenjoestar.github.io/post/writing_shader_effect_language_3/&#34;&gt;https://jorenjoestar.github.io/post/writing_shader_effect_language_3/&lt;/a&gt;) we can add another layer on top of it and built a complete &lt;em&gt;Rendering Frame&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;In this article I will talk about a simplified version of &lt;strong&gt;Render Graph&lt;/strong&gt; that I call &lt;strong&gt;Render Pipeline&lt;/strong&gt; and came into my mind in the canteen of Codemasters after thinking:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;What is the biggest dependency in Rendering ?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The answer is simple:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Render Targets!&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;Render Targets&lt;/strong&gt; or &lt;strong&gt;Frame Buffers&lt;/strong&gt; is just an intermediate buffer in which we can draw something and use it later.&lt;!-- raw HTML omitted --&gt;
Basically a Read/Write texture!&lt;!-- raw HTML omitted --&gt;
It is not easy to shuffle around a Render Target, and having knowledge of which one are you using can make a huge difference for your rendering tech.&lt;!-- raw HTML omitted --&gt;
Textures and Render Targets are the biggest memory lord in any rendering application, thus knowing &lt;em&gt;where&lt;/em&gt; you are spending your memory can be really powerful.&lt;/p&gt;
&lt;p&gt;From a pure &lt;em&gt;understanding&lt;/em&gt; of rendering techniques, having a clear visualization of this aspect makes a HUGE difference!&lt;/p&gt;
&lt;p&gt;Once I started using to describe a frame of rendering with the &lt;strong&gt;Render Target Dependencies&lt;/strong&gt; I never looked back.&lt;!-- raw HTML omitted --&gt;
As always, knowledge is power.&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;h1 id=&#34;render-pipeline-thinking&#34;&gt;Render Pipeline Thinking&lt;/h1&gt;
&lt;p&gt;First of all, let&amp;rsquo;s start defining some general concepts to describe the problem we are trying to solve.&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;p&gt;The problem we are trying to solve is:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;How to describe the inter-frame dependencies of Render Targets in a frame ?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The dependencies are who &lt;strong&gt;writes&lt;/strong&gt; and/or &lt;strong&gt;read&lt;/strong&gt; from/to a &lt;strong&gt;Render Target&lt;/strong&gt;.&lt;!-- raw HTML omitted --&gt;
That is exactly what is described in a Render Pipeline.
Enter the &lt;em&gt;Render Pipeline&lt;/em&gt;.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;A Render Pipeline is a list of Passes that read and writes Render Targets.&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;That&amp;rsquo;s it.&lt;!-- raw HTML omitted --&gt;
Done! See you next article!&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;p&gt;Of course I am kidding - but this is the gist of it.&lt;!-- raw HTML omitted --&gt;
The implications, however, are profound.&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;p&gt;Next logical question is:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;How can we read and write from/to a Render Target ?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Let&amp;rsquo;s list how we can &lt;em&gt;write&lt;/em&gt; to a Render Target&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Graphics - binding some geometry, render states and Render Targets&lt;/li&gt;
&lt;li&gt;Compute - write anything to the Render Target&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Even a so called &lt;em&gt;&amp;lsquo;post-process&amp;rsquo;&lt;/em&gt; is just a &lt;em&gt;fullscreen triangle with a shader&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;And to read&amp;hellip;well any &lt;strong&gt;shader&lt;/strong&gt; that takes reads a texture!&lt;/p&gt;
&lt;p&gt;It is incredible to think that with this simple building blocks you can describe almost everything to render!&lt;/p&gt;
&lt;p&gt;For example, let&amp;rsquo;s try to express some common rendering techniques using only those concepts.&lt;/p&gt;
&lt;h2 id=&#34;deferred-rendering&#34;&gt;Deferred Rendering&lt;/h2&gt;
&lt;p&gt;We can define the following simple steps:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Meshes uses their materials (shaders + textures + constants) as input and write into GBuffer Render Target + depth.&lt;/li&gt;
&lt;li&gt;A Compute/Post-process shader will read the Gbuffer Render Target and depth (to reconstruct the pixel position), a light list of some sort and outputs a texture with the result.&lt;/li&gt;
&lt;li&gt;Transparent objects are drawn into this new Render Target using their materials.&lt;/li&gt;
&lt;li&gt;And so on&amp;hellip;&lt;/li&gt;
&lt;/ol&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;h2 id=&#34;exponential-variance-shadow-mapping-in-a-forward-rendering-pipeline&#34;&gt;Exponential Variance Shadow Mapping in a Forward Rendering Pipeline&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Meshes writes into a depth-only render target using the light as &amp;lsquo;camera/point of view&amp;rsquo;.&lt;/li&gt;
&lt;li&gt;Compute or Postprocess converts the depth-only render target into a EVSM one.&lt;/li&gt;
&lt;li&gt;Meshes uses their materials and the &lt;em&gt;EVSM shadow map&lt;/em&gt; to render into a &lt;em&gt;&amp;lsquo;main&amp;rsquo;&lt;/em&gt; Render Target.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&amp;lt;diagram 2 goes here&amp;gt;&lt;/p&gt;
&lt;h1 id=&#34;other-rendering-concepts&#34;&gt;Other Rendering Concepts&lt;/h1&gt;
&lt;p&gt;To give a full description of the frame we need to add other concepts that will help us.&lt;!-- raw HTML omitted --&gt;
These are the less strict ones - and just a personal way of seeing things.&lt;/p&gt;
&lt;h2 id=&#34;render-view&#34;&gt;Render View&lt;/h2&gt;
&lt;p&gt;The concept of &lt;em&gt;&amp;lsquo;Render View&amp;rsquo;&lt;/em&gt; is just a way or representing a &lt;em&gt;camera&lt;/em&gt; and a list of visible objects from it.&lt;!-- raw HTML omitted --&gt;
We will see how we use it later, but a simple example of Render View would be the &amp;lsquo;Sun Shadow&amp;rsquo; render view - representing the sun (as a camera) and a list of visible objects from it.&lt;!-- raw HTML omitted --&gt;
The &amp;lsquo;Main&amp;rsquo; render view of course represent the main camera and visible objects.&lt;!-- raw HTML omitted --&gt;
This, combined with &lt;strong&gt;render managers&lt;/strong&gt; becomes a powerful combination to describe &lt;em&gt;what&lt;/em&gt; needs to be rendered.&lt;/p&gt;
&lt;h2 id=&#34;render-manager&#34;&gt;Render Manager&lt;/h2&gt;
&lt;p&gt;If you think from an ECS mentality, this would be a &amp;lsquo;system&amp;rsquo;.&lt;!-- raw HTML omitted --&gt;
Each render manager is responsible to render one or more render &lt;em&gt;&amp;lsquo;aspects/entities&amp;rsquo;&lt;/em&gt; into a Render Pass.&lt;!-- raw HTML omitted --&gt;
A render manager can subscribe to any &amp;lsquo;graphics&amp;rsquo; pass and render from there.&lt;/p&gt;
&lt;p&gt;For example, a &amp;lsquo;static geometry&amp;rsquo; render manager could setup an instancing buffer for the gbuffer-generation pass and draw all objects.&lt;/p&gt;
&lt;h1 id=&#34;render-pipeline-implementation&#34;&gt;Render Pipeline Implementation&lt;/h1&gt;
&lt;p&gt;After we defined the basic concepts let&amp;rsquo;s see an actual implementation of the Render Pipeline.&lt;!-- raw HTML omitted --&gt;
We will see the code of each component and arrive at the actual data definition (in json).&lt;/p&gt;
&lt;p&gt;The code has changed a bit since last article, with the inclusion of CGLM as math library and other high-level rendering code, included in hydra_rendering.h/.cpp.&lt;/p&gt;
&lt;h2 id=&#34;render-view-1&#34;&gt;Render View&lt;/h2&gt;
&lt;p&gt;First element is the Render View:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;//
// Render view is a &#39;contextualized&#39; camera - a way of using the camera in the render pipeline.
//
struct RenderView {

    Camera                          camera;

    array( RenderScene )            visible_render_scenes;

}; // struct RenderView

&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Using STB&amp;rsquo;s array (the macro is just an aid to know it is not just a pointer) we have a list of visible render scenes from that camera.&lt;!-- raw HTML omitted --&gt;
It should be pretty straighforward.&lt;/p&gt;
&lt;h2 id=&#34;render-manager-1&#34;&gt;Render Manager&lt;/h2&gt;
&lt;p&gt;Next is Render Manager:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;//
struct RenderManager {

    struct RenderContext {
        Device*                     device;

        const RenderView*           render_view;
        CommandBuffer*              commands;
        
        RenderScene*                render_scene_array;
        uint16_t                    start;
        uint16_t                    count;
        
        uint16_t                    stage_index;
    }; // struct RenderContext

    virtual void                    render( RenderContext&amp;amp; render_context ) = 0;

}; // struct RenderManager
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The base class is really just a &amp;lsquo;render&amp;rsquo; method.&lt;!-- raw HTML omitted --&gt;
Here the RenderContext is interesting, and it gives access to all you need to render:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Device - used to map/unmap resources.&lt;/li&gt;
&lt;li&gt;RenderView - access to camera (and more, but that&amp;rsquo;s for the next article!).&lt;/li&gt;
&lt;li&gt;CommandBuffer - the actual draw commands are written here.&lt;/li&gt;
&lt;li&gt;RenderScene - the RenderScene from start to start + count.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;In this very simple demo, we have just 2 &lt;em&gt;render managers&lt;/em&gt;: &lt;em&gt;Line Renderer&lt;/em&gt; and &lt;em&gt;Scene Renderer&lt;/em&gt;.&lt;!-- raw HTML omitted --&gt;
The most interesting one is the second: Line Renderer has commands to draw lines that will be mapped into a GPU buffer and uses instancing to draw them.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
void LineRenderer::render( RenderContext&amp;amp; render_context ) {

    Device&amp;amp; device = *render_context.device;

    // Update camera matrix
    const Camera&amp;amp; camera = render_context.render_view-&amp;gt;camera;

    MapBufferParameters cb_map = { lines_cb, 0, 0 };
    
    float L = 0, T = 0;
    float R = device.swapchain_width, B = device.swapchain_height;
    const float ortho_projection[4][4] =
    {
        { 2.0f / ( R - L ),   0.0f,         0.0f,   0.0f },
        { 0.0f,         2.0f / ( T - B ),   0.0f,   0.0f },
        { 0.0f,         0.0f,        -1.0f,   0.0f },
        { ( R + L ) / ( L - R ),  ( T + B ) / ( B - T ),  0.0f,   1.0f },
    };

    LocalConstants* cb_data = (LocalConstants*)device.map_buffer( cb_map );
    if ( cb_data ) {
        cb_data-&amp;gt;view_projection = camera.view_projection;
        
        memcpy( &amp;amp;cb_data-&amp;gt;projection, &amp;amp;ortho_projection, 64 );
        
        cb_data-&amp;gt;resolution = { device.swapchain_width * 1.0f, device.swapchain_height * 1.0f, 1.0f / device.swapchain_width, 1.0f / device.swapchain_height };
        device.unmap_buffer( cb_map );
    }

    if ( current_line_index ) {
        const uint32_t mapping_size = sizeof( LinVertex ) * current_line_index;
        MapBufferParameters map_parameters_vb = { lines_vb, 0, mapping_size };
        LinVertex* vtx_dst = (LinVertex*)device.map_buffer( map_parameters_vb );
        
        if ( vtx_dst ) {
            memcpy( vtx_dst, &amp;amp;s_line_buffer[0], mapping_size );
            
            device.unmap_buffer( map_parameters_vb );
        }

        CommandBuffer* commands = render_context.commands;
        commands-&amp;gt;begin_submit( 2 );

        ShaderInstance&amp;amp; shader_instance = line_material-&amp;gt;shader_instances[3];
        commands-&amp;gt;bind_pipeline( shader_instance.pipeline );
        commands-&amp;gt;bind_resource_list( shader_instance.resource_lists, shader_instance.num_resource_lists, nullptr, 0 );
        commands-&amp;gt;bind_vertex_buffer( lines_vb, 0, 0 );
        // Draw using instancing and 6 vertices.
        const uint32_t num_vertices = 6;
        commands-&amp;gt;draw( TopologyType::Triangle, 0, num_vertices, current_line_index / 2 );
        commands-&amp;gt;end_submit();

        current_line_index = 0;
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Easy to notice how, with a Vulkan/DX12 interface, there are few less commands to write. Binding a pipeline sets everything considered &amp;lsquo;static&amp;rsquo; - render states, shaders - and with just &lt;em&gt;resource lists&lt;/em&gt; (that sets textures and constants) and &lt;em&gt;vertex/index buffers&lt;/em&gt; we have everything needed to render.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: HFX has gone some improvements and now supports &lt;em&gt;render states and vertex declarations/formats&lt;/em&gt;. I&amp;rsquo;ll write about it in the next post - but this has become crucial.&lt;/p&gt;
&lt;h2 id=&#34;shader-resources-management&#34;&gt;Shader Resources Management&lt;/h2&gt;
&lt;p&gt;This is another personal preference - but not necessary at all.&lt;!-- raw HTML omitted --&gt;
Two concepts are really useful to me to be explicit and centralized: &lt;em&gt;resources and bindings&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Resources are all referenced in a &lt;em&gt;&amp;lsquo;Shader Resource Database&amp;rsquo;&lt;/em&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;//
// Struct used to retrieve textures, buffers and samplers.
//
struct ShaderResourcesDatabase {

    struct BufferStringMap {
        char*                       key;
        BufferHandle                value;
    }; // struct BufferStringMap

    struct TextureStringMap {
        char*                       key;
        TextureHandle               value;
    }; // struct TextureStringMap

    struct SamplerStringMap {
        char* key;
        SamplerHandle               value;
    }; // struct SamplerStringMap

    BufferStringMap*                name_to_buffer = nullptr;
    TextureStringMap*               name_to_texture = nullptr;
    SamplerStringMap*               name_to_sampler = nullptr;

    void                            init();
    void                            terminate();

    void                            register_buffer( char* name, BufferHandle buffer );
    void                            register_texture( char* name, TextureHandle texture );
    void                            register_sampler( char* name, SamplerHandle sampler );

    BufferHandle                    find_buffer( char* name );
    TextureHandle                   find_texture( char* name );
    SamplerHandle                   find_sampler( char* name );

}; // struct ShaderResourcesDatabase

&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Simply put, any resource used by rendering is here.&lt;!-- raw HTML omitted --&gt;
Both Materials, Pipelines and Render Managers register and use the database to create the &lt;em&gt;resource lists&lt;/em&gt; used in rendering.&lt;/p&gt;
&lt;p&gt;Next and more convoluted is the &lt;em&gt;shader resources lookup&lt;/em&gt; class:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;//
// Struct to link between a Shader Binding Name and a Resource. Used both in Pipelines and Materials.
//
struct ShaderResourcesLookup {

    enum Specialization {
        Frame, Pass, View, Shader
    }; // enum Specialization

    struct NameMap {
        char*                       key;
        char*                       value;
    }; // struct NameMap

    struct SpecializationMap {
        char*                       key;
        Specialization              value;
    }; // struct SpecializationMap

    NameMap*                        binding_to_resource = nullptr;
    SpecializationMap*              binding_to_specialization = nullptr;
    NameMap*                        binding_to_sampler = nullptr;

    void                            init();
    void                            terminate();

    void                            add_binding_to_resource( char* binding, char* resource );
    void                            add_binding_to_specialization( char* binding, Specialization specialization );
    void                            add_binding_to_sampler( char* binding, char* sampler );

    char*                           find_resource( char* binding );
    Specialization                  find_specialization( char* binding );
    char*                           find_sampler( char* binding );

    void                            specialize( char* pass, char* view, ShaderResourcesLookup&amp;amp; final_lookup );

}; // struct ShaderResourcesLookup
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This class specify the binding between a &lt;em&gt;shader resource&lt;/em&gt; and an &lt;em&gt;actual resource&lt;/em&gt;.&lt;!-- raw HTML omitted --&gt;
As a simple example to clarify, a shader could have an &lt;em&gt;&amp;lsquo;albedo&amp;rsquo;&lt;/em&gt; texture defined in the code, but the &lt;em&gt;actual&lt;/em&gt; texture is defined by the material.&lt;!-- raw HTML omitted --&gt;
Or for a Render Stage, like a Post-Processing one, its input could be defined in the shader code as &lt;em&gt;&amp;lsquo;input 0, input 1&amp;hellip;&#39;&lt;/em&gt; and the render pipeline creates the binding.&lt;/p&gt;
&lt;p&gt;With those in place, we can finalize any resource used by any shader/material/pipeline.&lt;/p&gt;
&lt;p&gt;The actual usage is into the Shader Instance class. Let&amp;rsquo;s have a quick look.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;//
struct ShaderInstance {

    void                            load_resources( const PipelineCreation&amp;amp; pipeline, PipelineHandle pipeline_handle, ShaderResourcesDatabase&amp;amp; database, ShaderResourcesLookup&amp;amp; lookup, Device&amp;amp; device );

    PipelineHandle                  pipeline;
    ResourceListHandle              resource_lists[k_max_resource_layouts];

    uint32_t                        num_resource_lists;
}; // struct ShaderInstance
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This class is what actually contains the resource lists and pipeline used to render anything.&lt;!-- raw HTML omitted --&gt;
Not very happy with the name - any suggestion welcome.&lt;!-- raw HTML omitted --&gt;
A material contains a list of those - one for each pass - and is used to draw.&lt;!-- raw HTML omitted --&gt;
Again with the new Vulkan/DX12 mentality, Pipeline + Resource Lists + Geometry is all you need to render almost.&lt;/p&gt;
&lt;p&gt;The magic happens when creating the resource lists:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;void ShaderInstance::load_resources( const PipelineCreation&amp;amp; pipeline_creation, PipelineHandle pipeline_handle, ShaderResourcesDatabase&amp;amp; database, ShaderResourcesLookup&amp;amp; lookup, Device&amp;amp; device ) {
    
    using namespace hydra::graphics;
    ResourceListCreation::Resource resources_handles[k_max_resources_per_list];

    for ( uint32_t l = 0; l &amp;lt; pipeline_creation.num_active_layouts; ++l ) {
        // Get resource layout description
        ResourceListLayoutDescription layout;
        device.query_resource_list_layout( pipeline_creation.resource_list_layout[l], layout );

&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;We know that a pipeline can have 1 or more resource lists, thus we just iterate through them.&lt;!-- raw HTML omitted --&gt;
Next we look into each resource of the current list:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
        // For each resource
        for ( uint32_t r = 0; r &amp;lt; layout.num_active_bindings; r++ ) {
            const ResourceBinding&amp;amp; binding = layout.bindings[r];

            // Find resource name
            // Copy string_buffer 
            char* resource_name = lookup.find_resource( (char*)binding.name );

            switch ( binding.type ) {
                case hydra::graphics::ResourceType::Constants:
                case hydra::graphics::ResourceType::Buffer:
                {
                    BufferHandle handle = resource_name ? database.find_buffer( resource_name ) : device.get_dummy_constant_buffer();
                    resources_handles[r].handle = handle.handle;

                    break;
                }

                ... same for textures
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;For each binding coming from the shader (think &amp;lsquo;albedo&amp;rsquo; for a PBR shader) we search for the actual resource name (&amp;lsquo;WoodBeamAlbedo&amp;rsquo;) and query the database to find it.&lt;!-- raw HTML omitted --&gt;
After we did that, we can create the list:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;            }
        }

        ResourceListCreation creation = { pipeline_creation.resource_list_layout[l], resources_handles, layout.num_active_bindings };
        resource_lists[l] = device.create_resource_list( creation );
    }

    num_resource_lists = pipeline_creation.num_active_layouts;
    pipeline = pipeline_handle;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;With this mechanism we added another explicit connection between resources.&lt;/p&gt;
&lt;p&gt;It is finally time to see the actual render pipeline!&lt;/p&gt;
&lt;h2 id=&#34;render-stagepass&#34;&gt;Render Stage/Pass&lt;/h2&gt;
&lt;p&gt;This is the &lt;em&gt;CORE&lt;/em&gt; of everything, and it must work with all both &lt;strong&gt;geometrical&lt;/strong&gt; stages and &lt;strong&gt;post-process&lt;/strong&gt; ones.&lt;!-- raw HTML omitted --&gt;
You can either create a base virtual class or doing something like here.&lt;!-- raw HTML omitted --&gt;
Important is understanding the concept!&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;//
// Encapsulate the rendering of anything that writes to one or more Render Targets.
//
struct RenderStage {

    enum Type {
        Geometry, Post, PostCompute, Swapchain, Count
    };

	Type                            type                                = Count;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Simply we define the types:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Geometry - uses render manager with meshes to draw.&lt;/li&gt;
&lt;li&gt;Post - fullscreen triangle + shader.&lt;/li&gt;
&lt;li&gt;PostCompute - any compute shader execution basically!&lt;/li&gt;
&lt;li&gt;Swapchain - special case of binding the window framebuffer and render the last time.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Next is the most important part: dependencies!&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    array( TextureHandle )          input_textures                      = nullptr;
    array( TextureHandle )          output_textures                     = nullptr;

    TextureHandle                   depth_texture;

&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;When we create the pipeline, we save all inputs and outputs textures.&lt;!-- raw HTML omitted --&gt;
Depth/Stencil is a put in its own part.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    float                           scale_x                             = 1.0f;
    float                           scale_y                             = 1.0f;
    uint16_t                        current_width                       = 1;
    uint16_t                        current_height                      = 1;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Here we handle scaling. When using scale, we use the framebuffer&amp;rsquo;s window width/height to calculate the Render Target size of the output ones. When using the current width/height we instead define a specific size (like for a shadow map).&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    RenderPassHandle                render_pass;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;hydra::graphics low level rendering needs this handle to actually handle the drawing.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    Material*                       material                            = nullptr;
    uint8_t                         pass_index                          = 0;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This is for PostProcesses : material and pass index to retrieve the &amp;lsquo;shader instance&amp;rsquo; containing the &lt;em&gt;pipeline&lt;/em&gt; and the &lt;em&gt;resource lists&lt;/em&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    RenderView*                     render_view                         = nullptr;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;RenderView used by this stage.&lt;!-- raw HTML omitted --&gt;
For example the &amp;lsquo;Sun Shadow Render Stage&amp;rsquo; will use the &amp;lsquo;Shadow Render View&amp;rsquo; to dispatch all its objects to each render manager.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    float                           clear_color[4];
    float                           clear_depth_value;
    uint8_t                         clear_stencil_value;

    uint8_t                         clear_rt                            : 1;
    uint8_t                         clear_depth                         : 1;
    uint8_t                         clear_stencil                       : 1;
    uint8_t                         resize_output                       : 1;
    uint8_t                         pad                                 : 4;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;If the stage needs to clear its output(s), these will tell what to do.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    uint64_t                        geometry_stage_mask;                // Used to send render objects to the proper stage. Not used by compute or postprocess stages.
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This creates a link between render managers and stages.&lt;!-- raw HTML omitted --&gt;
An object is rendered only if its &lt;em&gt;stage mask&lt;/em&gt; equals at least one stage.&lt;!-- raw HTML omitted --&gt;
Why that ? &lt;!-- raw HTML omitted --&gt;
Because when defining a &lt;em&gt;render view&lt;/em&gt;, we have a list of objects visible from that camera, and we need a way of dispatching those objects to their respective managers.&lt;/p&gt;
&lt;p&gt;For example a &amp;lsquo;dynamic render object&amp;rsquo; could have appear both on the gbuffer pass and an &amp;lsquo;object special effect&amp;rsquo; pass - both visible from the main camera.&lt;/p&gt;
&lt;p&gt;This ideas comes from the &lt;em&gt;AMAZING&lt;/em&gt; talk by Bungie:&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://advances.realtimerendering.com/destiny/gdc_2015/Tatarchuk_GDC_2015__Destiny_Renderer_web.pdf&#34;&gt;http://advances.realtimerendering.com/destiny/gdc_2015/Tatarchuk_GDC_2015__Destiny_Renderer_web.pdf&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;A &lt;em&gt;render manager&lt;/em&gt; is what they call a &lt;em&gt;feature renderer&lt;/em&gt; - named differently because this version is much more basic!&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    array( RenderManager* )         render_managers;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Render Managers can register to stages even if they don&amp;rsquo;t have objects, for example a &lt;em&gt;&amp;lsquo;Lighting Manager&amp;rsquo;&lt;/em&gt; would want to submit a list of visible light in a certain pass.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    // Interface
    virtual void                    init();
    virtual void                    terminate();

    virtual void                    begin( Device&amp;amp; device, CommandBuffer* commands );
    virtual void                    render( Device&amp;amp; device, CommandBuffer* commands );
    virtual void                    end( Device&amp;amp; device, CommandBuffer* commands );

    virtual void                    load_resources( ShaderResourcesDatabase&amp;amp; db, Device&amp;amp; device );
    virtual void                    resize( uint16_t width, uint16_t height, Device&amp;amp; device );

    void                            register_render_manager( RenderManager* manager );

}; // struct RenderStage
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This is the final interface.&lt;!-- raw HTML omitted --&gt;
Load resources is used for PostProcesses - they have a material and need to load its resources.&lt;/p&gt;
&lt;h2 id=&#34;render-pipeline&#34;&gt;Render Pipeline&lt;/h2&gt;
&lt;p&gt;We arrived at the last piece of the puzzle!&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;//
// A full frame of rendering using RenderStages.
//
struct RenderPipeline {

    struct StageMap {
        char*                       key;
        RenderStage*                value;
    };

    struct TextureMap {
        char*                       key;
        TextureHandle               value;
    };

    void                            init( ShaderResourcesDatabase* initial_db );
    void                            terminate( Device&amp;amp; device );

    void                            update();
    void                            render( Device&amp;amp; device, CommandBuffer* commands );

    void                            load_resources( Device&amp;amp; device );
    void                            resize( uint16_t width, uint16_t height, Device&amp;amp; device );

    StageMap*                       name_to_stage                       = nullptr;
    TextureMap*                     name_to_texture                     = nullptr;

    ShaderResourcesDatabase         resource_database;
    ShaderResourcesLookup           resource_lookup;

}; // struct RenderPipeline
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This is literally IT!&lt;!-- raw HTML omitted --&gt;
This class contains all the stages and resources needed to render.&lt;!-- raw HTML omitted --&gt;
Most of the time it will just iterate over the stages and execute something per stage.&lt;/p&gt;
&lt;p&gt;Resource database contains all the resources used actually - and the lookup instead is only for the PostProcess stages.&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;h2 id=&#34;render-pipeline-description&#34;&gt;Render Pipeline Description&lt;/h2&gt;
&lt;p&gt;We really have all the part to render a frame!&lt;!-- raw HTML omitted --&gt;
Let&amp;rsquo;s look at the data defining the pipeline.&lt;!-- raw HTML omitted --&gt;
We will define a simple-silly-non-effective PBR deferred rendering.&lt;!-- raw HTML omitted --&gt;
Probably the worst shaders you saw, but it will still work.&lt;/p&gt;
&lt;p&gt;First we define the Render Targets:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{
    &amp;quot;name&amp;quot;: &amp;quot;PBR_Deferred&amp;quot;,
    &amp;quot;RenderTargets&amp;quot;: [
        {
            &amp;quot;name&amp;quot;: &amp;quot;GBufferAlbedo&amp;quot;,
            &amp;quot;format&amp;quot;: &amp;quot;R8G8B8A8_UNORM&amp;quot;
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;GBufferNormals&amp;quot;,
            &amp;quot;format&amp;quot;: &amp;quot;R16G16B16A16_SNORM&amp;quot;
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;GBufferProperties0&amp;quot;,
            &amp;quot;format&amp;quot;: &amp;quot;R8G8B8A8_UNORM&amp;quot;
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;MainDepth&amp;quot;,
            &amp;quot;format&amp;quot;: &amp;quot;D24_UNORM_S8_UINT&amp;quot;
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;BackBufferColor&amp;quot;,
            &amp;quot;format&amp;quot;: &amp;quot;R16G16B16A16_FLOAT&amp;quot;
        }
    ],
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;by default they will have the same size as the window framebuffer, unless otherwise written (scale_x/y, width/height).&lt;/p&gt;
&lt;p&gt;Next are the actual render stages.&lt;!-- raw HTML omitted --&gt;
The first is the GBufferOpaque one:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    &amp;quot;RenderStages&amp;quot;: [
        {
            &amp;quot;name&amp;quot;: &amp;quot;GBufferOpaque&amp;quot;,
            &amp;quot;type&amp;quot;: &amp;quot;Geometry&amp;quot;,
            &amp;quot;render_view&amp;quot;: &amp;quot;main&amp;quot;,
            &amp;quot;depth_stencil&amp;quot;: &amp;quot;Main&amp;quot;,
            &amp;quot;inputs&amp;quot;: [

            ],
            &amp;quot;outputs&amp;quot;: {
                &amp;quot;rts&amp;quot;: [ &amp;quot;GBufferAlbedo&amp;quot;, &amp;quot;GBufferNormals&amp;quot;, &amp;quot;GBufferProperties0&amp;quot; ],
                &amp;quot;depth&amp;quot;: &amp;quot;MainDepth&amp;quot;,
                &amp;quot;flags&amp;quot;: &amp;quot;Common&amp;quot;,
                &amp;quot;clear_color&amp;quot;: &amp;quot;000000ff&amp;quot;,
                &amp;quot;clear_depth&amp;quot;: 1.0,
                &amp;quot;clear_stencil&amp;quot;: 0
            }
        },
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;As you see it outputs to 3 Render Targets + Depth.&lt;!-- raw HTML omitted --&gt;
It also specify clear color, depth and stencil.&lt;/p&gt;
&lt;p&gt;Next is the silliest compute shader to calculate light:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;        {
            &amp;quot;name&amp;quot;: &amp;quot;DeferredLights&amp;quot;,
            &amp;quot;type&amp;quot;: &amp;quot;PostCompute&amp;quot;,
            &amp;quot;material_name&amp;quot;: &amp;quot;SimpleFullscreen&amp;quot;,
            &amp;quot;material_pass_index&amp;quot;: 2,
            &amp;quot;inputs&amp;quot;: [
                {
                    &amp;quot;name&amp;quot;: &amp;quot;GBufferAlbedo&amp;quot;,
                    &amp;quot;sampler&amp;quot;: &amp;quot;Point&amp;quot;,
                    &amp;quot;binding&amp;quot;: &amp;quot;gbuffer_albedo&amp;quot;
                },
                {
                    &amp;quot;name&amp;quot;: &amp;quot;GBufferNormals&amp;quot;,
                    &amp;quot;sampler&amp;quot;: &amp;quot;Point&amp;quot;,
                    &amp;quot;binding&amp;quot;: &amp;quot;gbuffer_normals&amp;quot;
                },
                {
                    &amp;quot;name&amp;quot;: &amp;quot;GBufferProperties0&amp;quot;,
                    &amp;quot;sampler&amp;quot;: &amp;quot;Point&amp;quot;,
                    &amp;quot;binding&amp;quot;: &amp;quot;gbuffer_properties0&amp;quot;
                },
                {
                    &amp;quot;name&amp;quot;: &amp;quot;MainDepth&amp;quot;,
                    &amp;quot;sampler&amp;quot;: &amp;quot;Point&amp;quot;,
                    &amp;quot;binding&amp;quot;: &amp;quot;depth_texture&amp;quot;
                }
            ],
            &amp;quot;outputs&amp;quot;: {
                &amp;quot;images&amp;quot;: [
                    {
                        &amp;quot;name&amp;quot;: &amp;quot;BackBufferColor&amp;quot;,
                        &amp;quot;binding&amp;quot;: &amp;quot;destination_texture&amp;quot;
                    }
                ],
                &amp;quot;flags&amp;quot;: &amp;quot;Common&amp;quot;
            }
        },

&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;It will read all the previously generated textures and run a compute shader to calculate the final lighting.&lt;!-- raw HTML omitted --&gt;
Worth noting &amp;lsquo;material&amp;rsquo; and &amp;lsquo;material pass index&amp;rsquo; - to retrieve the shader from the material. If you open SimpleFullscreen.hfx and go to the third defined pass, you will see the code.&lt;/p&gt;
&lt;p&gt;Next is an example of reusing a Render Target to add informations (like transparent objects).&lt;!-- raw HTML omitted --&gt;
It will add debug rendering on top of the other objects and write in the BackBufferColor render target.&lt;!-- raw HTML omitted --&gt;
The absence of clear parameters dictates that we don&amp;rsquo;t want to clear.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;        {
            &amp;quot;name&amp;quot;: &amp;quot;DebugRendering&amp;quot;,
            &amp;quot;type&amp;quot;: &amp;quot;Geometry&amp;quot;,
            &amp;quot;render_view&amp;quot;: &amp;quot;main&amp;quot;,
            &amp;quot;inputs&amp;quot;: [

            ],
            &amp;quot;outputs&amp;quot;: {
                &amp;quot;rts&amp;quot;: [ &amp;quot;BackBufferColor&amp;quot; ],
                &amp;quot;depth&amp;quot;: &amp;quot;MainDepth&amp;quot;,
                &amp;quot;flags&amp;quot;: &amp;quot;Common&amp;quot;
            }
        },
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Last step is the swapchain.&lt;!-- raw HTML omitted --&gt;
It is simply using a simple shader to write to the window framebuffer as the last step of the frame.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;        {
            &amp;quot;name&amp;quot;: &amp;quot;Swapchain&amp;quot;,
            &amp;quot;type&amp;quot;: &amp;quot;Swapchain&amp;quot;,
            &amp;quot;mask&amp;quot;: &amp;quot;FRAMEBUFFER&amp;quot;,
            &amp;quot;material_name&amp;quot;: &amp;quot;Swapchain&amp;quot;,
            &amp;quot;render_view&amp;quot;: &amp;quot;&amp;quot;,
            &amp;quot;depth_stencil&amp;quot;: &amp;quot;Post&amp;quot;,
            &amp;quot;inputs&amp;quot;: [
                {
                    &amp;quot;name&amp;quot;: &amp;quot;BackBufferColor&amp;quot;,
                    &amp;quot;sampler&amp;quot;: &amp;quot;Point&amp;quot;,
                    &amp;quot;binding&amp;quot;: &amp;quot;input_texture&amp;quot;
                }
            ],
            &amp;quot;outputs&amp;quot;: {
                &amp;quot;rts&amp;quot;: [
                ],
                &amp;quot;depth&amp;quot;: &amp;quot;&amp;quot;,
                &amp;quot;flags&amp;quot;: &amp;quot;Common&amp;quot;,
                &amp;quot;clear_color&amp;quot;: &amp;quot;000000ff&amp;quot;
            }
        }
    ]
}
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;visualization&#34;&gt;Visualization&lt;/h2&gt;
&lt;p&gt;With all this defined, we can arrive to have something incredibly useful as this (included in the demo!):&lt;/p&gt;






&lt;figure&gt;

  &lt;a data-fancybox=&#34;&#34; href=&#34;HydraFrame.png&#34; &gt;

&lt;img src=&#34;HydraFrame.png&#34; &gt;
&lt;/a&gt;


&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;Render Pipeline&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;To me this is the quintessence of rendering: visualization.&lt;!-- raw HTML omitted --&gt;
Seeing things helps me understanding much better.&lt;!-- raw HTML omitted --&gt;
Debugging broken features, studying features, understanding dependencies, shuffling things around becomes MUCH easier.&lt;/p&gt;
&lt;h1 id=&#34;demo-and-code&#34;&gt;Demo and code&lt;/h1&gt;
&lt;p&gt;The demo loads a model, apply a silly directional light and gives you some controls, and uses the render pipeline.&lt;!-- raw HTML omitted --&gt;
It was setup during the night just to show something usable, but it is far from ideal!&lt;/p&gt;
&lt;p&gt;In the code provided there is everything I am talking here.&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;p&gt;And now some links to libraries/resources used.&lt;/p&gt;
&lt;p&gt;3 models are included from the free GLTF library:
&lt;a href=&#34;https://github.com/KhronosGroup/glTF-Sample-Models&#34;&gt;https://github.com/KhronosGroup/glTF-Sample-Models&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;TinyGLTF by &lt;a href=&#34;https://twitter.com/syoyo&#34;&gt;Syoyo Fujita&lt;/a&gt;:&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/syoyo/tinygltf&#34;&gt;https://github.com/syoyo/tinygltf&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The always present-always amazing ImGui by &lt;a href=&#34;https://twitter.com/ocornut&#34;&gt;Omar&lt;/a&gt;:
&lt;a href=&#34;https://github.com/ocornut/imgui&#34;&gt;https://github.com/ocornut/imgui&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;With the NodeEditor by &lt;a href=&#34;https://github.com/thedmd&#34;&gt;Michał Cichoń&lt;/a&gt;:
&lt;a href=&#34;https://github.com/thedmd/imgui-node-editor&#34;&gt;https://github.com/thedmd/imgui-node-editor&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;For the PBR rendering, kudos to the GREAT INFORMATIONS from &lt;a href=&#34;https://google.github.io/filament/Filament.md.html&#34;&gt;Google Filament&lt;/a&gt; and &lt;a href=&#34;https://twitter.com/romainguy&#34;&gt;Romain Guy&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Lastly, this is not anywhere near production ready, but I am still happy to share it as a knowledge building block for others.&lt;!-- raw HTML omitted --&gt;
I am thinking of making some videos for this - if you are interested let me know (both in English and Italian).&lt;/p&gt;
&lt;h1 id=&#34;conclusions&#34;&gt;Conclusions&lt;/h1&gt;
&lt;p&gt;We arrived at defining the Render Pipeline - a way of describing how a frame is rendered.&lt;!-- raw HTML omitted --&gt;
It is a very simplified version of the RenderGraph/FrameGraph - as seen in many talks - and this is something I&amp;rsquo;ve used in my home projects (and current indie game) with great success.&lt;!-- raw HTML omitted --&gt;
No mention of adding resource barriers, sharing memory, async compute and more.&lt;!-- raw HTML omitted --&gt;
The whole purpose of this article was instead to focus on the more high level architecture side.&lt;/p&gt;
&lt;p&gt;What is next ?&lt;/p&gt;
&lt;p&gt;I would write about the improvements on the HFX shader effect and would like to cleanup and make that library more robust.&lt;!-- raw HTML omitted --&gt;
Then there is the Vulkan backend to be wrote and many examples to be done. Examples could be amazing to be tutorial and develop the technology more.&lt;!-- raw HTML omitted --&gt;
Then there is talking deeper about dispatching rendering draws, render managers and such - another interesting and very unique subject in Rendering Engine architectures. In all the companies I&amp;rsquo;ve worked, I always found completely different solutions!&lt;/p&gt;
&lt;p&gt;Please comment, share, send feedback!
I am happy to answer any question and very happy to share this article.
Thanks for reading!&lt;/p&gt;
&lt;p&gt;Gabriel&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Writing a Shader Effect Language Part 3: Materials</title>
      <link>https://jorenjoestar.github.io/post/writing_shader_effect_language_3/</link>
      <pubDate>Mon, 14 Oct 2019 10:43:49 -0400</pubDate>
      
      <guid>https://jorenjoestar.github.io/post/writing_shader_effect_language_3/</guid>
      <description>&lt;h1 id=&#34;overview&#34;&gt;Overview&lt;/h1&gt;
&lt;p&gt;Data Driven Rendering Series:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://jorenjoestar.github.io/post/writing_shader_effect_language_1/&#34;&gt;https://jorenjoestar.github.io/post/writing_shader_effect_language_1/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://jorenjoestar.github.io/post/writing_shader_effect_language_2/&#34;&gt;https://jorenjoestar.github.io/post/writing_shader_effect_language_2/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://jorenjoestar.github.io/post/writing_shader_effect_language_3/&#34;&gt;https://jorenjoestar.github.io/post/writing_shader_effect_language_3/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://jorenjoestar.github.io/post/data_driven_rendering_pipeline/&#34;&gt;https://jorenjoestar.github.io/post/data_driven_rendering_pipeline/&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;In &lt;a href=&#34;https://jorenjoestar.github.io/post/writing_shader_effect_language_2/&#34;&gt;Part 2 of this series&lt;/a&gt; we added Resource Layouts and Properties to the &lt;strong&gt;HFX&lt;/strong&gt; language, trying to arrive at a point in which we can describe the rendering of a Shader Effect almost entirely.&lt;!-- raw HTML omitted --&gt;
In this article I would like to explore further adds to HFX, especially a proper &lt;strong&gt;Material System&lt;/strong&gt; to be used in conjunction with the HFX language.&lt;!-- raw HTML omitted --&gt;
I also separated the code a little bit for clarity and added the usage of STB array and hash maps.&lt;!-- raw HTML omitted --&gt;
With that I would like to develop a Material System that is robust and easy to use, even though I am (DISCLAIMER!) far from it!&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;p&gt;I will first talk about the theory and thoughts behind those changes, and then go through the code changes and addition.&lt;/p&gt;
&lt;h1 id=&#34;material-system-thoughts&#34;&gt;Material System thoughts&lt;/h1&gt;
&lt;p&gt;Following a nomenclature from the amazing guys at &lt;a href=&#34;https://ourmachinery.com/post/&#34;&gt;our_machinery&lt;/a&gt;, we are adding a &lt;em&gt;Tier 1 Shader System&lt;/em&gt; - something that builds on top of the graphics API created in the previous article.&lt;/p&gt;
&lt;p&gt;First of all, a great series of article is again on their website:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://ourmachinery.com/post/the-machinery-shader-system-part-1/&#34;&gt;https://ourmachinery.com/post/the-machinery-shader-system-part-1/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://ourmachinery.com/post/the-machinery-shader-system-part-2/&#34;&gt;https://ourmachinery.com/post/the-machinery-shader-system-part-2/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://ourmachinery.com/post/the-machinery-shader-system-part-3/&#34;&gt;https://ourmachinery.com/post/the-machinery-shader-system-part-3/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We are building a Material System based on a graphics-API that exposes the following concepts:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Buffer&lt;/li&gt;
&lt;li&gt;Texture&lt;/li&gt;
&lt;li&gt;Pipeline (that includes shaders)&lt;/li&gt;
&lt;li&gt;Render Pass&lt;/li&gt;
&lt;li&gt;Resource List Layout&lt;/li&gt;
&lt;li&gt;Resource List&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We are using a Vulkan/D3D12 interface here, and these concepts map 1 to 1 with that.&lt;!-- raw HTML omitted --&gt;
One of the big changes from a typical low-level graphics API is both the &amp;lsquo;missing&amp;rsquo; concept of Shader as a resource, and the addition of Render Pass as resource.&lt;!-- raw HTML omitted --&gt;
A new concept is the one of &lt;strong&gt;Resource List Layout&lt;/strong&gt; and &lt;strong&gt;Resource List&lt;/strong&gt;.&lt;!-- raw HTML omitted --&gt;
The Vulkan names are &lt;strong&gt;Descriptor Set Layout&lt;/strong&gt; and &lt;strong&gt;Descriptor Set&lt;/strong&gt;, but even though they reflect more the underlying driver nature of the term, I changed to &lt;strong&gt;Resource List&lt;/strong&gt; just to have it clearer as a concept.&lt;/p&gt;
&lt;p&gt;The &lt;strong&gt;King&lt;/strong&gt; here is the Pipeline: it is a structure that contains &lt;strong&gt;all the immutable data of a pipeline&lt;/strong&gt;. That includes our missing &lt;strong&gt;shaders&lt;/strong&gt;, all the &lt;strong&gt;render states&lt;/strong&gt; (DepthStencil, AlphaBlend, &amp;hellip;) and a &lt;strong&gt;Layout of the resources to be used by the shader&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Part of the &lt;strong&gt;dynamic&lt;/strong&gt; pipeline states are normally the &lt;strong&gt;geometry&lt;/strong&gt; and the &lt;strong&gt;resource lists&lt;/strong&gt;.&lt;!-- raw HTML omitted --&gt;
Note that I am using the plural here: each &lt;strong&gt;pipeline&lt;/strong&gt; can have 1 or more &lt;strong&gt;resource lists!!&lt;/strong&gt;.&lt;!-- raw HTML omitted --&gt;
This is a good to organize your resources based on update frequencies, something coming from the numerous talks about Approaching Zero Driver Overhead.&lt;/p&gt;
&lt;p&gt;Remembering the simple interface of our API, now we have the following:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;struct Device {

	...

    BufferHandle                    create_buffer( const BufferCreation&amp;amp; creation );
    TextureHandle                   create_texture( const TextureCreation&amp;amp; creation );
    PipelineHandle                  create_pipeline( const PipelineCreation&amp;amp; creation );
    SamplerHandle                   create_sampler( const SamplerCreation&amp;amp; creation );
    ResourceListLayoutHandle        create_resource_list_layout( const ResourceListLayoutCreation&amp;amp; creation );
    ResourceListHandle              create_resource_list( const ResourceListCreation&amp;amp; creation );
    RenderPassHandle                create_render_pass( const RenderPassCreation&amp;amp; creation );

    ...
};
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;If you look at the OpenGL implementation (the only I wrote for now :( ) you will find that Shaders are considered resources, but it is more for convenience of the attach/linking OpenGL need than anything else.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s finally introduce the new concept for this article!&lt;/p&gt;
&lt;h2 id=&#34;shader-effect&#34;&gt;Shader Effect&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;A &lt;strong&gt;Shader Effect&lt;/strong&gt; is the blueprint of &lt;em&gt;static&lt;/em&gt; data needed to draw something on the screen.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;It needs to include &lt;strong&gt;shaders&lt;/strong&gt; (included in a &lt;strong&gt;Pipeline Description&lt;/strong&gt;), &lt;strong&gt;properties&lt;/strong&gt; (coming from the HFX file) and find its location into a &lt;strong&gt;render graph&lt;/strong&gt;.&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;A &lt;strong&gt;Shader Effect&lt;/strong&gt; is 1 to 1 with a &lt;strong&gt;Binary HFX file&lt;/strong&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;As a convenience we will add also informations about the &lt;strong&gt;local constants&lt;/strong&gt;.&lt;!-- raw HTML omitted --&gt;
When creating a Shader Effect, we can define properties, and we put all the numerical properties into one buffer.&lt;/p&gt;
&lt;p&gt;This is the current code:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
struct ShaderEffect {

    //
    //
    struct PropertiesMap {

        char*                       key;
        hfx::ShaderEffectFile::MaterialProperty* value;

    }; // struct PropertiesMap

    struct Pass {
        PipelineCreation            pipeline_creation;
        char                        name[32];
        PipelineHandle              pipeline_handle;
        uint32_t                    pool_id;
    }; // struct Pass

    Pass*                           passes;

    uint16_t                        num_passes              = 0;
    uint16_t                        num_properties          = 0;
    uint32_t                        local_constants_size    = 0;

    char*                           local_constants_default_data = nullptr;
    char*                           properties_data         = nullptr;

    PropertiesMap*                  name_to_property        = nullptr;

    char                            name[32];
    char                            pipeline_name[32];
    uint32_t                        pool_id;

}; // struct ShaderEffect

&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;You see both a &lt;strong&gt;pipeline name&lt;/strong&gt; and an array of &lt;strong&gt;passes&lt;/strong&gt; with a name. These are to insert the pass into a very &lt;strong&gt;primordial&lt;/strong&gt; render graph, that I wrote just because I didn&amp;rsquo;t want to hardcode the frame structure, especially because next article will be EXACTLY on this topic!&lt;/p&gt;
&lt;p&gt;Having defined the Shader Effect, we can now move into the next big actor.&lt;/p&gt;
&lt;h2 id=&#34;material&#34;&gt;Material&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;A &lt;strong&gt;Material&lt;/strong&gt; is an instance of a &lt;strong&gt;Shader Effect&lt;/strong&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Given a HFX file, we generate a new file (HMT, Hydra Material) that will contain all the informations.&lt;!-- raw HTML omitted --&gt;
The concept of Material is really &lt;strong&gt;unique values for the properties of a Shader Effect&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;That is basically it.&lt;/p&gt;
&lt;p&gt;For example, if a shader contains a property like an &lt;em&gt;albedo texture&lt;/em&gt;, the material answer the question &amp;ldquo;which albedo texture?&amp;rdquo;.&lt;!-- raw HTML omitted --&gt;
This is done for every property.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s have a look at our new material:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{
    &amp;quot;name&amp;quot;: &amp;quot;SimpleFullscreen&amp;quot;,
    &amp;quot;effect_path&amp;quot;: &amp;quot;SimpleFullscreen.hfx&amp;quot;,
    &amp;quot;properties&amp;quot;: [
        {
            &amp;quot;scale&amp;quot;: 16.0,
            &amp;quot;albedo&amp;quot;: &amp;quot;AngeloCensorship.png&amp;quot;,
            &amp;quot;modulo&amp;quot;: 2.0
        }
    ],
    &amp;quot;bindings&amp;quot;: [
        {
            &amp;quot;LocalConstants&amp;quot;: &amp;quot;LocalConstants&amp;quot;,
            &amp;quot;destination_texture&amp;quot;: &amp;quot;compute_output_texture&amp;quot;,
            &amp;quot;input_texture&amp;quot;: &amp;quot;compute_output_texture&amp;quot;,
            &amp;quot;albedo_texture&amp;quot;: &amp;quot;albedo&amp;quot;
        }
    ]
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;As you can see there is a name, the effect path, the properties and the bindings. These will be explained in the next section.&lt;!-- raw HTML omitted --&gt;
Properties are just a name-value list, coming from the Shader Effect itself (the .bhfx file).&lt;/p&gt;
&lt;p&gt;The texture is my horrible drawing after reading the fantastic &lt;a href=&#34;http://c0de517e.blogspot.com/2019/08/engineering-career-guide-leaked.html&#34;&gt;rendering guide by Angelo Pesce&lt;/a&gt; and how he censored the parts that were internal to Roblox!&lt;/p&gt;
&lt;h2 id=&#34;shader-resource-database-and-lookup&#34;&gt;Shader Resource Database and Lookup&lt;/h2&gt;
&lt;p&gt;A concept that I saw only in the &lt;strong&gt;our_machinery&lt;/strong&gt; posts, but I personally adopted since a couple of years, is a way of automating a daunting task: &lt;em&gt;setting shader resources&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;I still need to finish the correct implementation of those, but the concepts are simple.&lt;!-- raw HTML omitted --&gt;
A &lt;strong&gt;Shader Resource Database&lt;/strong&gt; is a database of resources that can be searched using a &lt;strong&gt;Shader Resources Lookup&lt;/strong&gt;.&lt;!-- raw HTML omitted --&gt;
The name of the binding is the shader related name, while the value is the name into the database.&lt;!-- raw HTML omitted --&gt;
Of course you can use hashes instead of names, and compile them into a binary version of this, but this is not important now.&lt;/p&gt;
&lt;p&gt;One interesting bit (sadly not implemented here, sorry!) is the binding specialization. &lt;!-- raw HTML omitted --&gt;
This is done so that resources can be specialized in the database.&lt;!-- raw HTML omitted --&gt;
This is done per pass and it let you write only one binding list for all the Material, and then gather the proper resource based on the specialization.&lt;!-- raw HTML omitted --&gt;
For example if there is a binding for a pass-dependent resource, writing a generic version can specialize the shader pass correctly. Or using special keywords in the bindings, you can retrieve input/output textures from the render pass in which the shader is rendered!&lt;/p&gt;
&lt;p&gt;For now though it is more a manual written list, but it will be developed further.&lt;/p&gt;
&lt;h1 id=&#34;where-is-my-code-&#34;&gt;Where is my code ?&lt;/h1&gt;
&lt;p&gt;Having introduced the new concept, let&amp;rsquo;s look at the changes that happened in the last weeks of night coding.&lt;!-- raw HTML omitted --&gt;
As said before, in general I separated the code in header/cpp for clarity and building performances (after a good talk on Twitter, &lt;a href=&#34;https://twitter.com/GabrielSassone/status/1179810419617275905?s=20)&#34;&gt;https://twitter.com/GabrielSassone/status/1179810419617275905?s=20)&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;applications&#34;&gt;Applications&lt;/h2&gt;
&lt;p&gt;First big changes was separating the code from the previous articles in an &lt;em&gt;application&lt;/em&gt;: namely &lt;strong&gt;CustomShaderLanguageApplication&lt;/strong&gt; in &lt;strong&gt;CustomShaderLanguage.h/cpp&lt;/strong&gt; and &lt;strong&gt;MaterialSystemApplication&lt;/strong&gt; in &lt;strong&gt;MaterialSystem.h/cpp&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;The first contains all the application code that uses HDF and HFX, with code generation and HFX compilation.&lt;!-- raw HTML omitted --&gt;
The second contains both the new &lt;strong&gt;Material System&lt;/strong&gt; and the application that uses it.&lt;!-- raw HTML omitted --&gt;
I would love to say that is an usable app, but I really touched my limits in non designing clearly when night coding.&lt;!-- raw HTML omitted --&gt;
&lt;strong&gt;Personal note: I hope this could be the spark to create a FX Composer successor, open source and free for all!&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&#34;stb&#34;&gt;STB&lt;/h2&gt;
&lt;p&gt;As part of this experiment I wanted to try something different.&lt;!-- raw HTML omitted --&gt;
Instead of re-writing array and hash maps with templates, I wanted to give a try to the &lt;a href=&#34;https://github.com/nothings/stb&#34;&gt;STB libraries&lt;/a&gt;: namely &lt;strong&gt;stb_ds.h&lt;/strong&gt; and &lt;strong&gt;stb_image.h&lt;/strong&gt;.&lt;!-- raw HTML omitted --&gt;
Arrays and Hash Maps are now included in hydra_lib.h to be used across the code.&lt;/p&gt;
&lt;h2 id=&#34;hydra-graphics&#34;&gt;Hydra Graphics&lt;/h2&gt;
&lt;p&gt;The device added render passes and the support for multiple resources layout.&lt;!-- raw HTML omitted --&gt;
It also creates FBOs for color passes and supports resize, especially thanks to the Render Pipeline.&lt;/p&gt;
&lt;h2 id=&#34;primitive-render-graph-called-render-pipeline&#34;&gt;Primitive Render Graph (called Render Pipeline)&lt;/h2&gt;
&lt;p&gt;I use the term I used since the inception in 2010, and honestly it is more true to what it does.&lt;!-- raw HTML omitted --&gt;
It is not a graph but more a list of &lt;strong&gt;Render Stages&lt;/strong&gt; with input/outputs defined clearly.&lt;!-- raw HTML omitted --&gt;
In the next article I will develop more on this, but for now I needed some structure like this to be explicit.&lt;/p&gt;
&lt;p&gt;In the application there are 3 pipelines, one for a single pass ShaderToy shader, one for a silly compute to framebuffer shader(that for now loads a texture and outputs it to the framebuffer), and one for just a render to window.&lt;/p&gt;
&lt;p&gt;I use this in my indie project, with a fully custom and data driven (written in json) pipeline that includes compute deferred lighting and shadows, shadow passes, various post-process passes and such, everything very easy to debug and very easy to modify/add/delete.&lt;!-- raw HTML omitted --&gt;
There is a mechanism to send the correct draw calls to the correct pass through the usage of render systems, but again this will be a topic for the next article!&lt;/p&gt;
&lt;p&gt;In the included code, there is also a small but powerful tool: a pipeline explorer.&lt;!-- raw HTML omitted --&gt;
For now it will just show the render targets for each stage, and in these simple examples does not matter much.&lt;!-- raw HTML omitted --&gt;
In the next article we will dive deep into the &lt;strong&gt;Render Pipeline/Graph&lt;/strong&gt; subject and then all of this will make sense!&lt;/p&gt;
&lt;h1 id=&#34;break-a-simple-resource-manager&#34;&gt;Break: a simple Resource Manager&lt;/h1&gt;
&lt;p&gt;While being a very important topic, this is not the focus of this article.&lt;!-- raw HTML omitted --&gt;
Anyway I wanted a Resource Manager that would be helpful to handle resource creation and loading.&lt;!-- raw HTML omitted --&gt;
This includes also &lt;em&gt;resource compilation&lt;/em&gt;, something that normally happens at &lt;em&gt;build time&lt;/em&gt;, but in our exercise can be triggered at run-time.&lt;/p&gt;
&lt;p&gt;The &lt;strong&gt;resource manager&lt;/strong&gt; is a class that simply manages resources using &lt;strong&gt;factories&lt;/strong&gt; and manages dependencies between resources.&lt;!-- raw HTML omitted --&gt;
We have only 3 resources for now:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Textures&lt;/li&gt;
&lt;li&gt;Shader Effects&lt;/li&gt;
&lt;li&gt;Materials&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;resources&#34;&gt;Resources&lt;/h2&gt;
&lt;p&gt;A resource is a class that both has data and let the dependency with other data be clear.&lt;!-- raw HTML omitted --&gt;
The &lt;strong&gt;resource&amp;rsquo;s data&lt;/strong&gt; is actually a pointer to actual raw data used by other systems, in this case rendering.&lt;!-- raw HTML omitted --&gt;
Let&amp;rsquo;s see its definition:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;struct Resource {

    struct ResourceReference {
        uint8_t                     type;
        char                        path[255];
    }; // struct ResourceReference

    struct Header {

        char                        header[7];
        uint8_t                     type;   // ResourceType::enum

        size_t                      data_size;
        uint16_t                    num_external_references;
        uint16_t                    num_internal_references;
        
    }; // struct Header

    struct ResourceMap {
        char*                       key;
        Resource*                   value;
    };

    Header*                         header;
    char*                           data;
    void*                           asset;

    Resource::ResourceReference*    external_references;
    // External
    ResourceMap*                    name_to_external_resources;
    // Interal

}; // struct Resource
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;A resource is loaded from a binary file and contains a header and some data coming from the file, and an asset containing a system specific pointer.&lt;/p&gt;
&lt;p&gt;We added 3 system specific resources (Texture, Shader Effect and Material) but the class handled is always resource.&lt;!-- raw HTML omitted --&gt;
To access the system specific data, asset member is used.&lt;/p&gt;
&lt;p&gt;A resource contains also a map to the external resources loaded within it - to handle external references.&lt;/p&gt;
&lt;h2 id=&#34;compilation&#34;&gt;Compilation&lt;/h2&gt;
&lt;p&gt;Starting from a &lt;em&gt;source file&lt;/em&gt; (.hfx, .png, .hmt) using the specific factory, the resource manager compiles the code to a binary resource.&lt;!-- raw HTML omitted --&gt;
This means both converting the source format to a binary representation but also adding &lt;strong&gt;external dependencies&lt;/strong&gt; to the file.&lt;!-- raw HTML omitted --&gt;
These dependencies will be loaded when loading the resource, and before it.&lt;/p&gt;
&lt;h2 id=&#34;loading&#34;&gt;Loading&lt;/h2&gt;
&lt;p&gt;Loading happens by first loading all the dependent resources and then using the specific factory to load the &lt;em&gt;system specific&lt;/em&gt; asset.&lt;!-- raw HTML omitted --&gt;
This is a very semplicistic resource management - synchronous only, single threaded, not optimized - so really was an exercise in having something running for both compiling a resource and managing dependencies.&lt;!-- raw HTML omitted --&gt;
The whole point is the separation between a source and human-readable format to a binary one and encapsulate this.&lt;/p&gt;
&lt;p&gt;After this (very!) small break on resource management, let&amp;rsquo;s continue to the actual code for the materials!&lt;/p&gt;
&lt;h1 id=&#34;material-system-implementation&#34;&gt;Material System implementation&lt;/h1&gt;
&lt;p&gt;After all this thory let&amp;rsquo;s look at the code!&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;h2 id=&#34;shader-effect-1&#34;&gt;Shader Effect&lt;/h2&gt;
&lt;p&gt;The main parts of a &lt;strong&gt;Shader Effect&lt;/strong&gt; are &lt;strong&gt;Passes&lt;/strong&gt; and &lt;strong&gt;Properties&lt;/strong&gt;.&lt;!-- raw HTML omitted --&gt;
&lt;strong&gt;Passes&lt;/strong&gt; are the most important one, as they contain all the informations to create an actual &lt;strong&gt;Pipeline&lt;/strong&gt;, called &lt;strong&gt;Pipeline Creation&lt;/strong&gt;.&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;p&gt;Remembering the Vulkan/DX12 interface, we cannot create singularly a shader, but we need all the pipeline data (depth stencil, alpha blend, &amp;hellip;) to actually create the shaders too.&lt;/p&gt;
&lt;p&gt;The gist here is to access all those informations in a hiearchical way, basically reading them from the RenderPipeline and then overwriting with what is defined in the HFX file.&lt;/p&gt;
&lt;p&gt;Right now there is almost nothing if not the shaders, so the creation is quite simple:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;for ( uint16_t p = 0; p &amp;lt; shader_effect_file.header-&amp;gt;num_passes; p++ ) {
    hfx::ShaderEffectFile::PassHeader* pass_header = hfx::get_pass( shader_effect_file, p );

    uint32_t shader_count = pass_header-&amp;gt;num_shader_chunks;

    memcpy( effect-&amp;gt;passes[p].name, pass_header-&amp;gt;stage_name, 32 );

    PipelineCreation&amp;amp; pipeline_creation = effect-&amp;gt;passes[p].pipeline_creation;
    ShaderCreation&amp;amp; creation = pipeline_creation.shaders;
    bool compute = false;

    // Create Shaders
    for ( uint16_t i = 0; i &amp;lt; shader_count; i++ ) {
        hfx::get_shader_creation( pass_header, i, &amp;amp;creation.stages[i] );

        if ( creation.stages[i].type == ShaderStage::Compute )
            compute = true;
    }

    creation.name = pass_header-&amp;gt;name;
    creation.stages_count = shader_count;

    effect-&amp;gt;passes[p].pipeline_creation.compute = compute;

    // Create Resource Set Layouts
    for ( uint16_t l = 0; l &amp;lt; pass_header-&amp;gt;num_resource_layouts; l++ ) {

        uint8_t num_bindings = 0;
        const ResourceListLayoutCreation::Binding* bindings = get_pass_layout_bindings( pass_header, l, num_bindings );
        ResourceListLayoutCreation resource_layout_creation = { bindings, num_bindings };

        pipeline_creation.resource_list_layout[l] = context.device.create_resource_list_layout( resource_layout_creation );

    }

    pipeline_creation.num_active_layouts = pass_header-&amp;gt;num_resource_layouts;

    // Create Pipeline
    effect-&amp;gt;passes[p].pipeline_handle = context.device.create_pipeline( pipeline_creation );
    if ( effect-&amp;gt;passes[p].pipeline_handle.handle == k_invalid_handle ) {
        invalid_effect = true;
        break;
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;When we will have a proper RenderPipeline, we will get the basic pipeline creation from there, and overwrite the shaders and states that will be defined in the HFX.&lt;/p&gt;
&lt;p&gt;There are 3 main steps here:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Create Shaders&lt;/li&gt;
&lt;li&gt;Create Resource Set Layouts&lt;/li&gt;
&lt;li&gt;Create Pipelines&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;These are simple operations that rely heavily on the device.&lt;!-- raw HTML omitted --&gt;
The objective of the HFX is to embed most information possible to create a complete pipeline.&lt;/p&gt;
&lt;p&gt;Another important step is to populate the properties map:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;string_hash_init_arena( effect-&amp;gt;name_to_property );

for ( uint32_t p = 0; p &amp;lt; effect-&amp;gt;num_properties; ++p ) {
    hfx::ShaderEffectFile::MaterialProperty* property = hfx::get_property( effect-&amp;gt;properties_data, p );

    string_hash_put( effect-&amp;gt;name_to_property, property-&amp;gt;name, property );
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;We are using the STB String Hashmap here with the property that are inside the shader effect file. Those will contain the type, name for UI and the pointer to a default value. &lt;!-- raw HTML omitted --&gt;
The default value will be used based on the type of course.&lt;/p&gt;
&lt;p&gt;We are also saving the local constant buffer size, so that we can allocate some memory in the Material and alter its property using the UI.&lt;/p&gt;
&lt;p&gt;We will see the importance of this next.&lt;/p&gt;
&lt;h2 id=&#34;material-1&#34;&gt;Material&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;struct ShaderInstance {

    PipelineHandle                  pipeline;
    ResourceListHandle              resource_lists[hydra::graphics::k_max_resource_layouts];

    uint32_t                        num_resource_lists;
}; // struct ShaderInstance

struct Material {

    ShaderInstance*                 shader_instances        = nullptr;
    uint32_t                        num_instances           = 0;

    ShaderResourcesLookup           lookups; // Per-pass resource lookup. Same count as shader instances.
    ShaderEffect*                   effect                  = nullptr;

    BufferHandle                    local_constants_buffer;
    char*                           local_constants_data    = nullptr;

    const char*                     name                    = nullptr;
    StringBuffer                    loaded_string_buffer;
    
    uint32_t                        num_textures            = 0;
    uint32_t                        pool_id                 = 0;

    Texture**                       textures                = nullptr;

}; // struct Material
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This is the glue to actually render something on the screen.&lt;!-- raw HTML omitted --&gt;
As a recap, we need 3 informations to render something:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Pipeline (shaders + render states)&lt;/li&gt;
&lt;li&gt;Resources (handles to buffers and textures)&lt;/li&gt;
&lt;li&gt;Geometry (in this case a fullscreen quad)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Material gives all those informations.&lt;/p&gt;
&lt;p&gt;A &lt;strong&gt;Shader Instance&lt;/strong&gt; is defined for each &lt;strong&gt;pass&lt;/strong&gt;, and actually contains the Pipeline Handle and the &lt;strong&gt;List of Resource Lists&lt;/strong&gt; to be used.&lt;!-- raw HTML omitted --&gt;
This is one of the new concepts for Vulkan/DX12: you can use one of more lists of resources to render, and normally it is better to group them by frequency.&lt;/p&gt;
&lt;p&gt;Finally, a list of &lt;strong&gt;textures&lt;/strong&gt; is saved to be modified by the editor.&lt;/p&gt;
&lt;p&gt;To understand more the process, let&amp;rsquo;s look at the loading code of a Material.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;void* MaterialFactory::load( LoadContext&amp;amp; context ) {
    
    using namespace hydra::graphics;

    // 1. Read header from file
    MaterialFile material_file;
    material_file.header = (MaterialFile::Header*)context.data;
    material_file.property_array = (MaterialFile::Property*)(context.data + sizeof( MaterialFile::Header ));
    material_file.binding_array = (MaterialFile::Binding*)(context.data + sizeof( MaterialFile::Header ) + sizeof( MaterialFile::Property ) * material_file.header-&amp;gt;num_properties);
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;We are using the data from the material file to access properties and bindings.&lt;!-- raw HTML omitted --&gt;
Properties are both numerical and path to textures, bindings are name to retrieve resources from the database. We will look into that later.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    // 2. Read shader effect
    Resource* shader_effect_resource = string_hash_get( context.resource-&amp;gt;name_to_external_resources, material_file.header-&amp;gt;hfx_filename );
    ShaderEffect* shader_effect = shader_effect_resource ? (ShaderEffect*)shader_effect_resource-&amp;gt;asset : nullptr;
    if ( !shader_effect ) {
        return nullptr;
    }

    // 3. Search pipeline
    RenderPipeline* render_pipeline = string_hash_get( context.name_to_render_pipeline, shader_effect-&amp;gt;pipeline_name );
    if ( !render_pipeline ) {
        return nullptr;
    }

&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Access the Shader Effect through the resource dependencies, and the Render Pipeline from the map.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    // 4. Load material
    char* material_name = material_file.header-&amp;gt;name;
    uint32_t pool_id = materials_pool.obtain_resource();
    Material* material = new (materials_pool.access_resource(pool_id))Material();
    material-&amp;gt;loaded_string_buffer.init( 1024 );
    material-&amp;gt;pool_id = pool_id;

    // TODO: for now just have one lookup shared.
    material-&amp;gt;lookups.init();
    // TODO: properly specialize.
    // For each pass
    //for ( uint32_t i = 0; i &amp;lt; effect-&amp;gt;num_pipelines; i++ ) {
    //    PipelineCreation&amp;amp; pipeline = effect-&amp;gt;pipelines[i];
    //    //final ShaderBindings specializedBindings = bindings.specialize( shaderTechnique.passName, shaderTechnique.viewName );
    //    //shaderBindings.add( specializedBindings );
    //}

    material-&amp;gt;effect = shader_effect;
    material-&amp;gt;num_instances = shader_effect-&amp;gt;num_passes;
    material-&amp;gt;shader_instances = new ShaderInstance[shader_effect-&amp;gt;num_passes];
    material-&amp;gt;name = material-&amp;gt;loaded_string_buffer.append_use( material_name );
    material-&amp;gt;num_textures = material_file.header-&amp;gt;num_textures;
    material-&amp;gt;textures = (Texture**)hydra::hy_malloc( sizeof( Texture* ) * material-&amp;gt;num_textures );
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Here is the meaty part.&lt;!-- raw HTML omitted --&gt;
We create the Material, initialize a StringBuffer used to store all the names found in the file, init the db-&amp;gt;resource lookup and create the ShaderInstance array.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    // Init memory for local constants
    material-&amp;gt;local_constants_data = (char*)hydra::hy_malloc( shader_effect-&amp;gt;local_constants_size );
    // Copy default values to init to sane valuess
    memcpy( material-&amp;gt;local_constants_data, material-&amp;gt;effect-&amp;gt;local_constants_default_data, material-&amp;gt;effect-&amp;gt;local_constants_size );
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;We cached the constant data size to allocate its memory, and we copy the default values in it.
This memory will be overwritten by the other numerical properties and used to initialize the local constant buffer.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    // Add properties
    uint32_t current_texture = 0;
    for ( size_t p = 0; p &amp;lt; material_file.header-&amp;gt;num_properties; ++p ) {
        MaterialFile::Property&amp;amp; property = material_file.property_array[p];

        hfx::ShaderEffectFile::MaterialProperty* material_property = string_hash_get( material-&amp;gt;effect-&amp;gt;name_to_property, property.name );

        switch ( material_property-&amp;gt;type ) {
            case hfx::Property::Texture2D:
            {
                const char* texture_path = material-&amp;gt;loaded_string_buffer.append_use( property.data );
                Resource* texture_resource = string_hash_get( context.resource-&amp;gt;name_to_external_resources, texture_path );
                Texture* texture = (Texture*)texture_resource-&amp;gt;asset;
                texture-&amp;gt;filename = texture_path;

                render_pipeline-&amp;gt;resource_database.register_texture( property.name, texture-&amp;gt;handle );

                material-&amp;gt;textures[current_texture] = texture;

                ++current_texture;

                break;
            }

            case hfx::Property::Float:
            {
                memcpy( material-&amp;gt;local_constants_data + material_property-&amp;gt;offset, property.data, sizeof( float ) );
                break;
            }
        }
    }
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;When cycling through the properties, we are copying the numerical properties into the newly allocated memory (local_constant_data) and we load the textures from the dependencies.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;     // Add bindings
    for ( size_t b = 0; b &amp;lt; material_file.header-&amp;gt;num_bindings; ++b ) {
        MaterialFile::Binding&amp;amp; binding = material_file.binding_array[b];

        char* name = material-&amp;gt;loaded_string_buffer.append_use( binding.name );
        char* value = material-&amp;gt;loaded_string_buffer.append_use( binding.value );
        material-&amp;gt;lookups.add_binding_to_resource( name, value );
    }

&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;We populate the resource lookups.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    BufferCreation checker_constants_creation = {};
    checker_constants_creation.type = BufferType::Constant;
    checker_constants_creation.name = s_local_constants_name;
    checker_constants_creation.usage = ResourceUsageType::Dynamic;
    checker_constants_creation.size = shader_effect-&amp;gt;local_constants_size;
    checker_constants_creation.initial_data = material-&amp;gt;local_constants_data;

    material-&amp;gt;local_constants_buffer = context.device.create_buffer( checker_constants_creation );
    render_pipeline-&amp;gt;resource_database.register_buffer( (char*)s_local_constants_name, material-&amp;gt;local_constants_buffer );
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Generate the actual constant buffer.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    // Bind material resources
    update_material_resources( material, render_pipeline-&amp;gt;resource_database, context.device );
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;And finally search the bindings for the resources.&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;static void update_material_resources( hydra::graphics::Material* material, hydra::graphics::ShaderResourcesDatabase&amp;amp; database, hydra::graphics::Device&amp;amp; device ) {

    using namespace hydra::graphics;

    // Create resource list
    // Get all resource handles from the database.
    ResourceListCreation::Resource resources_handles[k_max_resources_per_list];

    // For each pass
    for ( uint32_t i = 0; i &amp;lt; material-&amp;gt;effect-&amp;gt;num_passes; i++ ) {
        PipelineCreation&amp;amp; pipeline = material-&amp;gt;effect-&amp;gt;passes[i].pipeline_creation;

        for ( uint32_t l = 0; l &amp;lt; pipeline.num_active_layouts; ++l ) {
            // Get resource layout description
            ResourceListLayoutDescription layout;
            device.query_resource_list_layout( pipeline.resource_list_layout[l], layout );

            // For each resource
            for ( uint32_t r = 0; r &amp;lt; layout.num_active_bindings; r++ ) {
                const ResourceBinding&amp;amp; binding = layout.bindings[r];

                // Find resource name
                // Copy string_buffer 
                char* resource_name = material-&amp;gt;lookups.find_resource( (char*)binding.name );

                switch ( binding.type ) {
                    case hydra::graphics::ResourceType::Constants:
                    case hydra::graphics::ResourceType::Buffer:
                    {
                        BufferHandle handle = resource_name ? database.find_buffer( resource_name ) : device.get_dummy_constant_buffer();
                        resources_handles[r].handle = handle.handle;

                        break;
                    }

                    case hydra::graphics::ResourceType::Texture:
                    case hydra::graphics::ResourceType::TextureRW:
                    {
                        TextureHandle handle = resource_name ? database.find_texture( resource_name ) : device.get_dummy_texture();
                        resources_handles[r].handle = handle.handle;

                        break;
                    }

                    default:
                    {
                        break;
                    }
                }
            }

            ResourceListCreation creation = { pipeline.resource_list_layout[l], resources_handles, layout.num_active_bindings };
            material-&amp;gt;shader_instances[i].resource_lists[l] = device.create_resource_list( creation );
        }
        material-&amp;gt;shader_instances[i].num_resource_lists = pipeline.num_active_layouts;
        material-&amp;gt;shader_instances[i].pipeline = material-&amp;gt;effect-&amp;gt;passes[i].pipeline_handle;
    }
}

&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;For each Pass, Resource Layout and Binding, we search the Database to retrieve the actual resource and create the Resource List.&lt;/p&gt;
&lt;p&gt;This can be improved - having a global database of resources and a &amp;lsquo;local&amp;rsquo; one based on material resources.&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    // 5. Bind material to pipeline
    for ( uint8_t p = 0; p &amp;lt; shader_effect-&amp;gt;num_passes; ++p ) {
        char* stage_name = shader_effect-&amp;gt;passes[p].name;
        hydra::graphics::RenderStage* stage = string_hash_get( render_pipeline-&amp;gt;name_to_stage, stage_name );

        if ( stage ) {
            stage-&amp;gt;material = material;
            stage-&amp;gt;pass_index = (uint8_t)p;
        }
    }

    return material;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Finally, and this is hacky, we assing the current material and pass index to the found stage.&lt;!-- raw HTML omitted --&gt;
Once we have the real Render Pipeline/Graph working, we will use another dispatching mechanism.&lt;/p&gt;
&lt;h1 id=&#34;rendering-of-a-material&#34;&gt;Rendering of a Material&lt;/h1&gt;
&lt;p&gt;After all of this we finally have created a Material.&lt;!-- raw HTML omitted --&gt;
But how can we render it ?&lt;!-- raw HTML omitted --&gt;
The magic here happens in a &lt;strong&gt;Render Pipeline&lt;/strong&gt;!&lt;!-- raw HTML omitted --&gt;
A Render Pipeline is a list of Render Stages and some resources with it. In this case resources are the &lt;strong&gt;render targets&lt;/strong&gt; and the &lt;strong&gt;buffers&lt;/strong&gt; that are shared amongst &lt;strong&gt;Stages&lt;/strong&gt; (and Render Systems in the future).&lt;!-- raw HTML omitted --&gt;
Resources are inside a &lt;strong&gt;Shader Resources Database&lt;/strong&gt; and they can be retrieved using a &lt;strong&gt;Shader Resource Lookup&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Each &lt;strong&gt;Render Stage&lt;/strong&gt; has defined a list of input and output textures plus some resize data. This data is needed to recreate textures when a resize event arrives if needed, or change size if an option is changed (like a Shadow Map resolution option).&lt;!-- raw HTML omitted --&gt;
As everthing in this articles, this is primordial and simple, but I think is a very good start, especially from a mindset perspective.&lt;/p&gt;
&lt;p&gt;In this simple scenario we render 1 material only, and normally it simply 1 &lt;em&gt;Material Pass&lt;/em&gt; for each &lt;em&gt;Render Stage Pass&lt;/em&gt;, rendering either using a fullscreen quad or through compute.&lt;/p&gt;
&lt;p&gt;There are 2 pipelines, both simple and used as a test, one is for a &lt;em&gt;ShaderToy&lt;/em&gt; shader that I use as test, the other as a compute only pipeline. They are both hardcoded and created at the beginning of the &lt;em&gt;Material Application&lt;/em&gt;, but as said before, it should be data-driven and reloadable to have great rendering power.&lt;/p&gt;
&lt;h2 id=&#34;rendering-of-a-pipeline&#34;&gt;Rendering of a Pipeline&lt;/h2&gt;
&lt;p&gt;The code is simple:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;void RenderPipeline::render( CommandBuffer* commands ) {

    for ( size_t i = 0; i &amp;lt; string_hash_length( name_to_stage ); i++ ) {

        RenderStage* stage = name_to_stage[i].value;
        stage-&amp;gt;begin( commands );
        stage-&amp;gt;render( commands );
        stage-&amp;gt;end( commands );
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;We cycle through each stage and render.&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;void RenderStage::begin( CommandBuffer* commands ) {
    commands-&amp;gt;begin_submit( 0 );
    commands-&amp;gt;begin_pass( render_pass );
    commands-&amp;gt;set_viewport( { 0, 0, (float)current_width, (float)current_height, 0.0f, 1.0f } );
    if ( clear_rt ) {
        commands-&amp;gt;clear( clear_color[0], clear_color[1], clear_color[2], clear_color[3] );
    }
    commands-&amp;gt;end_submit();
    // Set render stage states (depth, alpha, ...)
}

&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Before rendering anything this code will bind the correct FBO/Render Targets, clear and set viewport and set render states.&lt;!-- raw HTML omitted --&gt;
After this we are ready to render the actual stage. In this simple implementation we have only 3 type of stages: Compute, Post and Swapchain.&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;p&gt;They are very simple and similar, like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;commands-&amp;gt;begin_submit( pass_index );
commands-&amp;gt;bind_pipeline( shader_instance.pipeline );
commands-&amp;gt;bind_resource_list( &amp;amp;shader_instance.resource_lists[0], shader_instance.num_resource_lists );
commands-&amp;gt;draw( graphics::TopologyType::Triangle, 0, 3 );
commands-&amp;gt;end_submit();
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Set the pipeline, bind all the different resource lists and issue the draw (in this case a full screen triangle).&lt;/p&gt;
&lt;h1 id=&#34;included-in-the-code&#34;&gt;Included in the code&lt;/h1&gt;
&lt;h2 id=&#34;material-application&#34;&gt;Material application&lt;/h2&gt;
&lt;p&gt;I just added a simple Material Application to render the content of one of those simple shaders.&lt;/p&gt;
&lt;p&gt;Honestly not very happy about the code quality - and you can see why trying to add big features like memory management or multi-threading is a no-go.&lt;/p&gt;
&lt;p&gt;The application let you switch between &lt;strong&gt;materials&lt;/strong&gt; by right clicking on the &lt;strong&gt;.hmt&lt;/strong&gt; file.&lt;!-- raw HTML omitted --&gt;
The whole purpose is to explore with the given code a couple of materials and their dependencies.&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.shadertoy.com/view/XlfGRj&#34;&gt;Starnest&lt;/a&gt; is a shader by the amazing &lt;a href=&#34;https://www.deviantart.com/fractkali&#34;&gt;&lt;strong&gt;Pablo Roman Andrioli&lt;/strong&gt;&lt;/a&gt;, so all credits are to him! I wanted something beautiful to show in this simple example from ShaderToy.&lt;/p&gt;
&lt;h1 id=&#34;conclusions-and-some-thoughts&#34;&gt;Conclusions and some thoughts&lt;/h1&gt;
&lt;p&gt;We added a simple material system based on our HFX language.&lt;!-- raw HTML omitted --&gt;
Interestingly enough code generation is used much less - if almost nothing - instead of serializing data into files and using them.&lt;!-- raw HTML omitted --&gt;
As stated in the other articles, the goal is to have a parsing and code generation knowledge under your belt, and understand when it is time to use it!&lt;!-- raw HTML omitted --&gt;
We also introduced a lot of connections to other topics that are lengthy enough - like resource management - that need more time and dedication to properly be explored.&lt;!-- raw HTML omitted --&gt;
I am continuing working on this until it will become my &lt;em&gt;rendering explorer&lt;/em&gt; - a tool I can use to easily explore ideas, much like &lt;strong&gt;ShaderToy&lt;/strong&gt; but in an even more powerful way.&lt;!-- raw HTML omitted --&gt;
How ?&lt;!-- raw HTML omitted --&gt;
In the next article we will explore the final piece of the puzzle, and then we will probably start iterating and improving on what we have!&lt;!-- raw HTML omitted --&gt;
We will see how we can describe a frame and the rendering dependencies in an easy way, especially if done since the beginning, and how much having that knowledge upfront is GREAT to work on rendering.&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;p&gt;I am honestly not happy about the overall architecture though - here you have an example of &lt;em&gt;exploring code&lt;/em&gt; - code written to explore a specific subject, and after venturing more into it you want to rewrite it.&lt;!-- raw HTML omitted --&gt;
To properly rewrite it you need to create solid foundations - namely &lt;strong&gt;Memory Management, Multi-Threading, Basic Data Structures, &amp;hellip;&lt;/strong&gt; and choose to pick your battles!&lt;/p&gt;
&lt;p&gt;This is a huge lesson: pick your battles, choose what to concentrate on.&lt;!-- raw HTML omitted --&gt;
These articles are more towards code generation and rendering, but defining the constraints of the articles helps in narrowing down what to do.&lt;!-- raw HTML omitted --&gt;
If, as I would like, you want to use this code to evolve into something like a &amp;lsquo;desktop&amp;rsquo; Shadertoy, then you can&amp;rsquo;t ignore all the foundational topics.&lt;!-- raw HTML omitted --&gt;
On the other end if you just quickly want to experiment with those topics, this should suffice.&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;p&gt;I have two paths here: rewriting most of this code with a solid foundations, and delaying a RenderPipeline/Graph article, or finishing with this architecture and then re-write everything with the &amp;lsquo;desktop Shadertoy&amp;rsquo;.&lt;!-- raw HTML omitted --&gt;
Again, pick your battles :)&lt;/p&gt;
&lt;p&gt;As always, please comment, feedback, share!&lt;!-- raw HTML omitted --&gt;
I really hope soon there will be some &lt;em&gt;rendering joy&lt;/em&gt;!&lt;/p&gt;
&lt;p&gt;Gabriel&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Writing a Shader Effect Language Part 2</title>
      <link>https://jorenjoestar.github.io/post/writing_shader_effect_language_2/</link>
      <pubDate>Wed, 11 Sep 2019 00:42:13 -0400</pubDate>
      
      <guid>https://jorenjoestar.github.io/post/writing_shader_effect_language_2/</guid>
      <description>&lt;h1 id=&#34;overview&#34;&gt;Overview&lt;/h1&gt;
&lt;p&gt;Data Driven Rendering Series:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://jorenjoestar.github.io/post/writing_shader_effect_language_1/&#34;&gt;https://jorenjoestar.github.io/post/writing_shader_effect_language_1/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://jorenjoestar.github.io/post/writing_shader_effect_language_2/&#34;&gt;https://jorenjoestar.github.io/post/writing_shader_effect_language_2/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://jorenjoestar.github.io/post/writing_shader_effect_language_3/&#34;&gt;https://jorenjoestar.github.io/post/writing_shader_effect_language_3/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://jorenjoestar.github.io/post/data_driven_rendering_pipeline/&#34;&gt;https://jorenjoestar.github.io/post/data_driven_rendering_pipeline/&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;In &lt;a href=&#34;https://jorenjoestar.github.io/post/writing_shader_effect_language_1/&#34;&gt;Part 1 of this series&lt;/a&gt; we created a simple &lt;em&gt;language&lt;/em&gt; to work as &amp;lsquo;shader effect&amp;rsquo; - a shader language superset to make our life easier, by adding missing features.&lt;!-- raw HTML omitted --&gt;
The fact that there is not an industry standard for a shader effect language leads to either hand-crafted (and secret) languages, or to hardcoded permutations, or to other gray-area solutions.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;(Personal though: part of me would like to help in contributing to the creation of a standard through these articles and code.)&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;What is the &lt;strong&gt;goal&lt;/strong&gt; of this article ?&lt;/p&gt;
&lt;p&gt;The &lt;strong&gt;goal&lt;/strong&gt; is to enrich the &lt;strong&gt;HFX language&lt;/strong&gt; to generate more code possible and/or bake data for us, namely:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Shader constants generation&lt;/li&gt;
&lt;li&gt;Shader resource bindings&lt;/li&gt;
&lt;li&gt;Render states (depth stencil, blend, rasterization)&lt;/li&gt;
&lt;li&gt;Render pass hints for a future framegraph&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;We will see Render States and Render Pass hints in a following article, because this is an already lengthy article!&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;I hope that by now the way of adding an identifier, parsing it and generating code is clearer.&lt;!-- raw HTML omitted --&gt;
In this article we will focus more on the features than anything else, even though I will put a lot of code still.&lt;!-- raw HTML omitted --&gt;
But before that, we need to have a big addition to our example: a rendering API!&lt;!-- raw HTML omitted --&gt;
We will use this as target of our code generation, and it will be an amazing example to see something working.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Maybe this will spark a new FX Composer ?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;This article will be divided in 2 parts.&lt;!-- raw HTML omitted --&gt;
Part 1 of this article will talk about the rendering API.&lt;!-- raw HTML omitted --&gt;
Part 2 will be about the extended HFX language.&lt;!-- raw HTML omitted --&gt;
If you are not interested in that, jump to part 2 of this article.&lt;/p&gt;
&lt;h1 id=&#34;part-1-adding-a-low-level-rendering-api&#34;&gt;Part 1: adding a low-level rendering API&lt;/h1&gt;
&lt;p&gt;Writing articles on rendering without some sort of API to use is tricky.&lt;!-- raw HTML omitted --&gt;
Creating a language to speed up data driven rendering, either for generating code and/or for baking data &lt;em&gt;needs&lt;/em&gt; a target API.&lt;!-- raw HTML omitted --&gt;
The main idea is to have an abstract API to map more easily rendering concepts instead of losing ourselves in specific API needs.&lt;/p&gt;
&lt;h2 id=&#34;the-search-for-an-abstract-api&#34;&gt;The search for an abstract API&lt;/h2&gt;
&lt;p&gt;The first thing to do is to search for an existing abstract API.&lt;!-- raw HTML omitted --&gt;
I have few criteria in mind:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Simple and clear interface&lt;/li&gt;
&lt;li&gt;Compact and clear code&lt;/li&gt;
&lt;li&gt;Vulkan and D3D12 interface&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;With those in mind, I found 2 alternatives: &lt;a href=&#34;https://github.com/bkaradzic/bgfx&#34;&gt;BGFX&lt;/a&gt; and &lt;a href=&#34;https://github.com/floooh/sokol&#34;&gt;Sokol&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I am an honest fan of both, they are brilliant, robust and well written.&lt;!-- raw HTML omitted --&gt;
But for the purpose of these articles, sadly they miss my search criteria.&lt;!-- raw HTML omitted --&gt;
There is also a &lt;strong&gt;huge disclaimer&lt;/strong&gt; here: I used them too little, so it is possible I overlooked the usage of them.&lt;!-- raw HTML omitted --&gt;
I will be more than glad to use either instead of my toy API!&lt;!-- raw HTML omitted --&gt;
I respect the developers and the library a lot, they are doing an amazing job!&lt;!-- raw HTML omitted --&gt;
But we are handcrafting something, and to properly do that I personally need to know deeply the code. And I am not.&lt;/p&gt;
&lt;p&gt;BGFX is very complete, but the interface is a little confusing for me, possibly because I never used it but just read the code few times.&lt;!-- raw HTML omitted --&gt;
The main reason I chose not to use it is because the interface is missing the resource interface like Vulkan and D3D12 (DescriptorSets, &amp;hellip;), otherwise it would have been an amazing choice.&lt;/p&gt;
&lt;p&gt;Sokol is also very good, I love the code and the simple interface.&lt;!-- raw HTML omitted --&gt;
Two main problems here: again no Vulkan/D3D12 resource interface, and in this case a different target: it does not support compute shaders.&lt;/p&gt;
&lt;p&gt;Again, I want to make it clear: I am not saying these are not good libraries. They are amazing. They just don&amp;rsquo;t fit my search criteria, plus I LOVE to work on rendering architecture. Well actually, it is my favourite job!&lt;/p&gt;
&lt;p&gt;So kudos to them (I also wrote to Andre Weissflog to ask for compute shader support, but it is not in his plans for now) but we are making a different choice.&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;p&gt;If you ever find anything that I write useful guys, please let me know!&lt;/p&gt;
&lt;h2 id=&#34;hydra-graphics-design-principles&#34;&gt;Hydra Graphics: design principles&lt;/h2&gt;
&lt;p&gt;Small trivia: the name comes from my first ever graphics engine written in 2006 (I think), after devouring 3D Game Engine Design by Dave Eberly. I already knew I would write many engines and I would learn and grow stronger from every of them, so I chose the name Hydra from the Greek mythology monster.&lt;!-- raw HTML omitted --&gt;
The other name would have been Phoenx engine, but I remember finding already some tech with that name.&lt;/p&gt;
&lt;p&gt;Anyway, design principles!&lt;!-- raw HTML omitted --&gt;
I really loved the interface of Sokol, and often I used something similar by myself.&lt;!-- raw HTML omitted --&gt;
I opted for a pair of header/implementation files as the only needed files.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The backend is OpenGL for now, just because I have a working implementation in my indie project that works with pretty complex rendering, and I can use that as reference.&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;interface&#34;&gt;Interface&lt;/h3&gt;
&lt;p&gt;Rendering in general is a matter of creating, modifying and combining &lt;em&gt;resources&lt;/em&gt;.&lt;!-- raw HTML omitted --&gt;
There are mainly 2 classes that do all the rendering work:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Device&lt;/li&gt;
&lt;li&gt;Command Buffer&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;em&gt;The Device is responsible for creation, destruction, modification and query of the resources.&lt;!-- raw HTML omitted --&gt;
The Command Buffer is responsible for the usage of resources for rendering.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;The obvious fundamental concept is &lt;strong&gt;resource&lt;/strong&gt;.&lt;!-- raw HTML omitted --&gt;
A &lt;strong&gt;resource&lt;/strong&gt; is handled externally through handles, can be created using &lt;strong&gt;creation&lt;/strong&gt; structs and has both a common and an API-specific representation.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Buffers&lt;/strong&gt; are specialized in vertex/index/constant/&amp;hellip; depending on their creation parameters.&lt;/p&gt;
&lt;p&gt;This is a small example on creation/usage/destruction of a resource.&lt;!-- raw HTML omitted --&gt;
First, we can create a texture:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;graphics::TextureCreation first_rt = {};
first_rt.width = 512;
first_rt.height = 512;
first_rt.render_target = 1;
first_rt.format = graphics::TextureFormat::R8G8B8A8_UNORM;

TextureHandle render_target = gfx_device.create_texture( first_rt );
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Next we can create a command buffer:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;CommandBuffer* commands = gfx_device.get_command_buffer( graphics::QueueType::Graphics, 1024 );
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Skipping other creations, we bind resources and add the commands:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;commands-&amp;gt;bind_pipeline( first_graphics_pipeline );
commands-&amp;gt;bind_resource_set( gfx_resources );
commands-&amp;gt;bind_vertex_buffer( gfx_device.get_fullscreen_vertex_buffer() );
commands-&amp;gt;draw( graphics::TopologyType::Triangle, 0, 3 );
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;At this point we can execute the command buffer to draw.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;gfx_device.execute_command_buffer( commands );
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Updating a resource can be done like that:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;hydra::graphics::MapBufferParameters map_parameters = { buffer.handle, 0, 0 };
LocalConstants* buffer_data = (LocalConstants*)device.map_buffer( map_parameters );
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Everything uses structs to perform creation/updates.&lt;!-- raw HTML omitted --&gt;
Nothing new, but I always loved this design.&lt;/p&gt;
&lt;h3 id=&#34;resource-layout-and-resource-lists&#34;&gt;Resource layout and resource lists&lt;/h3&gt;
&lt;p&gt;I wanted to bring the Vulkan/D3D12 resource interface as first class citizens, and remove completely old concepts (like single constants, render states as single objects, single bind of a resource) and add new ones: resource layout, resource lists and command buffers. Well command buffers are not new, but &lt;em&gt;finally&lt;/em&gt; you can draw only with those!&lt;/p&gt;
&lt;p&gt;In Vulkan/D3D12 you can bind resources through the usage of &lt;em&gt;sets&lt;/em&gt;: basically tables that contains the resources used.&lt;!-- raw HTML omitted --&gt;
This is a welcomed difference from previous APIs, and I think it is a concept not too hard to grasp but very useful to have it explicit.&lt;/p&gt;
&lt;p&gt;The first thing to define is the &lt;strong&gt;resource layout&lt;/strong&gt; describes the layout of a set of resources.&lt;!-- raw HTML omitted --&gt;
For example, if we have a material that uses Albedo and Normals textures and a constant buffer, the layout will contain all the informations about that (like the type, the GPU registers and so on).&lt;!-- raw HTML omitted --&gt;
This though still does not contain the resources themselves!&lt;!-- raw HTML omitted --&gt;
Enter &lt;strong&gt;resource list&lt;/strong&gt;.&lt;!-- raw HTML omitted --&gt;
A &lt;strong&gt;resource list&lt;/strong&gt; is a list of actual resources &lt;em&gt;relative to a layout&lt;/em&gt;.&lt;!-- raw HTML omitted --&gt;
It sets resources using a layout.&lt;/p&gt;
&lt;p&gt;From now on, when we draw we can bind &lt;em&gt;one or more resource lists&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;In Vulkan lingo, the &lt;strong&gt;resource layout&lt;/strong&gt; is called &lt;strong&gt;descriptor set layout&lt;/strong&gt;, and a &lt;strong&gt;resource list&lt;/strong&gt; is a &lt;strong&gt;descriptor set&lt;/strong&gt;.&lt;!-- raw HTML omitted --&gt;
Here are a couple of articles for the Vulkan side:&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://vulkan.lunarg.com/doc/view/1.0.33.0/linux/vkspec.chunked/ch13s02.html&#34;&gt;Official Vulkan Documentation on Descriptor Layouts and Sets&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://software.intel.com/en-us/articles/api-without-secrets-introduction-to-vulkan-part-6&#34;&gt;Intel API Without Secrets Part 6&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Similarly in D3D12 there are Root Tables and Descriptor Tables. The concepts do no map 1 to 1 but they are pretty similar:&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://docs.microsoft.com/en-us/windows/win32/direct3d12/using-descriptor-tables&#34;&gt;D3D12 Descriptor Tables&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I tried to map these concepts using different words that would make more sense to me, so from &lt;em&gt;Descriptor Set&lt;/em&gt; or &lt;em&gt;Root Table&lt;/em&gt; it became &lt;em&gt;Resource List&lt;/em&gt; and &lt;em&gt;Resource Layout&lt;/em&gt;.&lt;/p&gt;
&lt;h3 id=&#34;pipelines&#34;&gt;Pipelines&lt;/h3&gt;
&lt;p&gt;Finally a pipeline is the complete description of what is needed by the GPU to draw something on the screen (or to use a Compute Shader for any other purpose).&lt;!-- raw HTML omitted --&gt;
Basically a pipeline must fill all the informations for all the GPU stages like this (thanks to &lt;a href=&#34;https://renderdoc.org&#34;&gt;RenderDoc&lt;/a&gt;):&lt;/p&gt;






&lt;figure&gt;

  &lt;a data-fancybox=&#34;&#34; href=&#34;RenderDoc_Pipeline.png&#34; &gt;

&lt;img src=&#34;RenderDoc_Pipeline.png&#34; &gt;
&lt;/a&gt;


&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;RenderDoc Pipeline&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;What once was setup individually now is all in one place (reflecting what happened behind the scene, into the driver).&lt;!-- raw HTML omitted --&gt;
DepthStencil, AlphaBlend, Rasterization, Shaders, all must be defined here.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;In the currrent implementation of the graphics-API a lot of states are still missing!&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Now that we say the basic principles of the target rendering API, we can finally concentrate on the new freatures of HFX.&lt;/p&gt;
&lt;h1 id=&#34;part-2-forging-the-hfx-language-features&#34;&gt;Part 2: forging the HFX language features&lt;/h1&gt;
&lt;p&gt;Our HFX language needs some properties to be added but first there is a change: HFX will generate a binary version to embed all the informations needed to create a shader.&lt;/p&gt;
&lt;h2 id=&#34;hfx-evolution-what-files-are-generated-&#34;&gt;HFX evolution: what files are generated ?&lt;/h2&gt;
&lt;p&gt;In the previous article, we used a single HFX file to generate multiple glsl files, ready to be used by any OpenGL renderer:&lt;/p&gt;






&lt;figure&gt;

  &lt;a data-fancybox=&#34;&#34; href=&#34;HFX_Shader_Gen.png&#34; &gt;

&lt;img src=&#34;HFX_Shader_Gen.png&#34; &gt;
&lt;/a&gt;


&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;Shader Generation&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;Remembering the article on &lt;a href=&#34;https://jorenjoestar.github.io/post/writing_a_simple_code_generator/&#34;&gt;Hydra Data Format&lt;/a&gt;, we instead were generating an header file.&lt;!-- raw HTML omitted --&gt;
For our needs, we will generate an embedded HFX (binary HFX) AND a C++ header:&lt;/p&gt;






&lt;figure&gt;

  &lt;a data-fancybox=&#34;&#34; href=&#34;HFX_Gen.png&#34; &gt;

&lt;img src=&#34;HFX_Gen.png&#34; &gt;
&lt;/a&gt;


&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;Binary and Header Generation&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;What is the next step for HFX ?&lt;!-- raw HTML omitted --&gt;
For shader generation, we want ideally to load a HFX file without having to manually stick together the single shader files, and that is why the first step is to create &lt;strong&gt;embedded HFX files&lt;/strong&gt;.&lt;!-- raw HTML omitted --&gt;
This will contain all the information to create a shader, and this includes also the resource layouts.&lt;/p&gt;
&lt;p&gt;For constant handling, we want to have UI generated and easy update on the gpu. We want to automate these things.&lt;!-- raw HTML omitted --&gt;
This can be done in a more code-generated way or by generating data.&lt;/p&gt;
&lt;p&gt;If we abstract the problem, all these articles are about understanding how you want to generate code or data to maximise iteration time, performances and control.&lt;!-- raw HTML omitted --&gt;
By moving the HFX to being binary, we are effectively generating &lt;em&gt;data&lt;/em&gt; used by the renderer.&lt;!-- raw HTML omitted --&gt;
For the shader UI, we can do both: generate code or create data. We will see the generated code part here.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s see briefly the internals of the &lt;strong&gt;Embedded HFX&lt;/strong&gt; file format:&lt;/p&gt;
&lt;h3 id=&#34;embedded-hfx&#34;&gt;Embedded HFX&lt;/h3&gt;
&lt;p&gt;As a Recap, when &lt;em&gt;parsing&lt;/em&gt; HFX we store some informations.&lt;/p&gt;
&lt;p&gt;First is the CodeFragment, including also (spoiler!) the addition of resources for the sake of this article:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// C++
//
struct CodeFragment {

    struct Resource {
        
        hydra::graphics::ResourceType::Enum type;
        StringRef               name;

    }; // struct Resource

    std::vector&amp;lt;StringRef&amp;gt;      includes;
    std::vector&amp;lt;Stage&amp;gt;          includes_stage;     // Used to separate which include is in which shader stage.
    std::vector&amp;lt;Resource&amp;gt;       resources;          // Used to generate the layout table.

    StringRef                   name;
    StringRef                   code;
    Stage                       current_stage       = Stage::Count;
    uint32_t                    ifdef_depth         = 0;
    uint32_t                    stage_ifdef_depth[Stage::Count];

}; // struct CodeFragment
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The rest is unchanged from the previous article.&lt;!-- raw HTML omitted --&gt;
We have basically code and includes to bake the final shader.&lt;!-- raw HTML omitted --&gt;
Remember, we are handling GLSL in these examples!&lt;/p&gt;
&lt;p&gt;Next is the Pass:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// C++
//
struct Pass {

    StringRef                   name;
    struct ShaderStage {

        const CodeFragment*     code                = nullptr;
        Stage                   stage               = Stage::Count;

    }; // struct ShaderStage

    StringRef                   name;
    std::vector&amp;lt;ShaderStage&amp;gt;    shader_stages;

}; // struct Pass
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Nothing changed here.&lt;!-- raw HTML omitted --&gt;
A pass is a container of one of more shaders.&lt;!-- raw HTML omitted --&gt;
In general we will use the term &lt;em&gt;shader state&lt;/em&gt; to describe the shaders that needs to be bound to the pipeline.&lt;!-- raw HTML omitted --&gt;
Most common are the couple Vertex and Fragment shaders, or the Compute by itself.&lt;/p&gt;
&lt;p&gt;Last is the Shader itself:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// C++
//
struct Shader {

    StringRef                   name;

    std::vector&amp;lt;Pass*&amp;gt;          passes;
    std::vector&amp;lt;Property*&amp;gt;      properties;

}; // struct Shader
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Being just a collection of passes.&lt;!-- raw HTML omitted --&gt;
Again we are seeing the properties here, that I will talk later on in the article.&lt;/p&gt;
&lt;p&gt;These will be used to &amp;lsquo;bake&amp;rsquo; data into a &amp;lsquo;bhfx&amp;rsquo; (binary HFX) file.&lt;/p&gt;
&lt;h3 id=&#34;bhfx-layout&#34;&gt;BHFX layout&lt;/h3&gt;
&lt;p&gt;In order to maximise efficiency, we are packing the data in the way we will use it.&lt;!-- raw HTML omitted --&gt;
The file is divided in two main sections: common and passes.&lt;!-- raw HTML omitted --&gt;
The overall layout is as follows:&lt;/p&gt;






&lt;figure&gt;

  &lt;a data-fancybox=&#34;&#34; href=&#34;BHFX_Format.png&#34; &gt;

&lt;img src=&#34;BHFX_Format.png&#34; &gt;
&lt;/a&gt;

&lt;/figure&gt;

&lt;p&gt;The trick is to have the offset for each section easy to access.&lt;/p&gt;
&lt;p&gt;The &lt;em&gt;pass section&lt;/em&gt; contains several informations as following:&lt;/p&gt;






&lt;figure&gt;

  &lt;a data-fancybox=&#34;&#34; href=&#34;BHFX_Pass.png&#34; &gt;

&lt;img src=&#34;BHFX_Pass.png&#34; &gt;
&lt;/a&gt;

&lt;/figure&gt;

&lt;p&gt;As we will see later we include shaders, resources layout and other data based on our target API (Hydra Graphics).&lt;/p&gt;
&lt;h3 id=&#34;writing-the-bhfx-file&#34;&gt;Writing the BHFX file&lt;/h3&gt;
&lt;p&gt;To write our file, we need to parse the HFX file.&lt;!-- raw HTML omitted --&gt;
A quick code could be something like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// C++
//

...

char* text = ReadEntireFileIntoMemory( &amp;quot;..\\data\\SimpleFullscreen.hfx&amp;quot;, nullptr );
initLexer( &amp;amp;lexer, (char*)text, data_buffer );

hfx::initParser( &amp;amp;effect_parser, &amp;amp;lexer );
hfx::generateAST( &amp;amp;effect_parser );

    
hfx::initCodeGenerator( &amp;amp;hfx_code_generator, &amp;amp;effect_parser, 4096, 5 );

hfx::compileShaderEffectFile( &amp;amp;hfx_code_generator, &amp;quot;..\\data\\&amp;quot;, &amp;quot;SimpleFullscreen.bhfx&amp;quot; );
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Here we are parsing the file (generateAST) and then using that to &lt;em&gt;compile&lt;/em&gt; our shader effect file. This is where the magic happens.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// C++
//
void compileShaderEffectFile( CodeGenerator* code_generator, const char* path, const char* filename ) {
    // Create the output file
    FILE* output_file;

    // Alias the StringBuffer for better readability.
    StringBuffer&amp;amp; filename_buffer = code_generator-&amp;gt;string_buffers[0];

    // Concatenate name
    filename_buffer.clear();
    filename_buffer.append( path );
    filename_buffer.append( filename );
    fopen_s( &amp;amp;output_file, filename_buffer.data, &amp;quot;wb&amp;quot; );

    if ( !output_file ) {
        printf( &amp;quot;Error opening file. Aborting. \n&amp;quot; );
        return;
    }
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Typical file creation preamble.&lt;!-- raw HTML omitted --&gt;
Concatenate the file using the StringBuffer, and try to create it.&lt;/p&gt;
&lt;p&gt;Remember that overall the file structure is:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;File header&lt;/li&gt;
&lt;li&gt;Pass offset list&lt;/li&gt;
&lt;li&gt;Pass sections&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Let&amp;rsquo;s start with the file header:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    const uint32_t pass_count = (uint32_t)code_generator-&amp;gt;parser-&amp;gt;passes.size();
    
    ShaderEffectFile shader_effect_file;
    shader_effect_file.num_passes = pass_count;    

    fwrite( &amp;amp;shader_effect_file, sizeof(ShaderEffectFile), 1, output_file );
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;In this case we are writing straight to the file, because it is an in-order operation with the file layout.&lt;!-- raw HTML omitted --&gt;
For the rest of the file writing we will need to use String Buffers to accumulate data out-of-order and then write the file in the correct order.&lt;!-- raw HTML omitted --&gt;
Think of the &lt;em&gt;Pass Offset List&lt;/em&gt;: to calculate the offsets we need to know the size of the passes. To know the size we need to finalize the pass data. To finalize the pass data we need to finalize shaders, and that means adding the includes.&lt;/p&gt;
&lt;p&gt;Again for code clarity I use aliases like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    StringBuffer&amp;amp; code_buffer = code_generator-&amp;gt;string_buffers[1];
    StringBuffer&amp;amp; pass_offset_buffer = code_generator-&amp;gt;string_buffers[2];
    StringBuffer&amp;amp; shader_offset_buffer = code_generator-&amp;gt;string_buffers[3];
    StringBuffer&amp;amp; pass_buffer = code_generator-&amp;gt;string_buffers[4];
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Let&amp;rsquo;s continue.&lt;!-- raw HTML omitted --&gt;
We start tracking the pass section memory offset knowing that it will be after the &lt;em&gt;header&lt;/em&gt; and the pass offset list:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    pass_offset_buffer.clear();
    pass_buffer.clear();

    // Pass memory offset starts after header and list of passes offsets.
    uint32_t pass_offset = sizeof( ShaderEffectFile ) + sizeof(uint32_t) * pass_count;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Now into the most interesting part. We will avoid talking about the resource layout part, that will be added later.&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    // Pass Section:
    // ----------------------------------------------------------------------------------------
    // Shaders count | Name | Shader Offset+Count List | Shader Code 0, Shader Code 1
    // ----------------------------------------------------------------------------------------

    ShaderEffectFile::PassHeader pass_header;

    for ( uint32_t i = 0; i &amp;lt; pass_count; i++ ) {

        pass_offset_buffer.append( &amp;amp;pass_offset, sizeof( uint32_t ) );

        const Pass&amp;amp; pass = code_generator-&amp;gt;parser-&amp;gt;passes[i];

        const uint32_t pass_shader_stages = (uint32_t)pass.shader_stages.size();
        const uint32_t pass_header_size = pass_shader_stages * sizeof( ShaderEffectFile::Chunk ) + sizeof( ShaderEffectFile::PassHeader );
        uint32_t current_shader_offset = pass_header_size;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;We start iterating the passes and calculate the shader offset.&lt;!-- raw HTML omitted --&gt;
Shader Chunks (the actual shader code) are written after the Pass Header and the dynamic list of shader chunk offset and size.&lt;!-- raw HTML omitted --&gt;
Next we will calculate the offsets of the single shaders AFTER we finalize the code - that means after the includes are added!&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;        shader_offset_buffer.clear();
        code_buffer.clear();

        for ( size_t s = 0; s &amp;lt; pass.shader_stages.size(); ++s ) {
            const Pass::ShaderStage shader_stage = pass.shader_stages[s];

            appendFinalizedCode( path, shader_stage.stage, shader_stage.code, filename_buffer, code_buffer, true, constants_buffer );
            updateOffsetTable( &amp;amp;current_shader_offset, pass_header_size, shader_offset_buffer, code_buffer );
        }

        // Update pass offset
        pass_offset += code_buffer.current_size + shader_offset;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;At this point we have code_buffer containing all the shaders of the pass one after another (null terminated) and we can update the pass offset for the next pass.&lt;!-- raw HTML omitted --&gt;
We also calculated the single shader offsets with the &lt;em&gt;updateOffsetTable&lt;/em&gt; method in shader_offset_buffer.&lt;!-- raw HTML omitted --&gt;
We need to finalize the Pass Header and then we can merge the pass memory in one block and proceed to the next pass:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;        // Fill Pass Header
        copy( pass.name, pass_header.name, 32 );
        pass_header.num_shader_chunks = pass.num_shaders;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This is a very IMPORTANT part.&lt;!-- raw HTML omitted --&gt;
Merge in the pass_buffer all the pass section currently calculated: pass header, the single shader code offsets and the shader code itself.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;        pass_buffer.append( (void*)&amp;amp;pass_header, sizeof( ShaderEffectFile::PassHeader ) );
        pass_buffer.append( shader_offset_buffer );
        pass_buffer.append( code_buffer );
    }
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;After we finished with all the passes, we have 2 buffers: one containing the pass offset list, the other the pass sections.&lt;!-- raw HTML omitted --&gt;
We can write them off in the correct order finally and close the file:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    fwrite( pass_offset_buffer.data, pass_offset_buffer.current_size, 1, output_file );
    fwrite( pass_buffer.data, pass_buffer.current_size, 1, output_file );
    
    fclose( output_file );
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;We can see &lt;em&gt;why&lt;/em&gt; we chose this format when looking at the code to actually create a &lt;em&gt;shader state&lt;/em&gt;.&lt;!-- raw HTML omitted --&gt;
First of all this is the struct to create a shader state:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// hydra_graphics.h
//
struct ShaderCreation {

    struct Stage {

        ShaderStage::Enum           type                = ShaderStage::Compute;
        const char*                 code                = nullptr;

    }; // struct Stage

    const Stage*                    stages              = nullptr;
    const char*                     name                = nullptr;

    uint32_t                        stages_count        = 0;

}; // struct ShaderCreation
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;It is very simple, each stage has a code and type.&lt;!-- raw HTML omitted --&gt;
A shader state can have one or more stages.&lt;!-- raw HTML omitted --&gt;
This was already the case in OpenGL - compiling shaders and linking them - so the interface is similar - but it maps well to Vulkan/D3D12 as well, in which the &lt;em&gt;Pipeline State&lt;/em&gt;, that describe almost everything the GPU needs to draw, needs an unique set of vertex/fragment/compute shaders.&lt;!-- raw HTML omitted --&gt;
Anyway, we embed this data already in the &lt;em&gt;binary HFX file&lt;/em&gt;, and thus we can easily create a shader state like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;static void compile_shader_effect_pass( hydra::graphics::Device&amp;amp; device, char* hfx_memory, 
                                        uint16_t pass_index, hydra::graphics::ShaderHandle&amp;amp; out_shader ) {
    using namespace hydra;

    // Get pass section memory
    char* pass = hfx::getPassMemory( hfx_memory, pass_index );
    hfx::ShaderEffectFile::PassHeader* pass_header = (hfx::ShaderEffectFile::PassHeader*)pass;

    const uint32_t shader_count = pass_header-&amp;gt;num_shader_chunks;    
    graphics::ShaderCreation::Stage* stages = new graphics::ShaderCreation::Stage[shader_count];

    // Get individual shader code and type
    for ( uint16_t i = 0; i &amp;lt; shader_count; i++ ) {
        hfx::getShaderCreation( shader_count, pass, i, &amp;amp;stages[i] );
    }

    graphics::ShaderCreation first_shader = {};
    first_shader.stages = stages;
    first_shader.stages_count = shader_count;
    first_shader.name = pass_header-&amp;gt;name;

    out_shader = device.create_shader( first_shader );

    delete stages;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Nothing really interesting here, but we read the file in memory and use the offsets we store to access the different sections of the file.&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;p&gt;To access the &lt;em&gt;Pass Section&lt;/em&gt; we first need to read its memory offset and then read from there.&lt;!-- raw HTML omitted --&gt;
Remember from before that the offset is in the list AFTER the ShaderEffectFile header, and it is a single uint32:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;char* getPassMemory( char* hfx_memory, uint32_t index ) {
    
    // Read offset form list after the ShaderEffectFile header.
    const uint32_t pass_offset = *(uint32_t*)(hfx_memory + sizeof( ShaderEffectFile ) + (index * sizeof( uint32_t )));

    return hfx_memory + pass_offset;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;From the &lt;em&gt;pass offset&lt;/em&gt;, the list of shader chunks (that are defined as code offset and size) is right after the &lt;em&gt;pass header&lt;/em&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;void getShaderCreation( uint32_t shader_count, char* pass_memory, uint32_t index,
                        hydra::graphics::ShaderCreation::Stage* shader_creation ) {

    char* shader_offset_list_start = pass_memory + sizeof( ShaderEffectFile::PassHeader );
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Read the single shader offset and access the memory there:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    const uint32_t shader_offset = *(uint32_t*)(shader_offset_list_start + (index * sizeof( ShaderEffectFile::Chunk )));
    char* shader_chunk_start = pass_memory + shader_offset;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The baked informations are first the type (as a single char, but called hfx::ShaderEffectFile::ChunkHeader in case we change it) and the actual shader code is right after!&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    shader_creation-&amp;gt;type = (hydra::graphics::ShaderStage::Enum)(*shader_chunk_start);
    shader_creation-&amp;gt;code = (const char*)(shader_chunk_start + sizeof( hfx::ShaderEffectFile::ChunkHeader ));
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;In this case I chose to bake the file instead of generating a header file - just cause I can reuse this code for every shader effect. I could have generated an header instead of the binary BHFX file, but then including it would mean that you need to recompile at every change.&lt;!-- raw HTML omitted --&gt;
We will see some areas in which we can have both approaches!&lt;/p&gt;
&lt;p&gt;Finally done with the new embedded format, let&amp;rsquo;s see the new features!&lt;/p&gt;
&lt;h2 id=&#34;brainstorming-what-features-are-needed-&#34;&gt;Brainstorming: what features are needed ?&lt;/h2&gt;
&lt;p&gt;We already talked about the features at the beginning of the articles, but let&amp;rsquo;s write them again to refresh our memory:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Shader constants generation&lt;/li&gt;
&lt;li&gt;Shader resource bindings&lt;/li&gt;
&lt;li&gt;Render states (depth stencil, blend, rasterization) &lt;strong&gt;(in the next article)&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Render pass hints for a future framegraph &lt;strong&gt;(in the next article)&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;There are few articles around this subject, but the most complete is from the amazing guys at &lt;a href=&#34;https://ourmachinery.com/&#34;&gt;OurMachinery&lt;/a&gt;, and in particular &lt;a href=&#34;https://ourmachinery.com/post/the-machinery-shader-system-part-2/&#34;&gt;this article&lt;/a&gt;.&lt;!-- raw HTML omitted --&gt;
These guys does (as always honestly) an amazing job in describing the problem we are facing and the solutions, and how enriching a shader language can make a huge difference in making better rendering (faster iteration time, less error prone, more artist friendly..) so I would suggest to read those articles (and in general any article/presentation/blog post they write!).&lt;/p&gt;
&lt;p&gt;We will go through each feature in depth so get ready!&lt;/p&gt;
&lt;h2 id=&#34;constants-artists-programmers-both-&#34;&gt;Constants: artists, programmers, both ?&lt;/h2&gt;
&lt;p&gt;Constants&amp;hellip;uniforms&amp;hellip;whatever name you choose, they represent the same concept: &lt;em&gt;numerical properties&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Even if they are a simple concept, still it is hard to make both rendering citizens happy: artists and programmers!&lt;/p&gt;
&lt;p&gt;Artists want tweakable UI, simple variables and fast iteration.&lt;!-- raw HTML omitted --&gt;
Programmers want optimal layout, more CPU calculated variables possible, and ultimate control.&lt;!-- raw HTML omitted --&gt;
How to make them both happy ?&lt;/p&gt;
&lt;p&gt;I brainstormed and designed for few days (well evenings) to solve this problem.&lt;!-- raw HTML omitted --&gt;
One thought that came to me is that artists want to create a &lt;em&gt;material interface&lt;/em&gt;, something they can tweak and change easily, and when you want to quickly prototype something, create and such, you don&amp;rsquo;t want to deal with low-level resource management and such.&lt;!-- raw HTML omitted --&gt;
Let&amp;rsquo;s solve this first: &lt;strong&gt;give artists a simple way of creating a material interface&lt;/strong&gt;!&lt;/p&gt;
&lt;p&gt;After searching for a bit, I chose to use a syntax very similar to Unity ShaderLab. Let&amp;rsquo;s see the HFX (finally!):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// .HFX
//
// For the artist: create a material interface.
properties {

    // Using Unity ShaderLab syntax:
    // AORemapMin0(&amp;quot;AORemapMin0&amp;quot;, Range(0.0, 1.0)) = 0.0
    scale(&amp;quot;Scale&amp;quot;, Float) = 32.00
    modulo(&amp;quot;Modulo&amp;quot;, Float) = 2.0
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;We added a new section in the language, named &amp;ldquo;&lt;em&gt;properties&lt;/em&gt;&amp;rdquo;.&lt;!-- raw HTML omitted --&gt;
Why this name ?&lt;!-- raw HTML omitted --&gt;
Because properties contains both &lt;em&gt;numerical properties and textures&lt;/em&gt;!&lt;!-- raw HTML omitted --&gt;
The name makes sense in this way. Naming &amp;lsquo;constants&amp;rsquo; and having also textures, not.&lt;/p&gt;
&lt;p&gt;There are 2 possible &lt;em&gt;outputs&lt;/em&gt; from this, one that is pure code-generation and the other that is more data-driven.
I will dwelve into the code-generation one and talk about the data-driven one in another post.&lt;/p&gt;
&lt;p&gt;There are 3 parts for the generated code of the properties:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Properties UI&lt;/li&gt;
&lt;li&gt;GPU-ready constant buffer&lt;/li&gt;
&lt;li&gt;API-dependant buffer&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;For the Properties UI, we want to generate something like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// C++
struct LocalConstantsUI {

    float                    scale                = 32.000000f;
    float                    modulo                = 2.000000f;

    void reflectMembers() {
        ImGui::InputScalar( &amp;quot;Scale&amp;quot;, ImGuiDataType_Float, &amp;amp;scale);
        ImGui::InputScalar( &amp;quot;Modulo&amp;quot;, ImGuiDataType_Float, &amp;amp;modulo);
    }

    void reflectUI() {
        ImGui::Begin( &amp;quot;LocalConstants&amp;quot; );
        reflectMembers();
        ImGui::End();
    }

}; // struct LocalConstantsUI
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;For the GPU-ready constants, we want to have a both a GPU and a CPU representation like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// C++
//
struct LocalConstants {

    float                    scale                = 32.000000f;
    float                    modulo                = 2.000000f;
    float                    pad_tail[2];

}; // struct LocalConstants

// GLSL
//
layout (std140, binding=7) uniform LocalConstants {

    float                    scale;
    float                    modulo;

    float                    pad[2];

} local_constants;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;And for the API-dependant buffer, we want to create code that takes care of everything for us. This is the real deal here - and something we will revisit in next articles to show some advanced features.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;void create( hydra::graphics::Device&amp;amp; device ) {

    using namespace hydra;

    graphics::BufferCreation constants_creation = {};
    constants_creation.type = graphics::BufferType::Constant;
    constants_creation.name = &amp;quot;LocalConstants&amp;quot;;
    constants_creation.usage = graphics::ResourceUsageType::Dynamic;

    // NOTE: using LocalConstants struct - is the GPU ready one with padding and such!
    constants_creation.size = sizeof( LocalConstants );
    // Struct is initialized with default values already, so it is safe to copy it to the GPU.
    constants_creation.initial_data = &amp;amp;constants;

    buffer = device.create_buffer( constants_creation );
}

void destroy( hydra::graphics::Device&amp;amp; device ) {

    device.destroy_buffer( buffer );
}

void updateUI( hydra::graphics::Device&amp;amp; device ) {
    // Draw UI
    constantsUI.reflectUI();

    // TODO:
    // Ideally there should be a way to tell if a variable has changed and update only in that case.
    
    // Map buffer to GPU and upload parameters from the UI
    hydra::graphics::MapBufferParameters map_parameters = { buffer.handle, 0, 0 };

    LocalConstants* buffer_data = (LocalConstants*)device.map_buffer( map_parameters );

    if ( buffer_data ) {
        buffer_data-&amp;gt;scale = constantsUI.scale;
        buffer_data-&amp;gt;modulo = constantsUI.modulo;
        device.unmap_buffer( map_parameters );
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;For the sake of the example this could be a possible implementation - but really depends on the rendering API.
Let&amp;rsquo;s quickly check parsing and code-generation.&lt;/p&gt;
&lt;h3 id=&#34;constants-parsing&#34;&gt;Constants Parsing&lt;/h3&gt;
&lt;p&gt;To parse the new &lt;strong&gt;property&lt;/strong&gt; section, there is the new method &lt;code&gt;void declarationProperties( Parser* parser )&lt;/code&gt; that iterates through all properties, and inside that the &lt;code&gt;void declarationProperty( Parser* parser, const StringRef&amp;amp; name )&lt;/code&gt; one.&lt;/p&gt;
&lt;p&gt;We are parsing the following HFX syntax:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// Syntax
//
identifier(string, identifier[(arguments)]) [= default_value]
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;With this is an example:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// HFX
//
properties {
    scale(&amp;quot;Scale&amp;quot;, Float) = 32.0
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;We will add a simple backtracking to the parsing because of the optional parameters.&lt;!-- raw HTML omitted --&gt;
Let&amp;rsquo;s check the code!&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;inline void declarationProperty( Parser* parser, const StringRef&amp;amp; name ) {
    Property* property = new Property();

    // Cache name
    property-&amp;gt;name = name;

    Token token;

    if ( !expectToken( parser-&amp;gt;lexer, token, Token::Token_OpenParen ) ) {
        return;
    }
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;We just parsed the property name and the &amp;lsquo;(&amp;rsquo;. Next is the string containing the UI name:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    // Advance to the string representing the ui_name
    if ( !expectToken( parser-&amp;gt;lexer, token, Token::Token_String ) ) {
        return;
    }

    property-&amp;gt;ui_name = token.text;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Saved the ui name and then we have the type.&lt;!-- raw HTML omitted --&gt;
Types can be &lt;em&gt;Float, Int, Range, Texture, Vector, Color&lt;/em&gt; and we will simply parse their text and convert it to an enum that we will use in the code generation phase.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    if ( !expectToken( parser-&amp;gt;lexer, token, Token::Token_Comma ) ) {
        return;
    }

    // Next is the identifier representing the type name
    if ( !expectToken( parser-&amp;gt;lexer, token, Token::Token_Identifier ) ) {
        return;
    }

    // Parse property type and convert it to an enum
    property-&amp;gt;type = propertyTypeIdentifier( token );
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Now will come the most complicated part.&lt;!-- raw HTML omitted --&gt;
We have optional &amp;lsquo;(&amp;rsquo; open parenthesis for the parameters if the type needs it.&lt;!-- raw HTML omitted --&gt;
For the length of code and article, I skip this part and will add it in next article!&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    // If an open parenthesis is present, then parse the ui arguments.
    nextToken( parser-&amp;gt;lexer, token );
    if ( token.type == Token::Token_OpenParen ) {
        property-&amp;gt;ui_arguments = token.text;

        while ( !equalToken( parser-&amp;gt;lexer, token, Token::Token_CloseParen ) ) {
            // TODO:
            // Parse parameters!
        }

        // Advance to the last close parenthesis
        nextToken( parser-&amp;gt;lexer, token );

        property-&amp;gt;ui_arguments.length = token.text.text - property-&amp;gt;ui_arguments.text;
    }

    if ( !checkToken( parser-&amp;gt;lexer, token, Token::Token_CloseParen ) ) {
        return;
    }
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;At this point we can either be at the end of the property or we could have a &amp;lsquo;=&amp;rsquo; token to add a default value.
Being that the Lexer class is small, we can backtrack by saving the current Lexer status:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    // Cache lexer status and advance to next token.
    // If the token is &#39;=&#39; then we parse the default value.
    // Otherwise backtrack by one token.
    Lexer cached_lexer = *parser-&amp;gt;lexer;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Now we can advance to the next token and:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;If the token is &amp;lsquo;=&amp;rsquo;, parse the default value.&lt;/li&gt;
&lt;li&gt;If not, backtrack the position of the Lexer and finish the parsing.&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;    nextToken( parser-&amp;gt;lexer, token );

    // At this point only the optional default value is missing, otherwise the parsing is over.
    if ( token.type == Token::Token_Equals ) {
        nextToken( parser-&amp;gt;lexer, token );
        
        if ( token.type = Token::Token_Number ) {
            // Cache the data buffer entry index into the property for later retrieval.
            property-&amp;gt;data_index = parser-&amp;gt;lexer-&amp;gt;data_buffer-&amp;gt;current_entries - 1;
        }
        else {
            // TODO:
            // Handle vectors, colors and non single number default values
        }
    }
    else {
        *parser-&amp;gt;lexer = cached_lexer;
    }

    parser-&amp;gt;shader.properties.push_back( property );
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;An interesting point is that the &lt;em&gt;numbers&lt;/em&gt; are parsed in a &lt;strong&gt;DataBuffer&lt;/strong&gt;, and during the parsing of the token we will add the number to it.&lt;!-- raw HTML omitted --&gt;
To retrieve it, we have the &lt;code&gt;data_index&lt;/code&gt; field of the &lt;code&gt;Property&lt;/code&gt; struct.&lt;!-- raw HTML omitted --&gt;
Also here, for the sake of &amp;lsquo;brevity&amp;rsquo;, I am handling only floats and ints. Vectors, colors and texture property should be easy to add.&lt;/p&gt;
&lt;p&gt;For vectors and colors we should parse a list of them and save them into the data buffer.&lt;/p&gt;
&lt;p&gt;For textures we should just save the default value as text and use it in the code-generation part.&lt;/p&gt;
&lt;h3 id=&#34;code-generation&#34;&gt;Code Generation&lt;/h3&gt;
&lt;p&gt;This should be pretty straight forward.&lt;!-- raw HTML omitted --&gt;
We can iterate the properties and generate both a C++ struct and a HLSL/GLSL buffer.&lt;!-- raw HTML omitted --&gt;
The only thing to be concerned is the padding: on the GPU normally the alignment is 16 bytes, so we can track that and insert padding when generating the code.&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;p&gt;In the method &lt;code&gt;void generateShaderResourceHeader( CodeGenerator* code_generator, const char* path )&lt;/code&gt; we can see how we generate the different code for C++:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// C++
//
// Beginning

fprintf( output_file, &amp;quot;\n#pragma once\n#include &amp;lt;stdint.h&amp;gt;\n#include \&amp;quot;hydra_graphics.h\&amp;quot;\n\n// This file is autogenerated!\nnamespace &amp;quot; );

fwrite( shader.name.text, shader.name.length, 1, output_file );
fprintf( output_file, &amp;quot; {\n\n&amp;quot; );

// Preliminary sections
constants_ui.append( &amp;quot;struct LocalConstantsUI {\n\n&amp;quot; );

cpu_constants.append( &amp;quot;struct LocalConstants {\n\n&amp;quot; );

constants_ui_method.append(&amp;quot;\tvoid reflectMembers() {\n&amp;quot;);

buffer_class.append( &amp;quot;struct LocalConstantsBuffer {\n\n\thydra::graphics::BufferHandle\tbuffer;\n&amp;quot; );
buffer_class.append( &amp;quot;\tLocalConstants\t\t\t\t\tconstants;\n\tLocalConstantsUI\t\t\t\tconstantsUI;\n\n&amp;quot; );
buffer_class.append( &amp;quot;\tvoid create( hydra::graphics::Device&amp;amp; device ) {\n\t\tusing namespace hydra;\n\n&amp;quot; );
buffer_class.append( &amp;quot;\t\tgraphics::BufferCreation constants_creation = { graphics::BufferType::Constant, graphics::ResourceUsageType::Dynamic, sizeof( LocalConstants ), &amp;amp;constants, \&amp;quot;LocalConstants\&amp;quot; };\n&amp;quot; );
buffer_class.append( &amp;quot;\t\tbuffer = device.create_buffer( constants_creation );\n\t}\n\n&amp;quot; );
buffer_class.append( &amp;quot;\tvoid destroy( hydra::graphics::Device&amp;amp; device ) {\n\t\tdevice.destroy_buffer( buffer );\n\t}\n\n&amp;quot; );
buffer_class.append( &amp;quot;\tvoid updateUI( hydra::graphics::Device&amp;amp; device ) {\n\t\t// Draw UI\n\t\tconstantsUI.reflectUI();\n\t\t// Update constants from UI\n&amp;quot; );
buffer_class.append( &amp;quot;\t\thydra::graphics::MapBufferParameters map_parameters = { buffer.handle, 0, 0 };\n&amp;quot; );
buffer_class.append( &amp;quot;\t\tLocalConstants* buffer_data = (LocalConstants*)device.map_buffer( map_parameters );\n\t\tif (buffer_data) {\n&amp;quot; );

// For GPU the struct must be 16 bytes aligned. Track alignment
uint32_t gpu_struct_alignment = 0;

DataBuffer* data_buffer = code_generator-&amp;gt;parser-&amp;gt;lexer-&amp;gt;data_buffer;
// For each property write code
for ( size_t i = 0; i &amp;lt; shader.properties.size(); i++ ) {
    hfx::Property* property = shader.properties[i];

    switch ( property-&amp;gt;type ) {
        case Property::Float:
        {
            constants_ui.append(&amp;quot;\tfloat\t\t\t\t\t&amp;quot;);
            constants_ui.append( property-&amp;gt;name );

            cpu_constants.append( &amp;quot;\tfloat\t\t\t\t\t&amp;quot; );
            cpu_constants.append( property-&amp;gt;name );
            
            if ( property-&amp;gt;data_index != 0xffffffff ) {
                float value = 0.0f;
                getData( data_buffer, property-&amp;gt;data_index, value );
                constants_ui.append( &amp;quot;\t\t\t\t= %ff&amp;quot;, value );
                cpu_constants.append( &amp;quot;\t\t\t\t= %ff&amp;quot;, value );
            }

            constants_ui.append( &amp;quot;;\n&amp;quot; );

            cpu_constants.append( &amp;quot;;\n&amp;quot; );

            constants_ui_method.append(&amp;quot;\t\tImGui::InputScalar( \&amp;quot;&amp;quot;);
            constants_ui_method.append( property-&amp;gt;ui_name );
            constants_ui_method.append( &amp;quot;\&amp;quot;, ImGuiDataType_Float, &amp;amp;&amp;quot; );
            constants_ui_method.append( property-&amp;gt;name );
            constants_ui_method.append( &amp;quot;);\n&amp;quot; );

            // buffer_data-&amp;gt;scale = constantsUI.scale;
            buffer_class.append(&amp;quot;\t\t\tbuffer_data-&amp;gt;&amp;quot;);
            buffer_class.append( property-&amp;gt;name );
            buffer_class.append( &amp;quot; = constantsUI.&amp;quot; );
            buffer_class.append( property-&amp;gt;name );
            buffer_class.append( &amp;quot;;\n&amp;quot; );

            ++gpu_struct_alignment;

            break;
        }
    }
}

// Post-property sections
constants_ui.append( &amp;quot;\n&amp;quot; );

constants_ui_method.append( &amp;quot;\t}\n\n&amp;quot; );
constants_ui_method.append( &amp;quot;\tvoid reflectUI() {\n\t\tImGui::Begin( \&amp;quot;LocalConstants\&amp;quot; );\n&amp;quot; );
constants_ui_method.append( &amp;quot;\t\treflectMembers();\n\t\tImGui::End();\n\t}\n\n&amp;quot; );
constants_ui_method.append( &amp;quot;}; // struct LocalConstantsUI\n\n&amp;quot; );

// Add tail padding data
uint32_t tail_padding_size = 4 - (gpu_struct_alignment % 4);
cpu_constants.append( &amp;quot;\tfloat\t\t\t\t\tpad_tail[%u];\n\n&amp;quot;, tail_padding_size );

cpu_constants.append( &amp;quot;}; // struct LocalConstants\n\n&amp;quot; );

buffer_class.append( &amp;quot;\t\t\tdevice.unmap_buffer( map_parameters );\n\t\t}\n\t}\n}; // struct LocalConstantBuffer\n\n&amp;quot; );

fwrite( constants_ui.data, constants_ui.current_size, 1, output_file );
fwrite( constants_ui_method.data, constants_ui_method.current_size, 1, output_file );
fwrite( cpu_constants.data, cpu_constants.current_size, 1, output_file );
fwrite( buffer_class.data, buffer_class.current_size, 1, output_file );


// End
fprintf( output_file, &amp;quot;} // namespace &amp;quot; );
fwrite( shader.name.text, shader.name.length, 1, output_file );
fprintf( output_file, &amp;quot;\n\n&amp;quot; );

fclose( output_file );
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This piece of code will generate a constant buffer from the properties:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// GLSL
//
static void generateConstantsCode( const Shader&amp;amp; shader, StringBuffer&amp;amp; out_buffer ) {
    if ( !shader.properties.size() ) {
        return;
    }

    // Add the local constants into the code.
    out_buffer.append( &amp;quot;\n\t\tlayout (std140, binding=7) uniform LocalConstants {\n\n&amp;quot; );

    // For GPU the struct must be 16 bytes aligned. Track alignment
    uint32_t gpu_struct_alignment = 0;

    const std::vector&amp;lt;Property*&amp;gt;&amp;amp; properties = shader.properties;
    for ( size_t i = 0; i &amp;lt; shader.properties.size(); i++ ) {
        hfx::Property* property = shader.properties[i];

        switch ( property-&amp;gt;type ) {
            case Property::Float:
            {
                out_buffer.append( &amp;quot;\t\t\tfloat\t\t\t\t\t&amp;quot; );
                out_buffer.append( property-&amp;gt;name );
                out_buffer.append( &amp;quot;;\n&amp;quot; );

                ++gpu_struct_alignment;
                break;
            }
        }
    }

    uint32_t tail_padding_size = 4 - (gpu_struct_alignment % 4);
    out_buffer.append( &amp;quot;\t\t\tfloat\t\t\t\t\tpad_tail[%u];\n\n&amp;quot;, tail_padding_size );
    out_buffer.append( &amp;quot;\t\t} local_constants;\n\n&amp;quot; );
}
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;expert-constants-an-interesting-problem&#34;&gt;Expert constants: an interesting problem&lt;/h3&gt;
&lt;p&gt;A problem many times surfaces is that the material interface does not correspond to the buffer sent to the GPU, because the programmers will do the following:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Add &lt;em&gt;system&lt;/em&gt; constants, that don&amp;rsquo;t need a UI&lt;/li&gt;
&lt;li&gt;Change order of the constants&lt;/li&gt;
&lt;li&gt;Change constants to more GPU friendly values, calculating some stuff on the CPU&lt;/li&gt;
&lt;li&gt;Pack constants into smaller ones&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This is an interesting topic and I&amp;rsquo;ll cover it in another article, but a simple solution would be to add a mapping between the GPU constants and the UI, so that we can separate the UI constants from the GPU ones.&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;ll give a brief example but it would be too much for this article and will not be included in the source code.&lt;/p&gt;
&lt;p&gt;Basically we are trying to create a mapping between the material interface:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// C++
struct LocalConstantsUI {

    float                    scale                = 32.000000f;
    float                    modulo                = 2.000000f;

    void reflectMembers() {
        ImGui::InputScalar( &amp;quot;Scale&amp;quot;, ImGuiDataType_Float, &amp;amp;scale);
        ImGui::InputScalar( &amp;quot;Modulo&amp;quot;, ImGuiDataType_Float, &amp;amp;modulo);
    }

    void reflectUI() {
        ImGui::Begin( &amp;quot;LocalConstants&amp;quot; );
        reflectMembers();
        ImGui::End();
    }

}; // struct LocalConstantsUI
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;And the GPU constants:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// C++
struct LocalConstants {

    float                    scale                = 32.000000f;
    float                    modulo                = 2.000000f;
    float                    pad_tail[2];

}; // struct LocalConstants
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;We could enhance HFX with some syntax to mark the &lt;em&gt;derivate&lt;/em&gt; properties and just add the &lt;em&gt;system&lt;/em&gt; ones in an explicit buffer layout, and add a &lt;em&gt;layout&lt;/em&gt; section in the HFX:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// HFX

properties {

    // Using Unity ShaderLab syntax:
    scale(&amp;quot;Scale&amp;quot;, Range(0.0, 100.0)) = 100.0
    modulo(&amp;quot;Modulo&amp;quot;, Float) = 2.0
}

layout {
    CBuffer LocalConstants {
        float4x4            world_view_projection;    // &#39;System&#39; variable

        float               scale01 = (scale);       // Silly normalized version of scale interface property
        float               modulo;
        float               pad[2];
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;we could completely override the automatic constant buffer generation from the properties.&lt;!-- raw HTML omitted --&gt;
With this we can:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Add a system variable like &lt;em&gt;world_view_projection&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Flag the property &lt;strong&gt;scale&lt;/strong&gt; as UI only, by saying that property &lt;strong&gt;scale01&lt;/strong&gt; uses it.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I think that with this syntax both artists and programmers can be happy together!&lt;!-- raw HTML omitted --&gt;
I will try to work on this on a later article.&lt;/p&gt;
&lt;h2 id=&#34;resource-bindings-vulkan-and-d3d12-mentality&#34;&gt;Resource bindings: Vulkan and D3D12 mentality&lt;/h2&gt;
&lt;p&gt;As stated multiple times, the shift in mentality is towards the new APIs, and that includes the concept of &lt;strong&gt;resource lists&lt;/strong&gt;.&lt;!-- raw HTML omitted --&gt;
The problem is that we don&amp;rsquo;t want artists to have to handle this kind of things - especially if you want to quickly prototype things!&lt;!-- raw HTML omitted --&gt;
But at the same time, we want programmers to have the possibility to optimize the shaders the artists gave them.&lt;!-- raw HTML omitted --&gt;
What is the solution?&lt;!-- raw HTML omitted --&gt;
Simple: creating an optional &lt;em&gt;resource layout&lt;/em&gt; section and &lt;strong&gt;automatically&lt;/strong&gt; generate it if not present, so that artists (and not only) can happily create amazing tech and THEN worry about these details!&lt;/p&gt;
&lt;h3 id=&#34;automatic-resource-layout&#34;&gt;Automatic Resource Layout&lt;/h3&gt;
&lt;p&gt;The easiest way to handle resource layout is to make them &lt;strong&gt;SIMPLE&lt;/strong&gt;. Remember the &lt;strong&gt;K.I.S.S. principle&lt;/strong&gt;.&lt;!-- raw HTML omitted --&gt;
In this case it means that we can create a Resource List for each pass, that will contain:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;One constant/uniform buffer containing all the properties&lt;/li&gt;
&lt;li&gt;All the textures used by the shader&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;How can we achieve that ?&lt;/p&gt;
&lt;p&gt;We already saw how we can generate the constant buffer from the properties in the previous section.
For textures we have a couple of options.&lt;/p&gt;
&lt;h4 id=&#34;list-of-textures&#34;&gt;List of Textures&lt;/h4&gt;
&lt;p&gt;Being in automation land, there are 2 ways to add texture dependencies:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Use reflection mechanism from the target shader language&lt;/li&gt;
&lt;li&gt;Parse identifiers in the current finalized shader&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;For the sake of fun we will look into the second of course!&lt;!-- raw HTML omitted --&gt;
If we go back to &lt;code&gt;void declarationGlsl( Parser* parser )&lt;/code&gt;, we can add a new method to parse the keyword:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// Parse hash for includes and defines
if ( token.type == Token::Token_Hash ) {
    // Get next token and check which directive is
    nextToken( parser-&amp;gt;lexer, token );

    directiveIdentifier( parser, token, code_fragment );
}
else if ( token.type == Token::Token_Identifier ) {        &amp;lt;------------  New Code!

    // Parse uniforms to add resource dependencies if not explicit in the HFX file.
    if ( expectKeyword( token.text, 7, &amp;quot;uniform&amp;quot; ) ) {
        nextToken( parser-&amp;gt;lexer, token );

        uniformIdentifier( parser, token, code_fragment );
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;In this way it will search for the identifier &lt;em&gt;uniform&lt;/em&gt; and search for the other identifiers. This is GLSL centric of course.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;inline void uniformIdentifier( Parser* parser, const Token&amp;amp; token, CodeFragment&amp;amp; code_fragment ) {
    for ( uint32_t i = 0; i &amp;lt; token.text.length; ++i ) {
        char c = *(token.text.text + i);

        switch ( c ) {
            case &#39;i&#39;:
            {
                if ( expectKeyword( token.text, 7, &amp;quot;image2D&amp;quot; ) ) {
                    // Advance to next token to get the name
                    Token name_token;
                    nextToken( parser-&amp;gt;lexer, name_token );

                    CodeFragment::Resource resource = { hydra::graphics::ResourceType::TextureRW, name_token.text };
                    code_fragment.resources.emplace_back( resource );
                }
                break;
            }

            case &#39;s&#39;:
            {
                if ( expectKeyword( token.text, 9, &amp;quot;sampler2D&amp;quot; ) ) {
                    // Advance to next token to get the name
                    Token name_token;
                    nextToken( parser-&amp;gt;lexer, name_token );

                    CodeFragment::Resource resource = { hydra::graphics::ResourceType::Texture, name_token.text };
                    code_fragment.resources.emplace_back( resource );
                }
                break;
            }
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Should be pretty straight-forward: if you find the identifier for texture, add a resource dependency with type and name to the current code fragment!&lt;!-- raw HTML omitted --&gt;
Is this the ideal solution ?&lt;!-- raw HTML omitted --&gt;
Probably not.&lt;!-- raw HTML omitted --&gt;
But I wanted to show what we can achieve once we have fun with parsing, including the understanding on when to say &lt;strong&gt;NO&lt;/strong&gt; to it!&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;h3 id=&#34;manual-resource-layout&#34;&gt;Manual Resource Layout&lt;/h3&gt;
&lt;p&gt;Now that the effect can work without too much programmer time, it is time to give back to programmers the control they want.&lt;!-- raw HTML omitted --&gt;
In the previous paragraph about &lt;em&gt;Expert Constants&lt;/em&gt; we talked about adding a new section, called &lt;strong&gt;layout&lt;/strong&gt;.&lt;!-- raw HTML omitted --&gt;
In this section we can specify the resource list for each &lt;em&gt;pass&lt;/em&gt; manually, and later on in the pass we can reference this lists as used by the pass.&lt;/p&gt;
&lt;p&gt;Going on a more complete solution, layouts &lt;strong&gt;should be included and merged when including other HFX files&lt;/strong&gt;.&lt;!-- raw HTML omitted --&gt;
This is something we want and we&amp;rsquo;ll look in another post, we can start simple by defining something local:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// HFX
//
// For the developer
layout {
    list LocalCompute {
        cbuffer LocalConstants;

        texture2Drw(rgba8) destination_texture;
    }

    list Local {
        texture2D input_texture;
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This is a rather simple layout, but let&amp;rsquo;s see it.&lt;!-- raw HTML omitted --&gt;
First of all, for each &amp;lsquo;list&amp;rsquo; keyword we define a single list with a unique name.&lt;!-- raw HTML omitted --&gt;
With that, we can reference in the pass which list to use.&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;p&gt;The code that does the parsing is (at this point) pretty straight-forward, both in &lt;code&gt;void declarationResourceList( Parser* parser, ResourceList&amp;amp; resource_list )&lt;/code&gt; and  &lt;code&gt;void resourceBindingIdentifier( Parser* parser, const Token&amp;amp; token, ResourceBinding&amp;amp; binding )&lt;/code&gt;.&lt;!-- raw HTML omitted --&gt;
I will not go over it, but basically it will parse the resource lists and add them to the shader.&lt;!-- raw HTML omitted --&gt;
The parsing itself will read the text and create the &lt;code&gt;ResourceSetLayoutCreation::Binding&lt;/code&gt; and add it to the list of the resources.&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;p&gt;We then add a new identifier in the pass to choose which resource list to be used:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// HFX
//
pass FillTexture {

    resources = LocalCompute, ...

    dispatch = 32, 32, 1
    render_pass = compute
    compute = ComputeTest
}

pass ToScreen {

    resources = Local

    render_pass = fullscreen
    vertex = ToScreen
    fragment = ToScreen
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The parsing will happen in &lt;code&gt;void declarationPassResources( Parser* parser, Pass&amp;amp; pass )&lt;/code&gt;.&lt;/p&gt;
&lt;h3 id=&#34;adding-resource-layout-data-to-binary-hfx&#34;&gt;Adding Resource Layout data to binary HFX&lt;/h3&gt;
&lt;p&gt;So after this amazing journey we are ready to embed those informations into the BHFX and use it right away into the rendering API.&lt;/p&gt;
&lt;p&gt;The big difference is &lt;strong&gt;if the hfx file contains a layout section&lt;/strong&gt;.&lt;!-- raw HTML omitted --&gt;
If it is not present, then all the informations will be gathered automatically and will be added with the &lt;code&gt;writeAutomaticResourcesLayout&lt;/code&gt; method.&lt;/p&gt;
&lt;p&gt;First we will add the LocalConstant buffer created from the properties:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;static void writeAutomaticResourcesLayout( const hfx::Pass&amp;amp; pass, StringBuffer&amp;amp; pass_buffer, uint32_t&amp;amp; pass_offset ) {

    using namespace hydra::graphics;

    // Add the local constant buffer obtained from all the properties in the layout.
    hydra::graphics::ResourceSetLayoutCreation::Binding binding = { hydra::graphics::ResourceType::Constants, 0, 1, &amp;quot;LocalConstants&amp;quot; };

    pass_buffer.append( (void*)&amp;amp;binding, sizeof( hydra::graphics::ResourceSetLayoutCreation::Binding) );
    pass_offset += sizeof( hydra::graphics::ResourceSetLayoutCreation::Binding );
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Then we will cycle through all the shader stages and write the resources into the memory:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    for ( size_t s = 0; s &amp;lt; pass.shader_stages.size(); ++s ) {
        const Pass::ShaderStage shader_stage = pass.shader_stages[s];

        for ( size_t p = 0; p &amp;lt; shader_stage.code-&amp;gt;resources.size(); p++ ) {
            const hfx::CodeFragment::Resource&amp;amp; resource = shader_stage.code-&amp;gt;resources[p];

            switch ( resource.type ) {
                case ResourceType::Texture:
                {
                    copy( resource.name, binding.name, 32 );
                    binding.type = hydra::graphics::ResourceType::Texture;

                    pass_buffer.append( (void*)&amp;amp;binding, sizeof( hydra::graphics::ResourceSetLayoutCreation::Binding ) );
                    pass_offset += sizeof( hydra::graphics::ResourceSetLayoutCreation::Binding );
                    break;
                }

                case ResourceType::TextureRW:
                {
                    copy( resource.name, binding.name, 32 );
                    binding.type = hydra::graphics::ResourceType::TextureRW;

                    pass_buffer.append( (void*)&amp;amp;binding, sizeof( hydra::graphics::ResourceSetLayoutCreation::Binding ) );
                    pass_offset += sizeof( hydra::graphics::ResourceSetLayoutCreation::Binding );
                    break;
                }
            }
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;If instead there is a layout section, the method &lt;code&gt;writeResourcesLayout&lt;/code&gt; is called and will be pretty straight-forward:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;static void writeResourcesLayout( const hfx::Pass&amp;amp; pass, StringBuffer&amp;amp; pass_buffer, uint32_t&amp;amp; pass_offset ) {

    using namespace hydra::graphics;

    for ( size_t r = 0; r &amp;lt; pass.resource_lists.size(); ++r ) {
        const ResourceList* resource_list = pass.resource_lists[r];

        const uint32_t resources_count = (uint32_t)resource_list-&amp;gt;resources.size();
        pass_buffer.append( (void*)resource_list-&amp;gt;resources.data(), sizeof(ResourceBinding) * resources_count );
        pass_offset += sizeof( ResourceBinding ) * resources_count;
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;And this will be put at the end of the current pass section:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pass_buffer.append( (void*)&amp;amp;pass_header, sizeof( ShaderEffectFile::PassHeader ) );
pass_buffer.append( shader_offset_buffer );
pass_buffer.append( code_buffer );

if ( automatic_layout ) {
    writeAutomaticResourcesLayout( pass, pass_buffer, pass_offset );
}
else {
    writeResourcesLayout( pass, pass_buffer, pass_offset );
}
&lt;/code&gt;&lt;/pre&gt;&lt;h1 id=&#34;conclusions-and-whats-next&#34;&gt;Conclusions and what&amp;rsquo;s next&lt;/h1&gt;
&lt;p&gt;We arrived at the end of this article, and we started seeing how we can use HFX as a more complete language to embed different rendering features.&lt;!-- raw HTML omitted --&gt;
We saw how to embed shader code and resource lists so that the rendering API can create everything without hard-coded generation of resources. This also showed when it was useful to create data instead of code.&lt;!-- raw HTML omitted --&gt;
On the contrary, the UI and the Constants are generated in a new header file - thus code generation.&lt;!-- raw HTML omitted --&gt;
There are pros and cons to both approaches, but I hope that knowing how to generate code and create a custom language will let you play with the concepts and explore your own needs.&lt;/p&gt;
&lt;p&gt;As next steps, there are some questions opened: how to reload shaders ? Can I add new material properties without recompiling code ?&lt;/p&gt;
&lt;p&gt;We will also see a simple implementation of a frame-graph, that I use since my years in Codemasters and in my indie project. This will be much more data-driven than code-generated, but again, the purpose of these articles is to explore the concepts and understanding when to use what.&lt;/p&gt;
&lt;p&gt;As always please comment, feedback, share!&lt;/p&gt;
&lt;p&gt;Thanks for reading!
Gabriel&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Writing a Shader Effect Language Part 1</title>
      <link>https://jorenjoestar.github.io/post/writing_shader_effect_language_1/</link>
      <pubDate>Tue, 06 Aug 2019 13:04:15 -0400</pubDate>
      
      <guid>https://jorenjoestar.github.io/post/writing_shader_effect_language_1/</guid>
      <description>&lt;h1 id=&#34;overview&#34;&gt;Overview&lt;/h1&gt;
&lt;p&gt;Data Driven Rendering Series:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://jorenjoestar.github.io/post/writing_shader_effect_language_1/&#34;&gt;https://jorenjoestar.github.io/post/writing_shader_effect_language_1/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://jorenjoestar.github.io/post/writing_shader_effect_language_2/&#34;&gt;https://jorenjoestar.github.io/post/writing_shader_effect_language_2/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://jorenjoestar.github.io/post/writing_shader_effect_language_3/&#34;&gt;https://jorenjoestar.github.io/post/writing_shader_effect_language_3/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://jorenjoestar.github.io/post/data_driven_rendering_pipeline/&#34;&gt;https://jorenjoestar.github.io/post/data_driven_rendering_pipeline/&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;In this article we will create a simple language that can encapsulate shader code (called &lt;strong&gt;code fragments&lt;/strong&gt;) and output different files for each fragment.&lt;!-- raw HTML omitted --&gt;
This is the initial step to switch from an engine that loads single files for each &lt;strong&gt;shader stage&lt;/strong&gt; (vertex, fragment, compute, &amp;hellip;) to one that uses an effect file that contains more than one shader.&lt;/p&gt;
&lt;p&gt;We will start by motivation, then will define the language itself (very simple), then we will look at the Parser and last the Code Generator.&lt;/p&gt;
&lt;p&gt;Have a good read!&lt;/p&gt;
&lt;h1 id=&#34;motivation&#34;&gt;Motivation&lt;/h1&gt;
&lt;p&gt;In the incredible quest of &lt;em&gt;data-driven rendering&lt;/em&gt;, after we defeated the dragon of &lt;a href=&#34;https://jorenjoestar.github.io/post/writing_a_simple_code_generator/&#34;&gt;code generation&lt;/a&gt; another multiple headed dragon arises: an hydra!
We have different options here: be the brave warrior in shiny armor that tries to cut all the heads of the hydra, built some machines that can fight for us and send them, or both built the machines AND fight.&lt;/p&gt;
&lt;p&gt;Our code is invaluable, like our energies fighting the hydra.
We need to carefully balance them and see how can we use for the BEST.&lt;/p&gt;
&lt;p&gt;Writing manual code is good, it is generally what is done, but it is slow and error prone.
Going data-driven can be fast, but can give you a sense of losing control (not personally, but I heard few people saying that).
Only generating code can quickly become a recipe for disaster: so many particular use cases need attention, that the code could be come a different kind of mess.&lt;/p&gt;
&lt;p&gt;We will try to go down the route of code generation mixed with data-driven.
As I wrote in my previous articles, it is a fine line and can be good to know when to go in which direction!&lt;/p&gt;
&lt;p&gt;I will divide the article in 2 parts.
The first part (this one) will contain the new Shader Code Generator to generate shader permutations and add include support to GLSL.
The second will require a low-level rendering library and will show Code Generation of more CPU areas of Rendering, the real goal of all these articles!&lt;/p&gt;
&lt;p&gt;The code is available here:&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/JorenJoestar/DataDrivenRendering&#34;&gt;https://github.com/JorenJoestar/DataDrivenRendering&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;effect-file-structure&#34;&gt;Effect file structure&lt;/h1&gt;
&lt;p&gt;Looking at effects, the first thing to do is to define a file that will represent our shaders. My choice is to create a simple language to embed shaders code and generate the CPU code necessary to render it.&lt;/p&gt;
&lt;h2 id=&#34;why-not-using-json-&#34;&gt;Why not using Json ?&lt;/h2&gt;
&lt;p&gt;While it is an amazing data-format, I still want a bigger degree of control of what to parse and what to generate.
The decision is based on the fact that by writing a parser for the language, I can automate some code-generation that would be more intricate with Json.
Also, this series itself is a personal exploration on the topic, so using Json was not an option for this level of complexity.&lt;/p&gt;
&lt;h2 id=&#34;the-hfx-format&#34;&gt;The HFX Format&lt;/h2&gt;
&lt;p&gt;HFX (Hydra Effects) is a new language we will define to write out shaders.
The first iteration will be barebone - it will simply be a shader permutation generator - but it will be the foundation to extensions that will allow us to write CPU rendering code that we want to automate.&lt;/p&gt;
&lt;p&gt;In defining the format, there will be few keywords that will be defined, but the general architecture will make straightforward to copy-paste shader code fragments from any language into the HFX language.
We will use the following keywords (and concepts).&lt;/p&gt;
&lt;h3 id=&#34;shader&#34;&gt;Shader&lt;/h3&gt;
&lt;p&gt;The root of a shader effect. It will contain everything we are writing.&lt;/p&gt;
&lt;h3 id=&#34;glslhlsl&#34;&gt;Glsl/Hlsl&lt;/h3&gt;
&lt;p&gt;These will define the actual shader code, enclosed fragments. Fragments can be composed and reused.
For Glsl in particular, code fragments needs to be embedded in defines for each stage. More on that later.&lt;/p&gt;
&lt;h3 id=&#34;pass-technique-variant&#34;&gt;Pass, Technique, Variant&lt;/h3&gt;
&lt;p&gt;This is the central part for the effects to work. I&amp;rsquo;ve researched a bit, between &lt;a href=&#34;https://docs.microsoft.com/en-us/windows/win32/direct3d9/using-an-effect&#34;&gt;Microsoft effects&lt;/a&gt;, &lt;a href=&#34;https://docs.unity3d.com/Manual/SL-Shader.html&#34;&gt;Unity effects&lt;/a&gt;, &lt;a href=&#34;https://github.com/BastiaanOlij/shader_tutorial/blob/master/shaders/water_3d/depth_buffer/depth_buffer_textured.shader&#34;&gt;Godot&lt;/a&gt; and &lt;a href=&#34;http://advances.realtimerendering.com/destiny/gdc_2017/&#34;&gt;Bungie&lt;/a&gt; and the concepts are very similar, but they seem to differ a little and also each implementation becomes very engine-specific of course.&lt;!-- raw HTML omitted --&gt;
The presentation by Bungie is amazing and their system is by far the more extensive and complex, we will work on a much simpler shader effect system.&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s define a pass as a combination of shader code for at least one stage of the shader pipeline. For example a single compute shader or a couple vertex-fragment shader.&lt;/p&gt;
&lt;p&gt;Variants and techniques are loose concept to help separating shader paths.
For example a &lt;em&gt;variant&lt;/em&gt; could be a different post-process shader, like different implementations of SSAO.&lt;/p&gt;
&lt;p&gt;A technique could be a whole set of passes that target a specific platform.&lt;/p&gt;
&lt;p&gt;Not having my mind set on those still, I will omit them for now, as they are concepts that are less central than the code generation, and can be very subjective opinion-wise.
Possibly I&amp;rsquo;ll get them in part 2.&lt;/p&gt;
&lt;h3 id=&#34;properties&#34;&gt;Properties&lt;/h3&gt;
&lt;p&gt;Final piece of the puzzle. This will define the resources used by the shader effect on a per-effect level.
Keeping an eye on the newer rendering APIs (DX12 and Vulkan) this defines also the layout of the resources and how they are used.
Possibly the most intense part from an automation possibility (and thus code-generation).
We will define this in part 2 of this article.&lt;/p&gt;
&lt;h1 id=&#34;high-level-workflow&#34;&gt;High level workflow&lt;/h1&gt;
&lt;p&gt;From a high level perspective what will happen in all this code is enclosed in this code:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;text = ReadEntireFileIntoMemory( &amp;quot;..\\data\\SimpleFullscreen.hfx&amp;quot;, nullptr );
initLexer( &amp;amp;lexer, (char*)text );

hfx::Parser effect_parser;
hfx::initParser( &amp;amp;effect_parser, &amp;amp;lexer );
hfx::generateAST( &amp;amp;effect_parser );

hfx::CodeGenerator hfx_code_generator;
hfx::initCodeGenerator( &amp;amp;hfx_code_generator, &amp;amp;effect_parser, 4096 );
hfx::generateShaderPermutations( &amp;amp;hfx_code_generator, &amp;quot;..\\data\\&amp;quot; );
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;We separated the &lt;em&gt;Lexer&lt;/em&gt; from the &lt;em&gt;Parser&lt;/em&gt; so we can reuse the lexer functionalities, thus we can reuse it from the previous example (parsing the HydraDataFormat files).&lt;!-- raw HTML omitted --&gt;
Then we initialize the &lt;em&gt;Parser&lt;/em&gt; and &lt;em&gt;generate the AST&lt;/em&gt;. This will save all the passes and code fragments we defined in the HFX file.&lt;!-- raw HTML omitted --&gt;
Finally we will get the parsing informations and give them to the &lt;em&gt;code generator&lt;/em&gt;, that will write out the files for each pass and stage.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s dig into the example!&lt;/p&gt;
&lt;h1 id=&#34;parser-welcome-hfx&#34;&gt;Parser: welcome HFX!&lt;/h1&gt;
&lt;p&gt;In most rendering-API (OpenGL, Vulkan, Direct3D12, &amp;hellip;) shaders are compiled by compiling the individual stages (vertex, fragment, compute, geometry, &amp;hellip;) and in some APIs (especially the newer ones) are compiled into a &lt;strong&gt;Shader State&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;As first step of this shader language, single shader files will be created by the &lt;em&gt;shader generation&lt;/em&gt; method in our code.&lt;/p&gt;
&lt;p&gt;We will define a simple fullscreen HFX with &lt;em&gt;code fragments&lt;/em&gt; and &lt;em&gt;passes&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;First, we define the root shader (SimpleFullscreen.hfx, under folder &amp;lsquo;data&amp;rsquo;):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;shader SimpleFullscreen {
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This is simply the container for all the code and passes that will define the shader effect.&lt;/p&gt;
&lt;p&gt;Now we need some actual code, so we can define a shader fragment.&lt;!-- raw HTML omitted --&gt;
The keyword used in our language is &lt;strong&gt;glsl&lt;/strong&gt; followed by a name and an open brace:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;glsl ToScreen {
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This will define a &lt;strong&gt;code fragment&lt;/strong&gt; named &lt;em&gt;ToScreen&lt;/em&gt;, that can be referenced from the passes.&lt;!-- raw HTML omitted --&gt;
Next we use a glsl trick to &lt;em&gt;signal our parser to use includes&lt;/em&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#pragma include &amp;quot;Platform.h&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This #pragma is actually ignored by the compiler, but will be used by the parser to actually add the include!&lt;!-- raw HTML omitted --&gt;
BEWARE: this code will be included in BOTH &lt;em&gt;vertex&lt;/em&gt; and &lt;em&gt;fragment&lt;/em&gt; program!&lt;!-- raw HTML omitted --&gt;
Anything outside of the VERTEX/FRAGMENT/COMPUTE macros will be, and this is done on purpose, like defining an interpolator struct only once or for common includes.&lt;/p&gt;
&lt;p&gt;Next we define the vertex program.&lt;!-- raw HTML omitted --&gt;
BEWARE: vertex only code must be enclosed in &lt;strong&gt;VERTEX&lt;/strong&gt; define!&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#if defined VERTEX

out vec4 vTexCoord;

void main() {

   vTexCoord.xy = vec2((gl_VertexID &amp;lt;&amp;lt; 1) &amp;amp; 2, gl_VertexID &amp;amp; 2);
   vTexCoord.zw = vTexCoord.xy;
   gl_Position = vec4(vTexCoord.xy * 2.0f + -1.0f, 0.0f, 1.0f);
}

#endif // VERTEX
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This code is a simple fullscreen triangle that does not require any vertex buffer, but uses the vertex id to draw. Nothing fancy.&lt;/p&gt;
&lt;p&gt;Next is the fragment program, and again enclosed in &lt;strong&gt;FRAGMENT&lt;/strong&gt; define:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#if defined FRAGMENT

in vec4 vTexCoord;

out vec4 outColor;

layout(binding=0) uniform sampler2D input_texture;

void main() {

    vec3 color = texture2D(input_texture, vTexCoord.xy).xyz;
    outColor = vec4(color, 1);
}

#endif // FRAGMENT

} // glsl ToScreen

&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This code simply reads a texture and outputs it to the screen.&lt;/p&gt;
&lt;p&gt;We defined the code fragment ToScreen, containing both a vertex and a fragment program, and now we can actually generate the permutation that we need.&lt;!-- raw HTML omitted --&gt;
The code for this in our effect file is:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pass ToScreen {
   vertex = ToScreen
   fragment = ToScreen
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;We are simply defining a pass with the vertex and fragment program defined in the ToScreen code fragment (yes I don&amp;rsquo;t like this term too).&lt;/p&gt;
&lt;p&gt;Running the &lt;strong&gt;code generator&lt;/strong&gt; on this simple effect file will generate the two files ToScreen.vert and ToScreen.frag.&lt;/p&gt;
&lt;p&gt;These can be read directly into your favourite OpenGL renderer and used as is!&lt;/p&gt;
&lt;h2 id=&#34;the-parser&#34;&gt;The Parser&lt;/h2&gt;
&lt;p&gt;Now that we have defined the effect and we know what is the outcome of generating code from the effect file, let&amp;rsquo;s look into the different component of the parser and code generator needed.&lt;/p&gt;
&lt;p&gt;By design, we chose the Lexer to know nothing about the language, so that we can use it between different languages.
The entry point to parse the effect is the method generateAST:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;void generateAST( Parser* parser ) {

    // Read source text until the end.
    // The main body can be a list of declarations.
    bool parsing = true;

    while ( parsing ) {

        Token token;
        nextToken( parser-&amp;gt;lexer, token );

        switch ( token.type ) {

            case Token::Token_Identifier:
            {
                identifier( parser, token );
                break;
            }

            case Token::Type::Token_EndOfStream:
            {
                parsing = false;
                break;
            }
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This code simply process the file -  using the lexer -  until the end of it, and reads only identifiers.&lt;!-- raw HTML omitted --&gt;
It is the same as the previous article and the previous parser. What changes drastically is the &lt;strong&gt;identifier&lt;/strong&gt; method!&lt;!-- raw HTML omitted --&gt;
We will have 3 different set of identifiers, usable in different parts of the HFX file:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Main identifiers, &amp;lsquo;shader&amp;rsquo;, &amp;lsquo;glsl&amp;rsquo;, &amp;lsquo;pass&amp;rsquo;&lt;/li&gt;
&lt;li&gt;Pass identifiers, &amp;lsquo;compute&amp;rsquo;, &amp;lsquo;vertex&amp;rsquo;, &amp;lsquo;fragment&amp;rsquo;&lt;/li&gt;
&lt;li&gt;Directive identifiers, &amp;lsquo;if defined&amp;rsquo;, &amp;lsquo;pragma include&amp;rsquo;, &amp;lsquo;endif&amp;rsquo;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Let&amp;rsquo;s have a look at the code for parsing the main identifiers:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;inline void identifier( Parser* parser, const Token&amp;amp; token ) {

    // Scan the name to know which 
    for ( uint32_t i = 0; i &amp;lt; token.text.length; ++i ) {
        char c = *(token.text.text + i);

        switch ( c ) {
            case &#39;s&#39;:
            {
                if ( expectKeyword( token.text, 6, &amp;quot;shader&amp;quot; ) ) {
                    declarationShader( parser );
                    return;
                }

                break;
            }

            case &#39;g&#39;:
            {
                if ( expectKeyword( token.text, 4, &amp;quot;glsl&amp;quot; ) ) {
                    declarationGlsl( parser );
                    return;
                }
                break;
            }

            case &#39;p&#39;:
            {
                if ( expectKeyword( token.text, 4, &amp;quot;pass&amp;quot; ) ) {
                    declarationPass( parser );
                    return;
                }
                break;
            }

        }
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This code simply defers the parsing of a particular identifier using the &lt;strong&gt;declaration&lt;/strong&gt; method corresponding to the identifier.
We will look into detail on each method.&lt;/p&gt;
&lt;h3 id=&#34;parsing-shader&#34;&gt;Parsing &amp;lsquo;shader&amp;rsquo;&lt;/h3&gt;
&lt;p&gt;We are parsing now the following part from the HFX file:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// HFX

shader SimpleFullscreen {
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This is the entry point of the effect itself.&lt;!-- raw HTML omitted --&gt;
What should the parser do here ?&lt;!-- raw HTML omitted --&gt;
Simply iterate through the main identifiers, &amp;lsquo;glsl&amp;rsquo; and &amp;lsquo;pass&amp;rsquo;.&lt;!-- raw HTML omitted --&gt;
Technically I could have separated the methods to have one with parsing shader only and the others parsing &amp;lsquo;glsl&amp;rsquo; and &amp;lsquo;pass&amp;rsquo;, but did not want to complicate the code further.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s look at how we parse the identifier &amp;lsquo;shader&amp;rsquo;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// C++

inline void declarationShader( Parser* parser ) {
    // Parse name
    Token token;
    if ( !expectToken( parser-&amp;gt;lexer, token, Token::Token_Identifier ) ) {
        return;
    }

    // Cache name string
    StringRef name = token.text;

    if ( !expectToken( parser-&amp;gt;lexer, token, Token::Token_OpenBrace ) ) {
        return;
    }

    while ( !equalToken( parser-&amp;gt;lexer, token, Token::Token_CloseBrace ) ) {

        identifier( parser, token );
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;As the previous article&amp;rsquo;s code, this will get the tokens from the lexer and generate data if the syntax is correct.&lt;!-- raw HTML omitted --&gt;
When we enter the method the Lexer will be just at the beginning of the name (SimpleFullscreen), so the code will parse the name, the open brace, and parse everything else until it encounter the close brace.&lt;/p&gt;
&lt;p&gt;The method identifier will parse also identifiers &amp;lsquo;glsl&amp;rsquo; and &amp;lsquo;pass&amp;rsquo;.&lt;/p&gt;
&lt;h3 id=&#34;parsing-glsl&#34;&gt;Parsing &amp;lsquo;glsl&amp;rsquo;&lt;/h3&gt;
&lt;p&gt;This is the most complex parsing in the code.&lt;!-- raw HTML omitted --&gt;
I will put both the HFX part and C++ code so hopefully it will be clearer what the parser is doing and why.&lt;/p&gt;
&lt;p&gt;As a refresh and reference, this is the &lt;strong&gt;code fragment&lt;/strong&gt; ToScreen defined in SimpleFullscreen.hfx:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// HFX

glsl ToScreen {

    #pragma include &amp;quot;Platform.h&amp;quot;

    #if defined VERTEX
    out vec4 vTexCoord;

    void main() {

        vTexCoord.xy = vec2((gl_VertexID &amp;lt;&amp;lt; 1) &amp;amp; 2, gl_VertexID &amp;amp; 2);
        vTexCoord.zw = vTexCoord.xy;

        gl_Position = vec4(vTexCoord.xy * 2.0f + -1.0f, 0.0f, 1.0f);
    }
    #endif // VERTEX

    #if defined FRAGMENT

    in vec4 vTexCoord;

    out vec4 outColor;

    layout(binding=0) uniform sampler2D input_texture;

    void main() {
        vec3 color = texture2D(input_texture, vTexCoord.xy).xyz;
        outColor = vec4(1, 1, 0, 1);
        outColor = vec4(color, 1);
    }
    #endif // FRAGMENT
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Let&amp;rsquo;s start from the beginning.&lt;!-- raw HTML omitted --&gt;
When the parser finds the &amp;lsquo;glsl&amp;rsquo; keyword in the identifier method:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// C++

case &#39;g&#39;:
{
    if ( expectKeyword( token.text, 4, &amp;quot;glsl&amp;quot; ) ) {
        declarationGlsl( parser );
        return;
    }
    break;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;It calls the method &lt;em&gt;&lt;em&gt;void declarationGlsl( Parser&lt;/em&gt; parser )&lt;/em&gt;*.&lt;/p&gt;
&lt;p&gt;The lexer reading the HFX is after the glsl keyword when entering the method, just before the ToScreen identifier:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// HFX

glsl (Here!)ToScreen {
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Let&amp;rsquo;s see the C++ code step by step.&lt;!-- raw HTML omitted --&gt;
First parsing the name &amp;lsquo;ToScreen&amp;rsquo;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// C++

inline void declarationGlsl( Parser* parser ) {

    // Parse name
    Token token;
    if ( !expectToken( parser-&amp;gt;lexer, token, Token::Token_Identifier ) ) {
        return;
    }
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;as seen in other methods as well.&lt;!-- raw HTML omitted --&gt;
We are defining a new &lt;strong&gt;code fragment&lt;/strong&gt;, thus we need to initialize it. There is tracking of the #ifdef depths to manage when some code must be included in a code fragment and when not:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    CodeFragment code_fragment = {};
    // Cache name string
    code_fragment.name = token.text;

    for ( size_t i = 0; i &amp;lt; CodeFragment::Count; i++ ) {
        code_fragment.stage_ifdef_depth[i] = 0xffffffff;
    }

    if ( !expectToken( parser-&amp;gt;lexer, token, Token::Token_OpenBrace ) ) {
        return;
    }
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Next is simply arriving at the first token that contains all the glsl code:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    // Advance token and cache the starting point of the code.
    nextToken( parser-&amp;gt;lexer, token );
    code_fragment.code = token.text;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;And now some more parsing craftmanship.&lt;!-- raw HTML omitted --&gt;
We cannot use anymore the simple check to end parsing when encountering a closed brace, because there can be different structs defined that will break that mechanism.&lt;!-- raw HTML omitted --&gt;
Instead we track the number of open braces and when we close the last one, we consider finished the parsing of the &lt;strong&gt;code fragment&lt;/strong&gt;!&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    uint32_t open_braces = 1;

    // Scan until close brace token
    while ( open_braces ) {

        if ( token.type == Token::Token_OpenBrace )
            ++open_braces;
        else if ( token.type == Token::Token_CloseBrace )
            --open_braces;

&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The only token that we care inside the code fragment is the &lt;strong&gt;hash&lt;/strong&gt;, signalling either an include or a define, used for separating &lt;em&gt;per-stage code&lt;/em&gt;.&lt;!-- raw HTML omitted --&gt;
The parsing of the &lt;em&gt;hash&lt;/em&gt; token will be done inside the &lt;strong&gt;directiveIdentifier&lt;/strong&gt; method:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;        // Parse hash for includes and defines
        if ( token.type == Token::Token_Hash ) {
            // Get next token and check which directive is
            nextToken( parser-&amp;gt;lexer, token );

            directiveIdentifier( parser, token, code_fragment );
        }

&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Before diving deep into the &lt;strong&gt;directive identifiers&lt;/strong&gt;, let&amp;rsquo;s finish the main parsing routine.&lt;!-- raw HTML omitted --&gt;
We advance to the next token until we close all the braces, and then save the text length of all the code fragment:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;        nextToken( parser-&amp;gt;lexer, token );
    }
    
    // Calculate code string length
    code_fragment.code.length = token.text.text - code_fragment.code.text;

&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Final step is to save the newly parsed code fragment into the parser data:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    parser-&amp;gt;code_fragments.emplace_back( code_fragment );
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;We can now dive deep into the parsing of directives, namely #if defined, #pragma include and #endif.&lt;/p&gt;
&lt;h4 id=&#34;parsing-if-defined&#34;&gt;Parsing &amp;lsquo;#if defined&amp;rsquo;&lt;/h4&gt;
&lt;p&gt;When we encounter the &lt;strong&gt;Hash&lt;/strong&gt; token within the &lt;strong&gt;glsl&lt;/strong&gt; part, we need to parse further to understand the other keywords.&lt;!-- raw HTML omitted --&gt;
&lt;strong&gt;#if defined&lt;/strong&gt; is the most important directive for us, because it will tell the parser which &lt;strong&gt;shader stage&lt;/strong&gt; we are parsing currently and thus where to direct the text!&lt;!-- raw HTML omitted --&gt;
It starts from a common/shared stage, for shared code, and when encounters a #if defined it can signal a stage specific code.&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;p&gt;Namely when parsing the following line in HFX:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// HFX

#(Here!)if defined VERTEX
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The parser needs to check 2 other identifiers. Remember that the parser is currently AFTER the &lt;strong&gt;Hash&lt;/strong&gt; token, as beautifully written in the previous snippet!&lt;!-- raw HTML omitted --&gt;
Let&amp;rsquo;s look at the code:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// C++

inline void directiveIdentifier( Parser* parser, const Token&amp;amp; token, CodeFragment&amp;amp; code_fragment ) {
    
    Token new_token;
    for ( uint32_t i = 0; i &amp;lt; token.text.length; ++i ) {
        char c = *(token.text.text + i);

        switch ( c ) {
            case &#39;i&#39;:
            {
                // Search for the pattern &#39;if defined&#39;
                if ( expectKeyword( token.text, 2, &amp;quot;if&amp;quot; ) ) {
                    nextToken( parser-&amp;gt;lexer, new_token );

                    if ( expectKeyword( new_token.text, 7, &amp;quot;defined&amp;quot; ) ) {
                        nextToken( parser-&amp;gt;lexer, new_token );

                        // Use 0 as not set value for the ifdef depth.
                        ++code_fragment.ifdef_depth;

                        if ( expectKeyword( new_token.text, 6, &amp;quot;VERTEX&amp;quot; ) ) {

                            code_fragment.stage_ifdef_depth[CodeFragment::Vertex] = code_fragment.ifdef_depth;
                            code_fragment.current_stage = CodeFragment::Vertex;
                        }
                        else if ( expectKeyword( new_token.text, 8, &amp;quot;FRAGMENT&amp;quot; ) ) {

                            code_fragment.stage_ifdef_depth[CodeFragment::Fragment] = code_fragment.ifdef_depth;
                            code_fragment.current_stage = CodeFragment::Fragment;
                        }
                        else if ( expectKeyword( new_token.text, 7, &amp;quot;COMPUTE&amp;quot; ) ) {

                            code_fragment.stage_ifdef_depth[CodeFragment::Compute] = code_fragment.ifdef_depth;
                            code_fragment.current_stage = CodeFragment::Compute;
                        }
                    }

                    return;
                }
                break;
            }

&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Let&amp;rsquo;s dissect this code!&lt;/p&gt;
&lt;p&gt;Starting from the current token, just after the &lt;strong&gt;#(Hash)&lt;/strong&gt;, we need to check the correct composition of the keywords.&lt;!-- raw HTML omitted --&gt;
We expect &amp;lsquo;if&amp;rsquo;, and then if found we go to the next token:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;if ( expectKeyword( token.text, 2, &amp;quot;if&amp;quot; ) ) {
    nextToken( parser-&amp;gt;lexer, new_token );
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;We search for the &amp;lsquo;defined&amp;rsquo; identifier and if found we go to the next identifier:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;if ( expectKeyword( new_token.text, 7, &amp;quot;defined&amp;quot; ) ) {
    nextToken( parser-&amp;gt;lexer, new_token );
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The parser is currently here:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#if defined (Here!)VERTEX
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;And thus the last step is to check which &lt;strong&gt;shader stage&lt;/strong&gt; is currently starting.
This is done here:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;if ( expectKeyword( new_token.text, 6, &amp;quot;VERTEX&amp;quot; ) ) {

    code_fragment.stage_ifdef_depth[CodeFragment::Vertex] = code_fragment.ifdef_depth;
    code_fragment.current_stage = CodeFragment::Vertex;
}

&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;In this central piece of code, we set the current stage to Vertex (because we found the keyword &amp;lsquo;VERTEX&amp;rsquo;) and we save the current ifdef depth.&lt;!-- raw HTML omitted --&gt;
Why that ? &lt;!-- raw HTML omitted --&gt;
Because when we will parse #endif, we will do the same for the open/close braces depth in the main glsl parser: we want to be sure that the defines are paired correctly and we are saving the per-stage code in the correct way!&lt;!-- raw HTML omitted --&gt;
This will be more clear when we see the #endif parsing.&lt;/p&gt;
&lt;p&gt;Moving on, we will do the same for all the other keywords (&amp;lsquo;FRAGMENT&amp;rsquo; and &amp;lsquo;COMPUTE&amp;rsquo; for now):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;else if ( expectKeyword( new_token.text, 8, &amp;quot;FRAGMENT&amp;quot; ) ) {

    code_fragment.stage_ifdef_depth[CodeFragment::Fragment] = code_fragment.ifdef_depth;
    code_fragment.current_stage = CodeFragment::Fragment;
}
else if ( expectKeyword( new_token.text, 7, &amp;quot;COMPUTE&amp;quot; ) ) {

    code_fragment.stage_ifdef_depth[CodeFragment::Compute] = code_fragment.ifdef_depth;
    code_fragment.current_stage = CodeFragment::Compute;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;And the parsing of &lt;strong&gt;#if defined&lt;/strong&gt; is over!&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;h4 id=&#34;parsing-pragma-include&#34;&gt;Parsing &amp;lsquo;#pragma include&amp;rsquo;&lt;/h4&gt;
&lt;p&gt;In HFX we are parsing the following:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// HFX

#pragma include &amp;quot;Platform.h&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;With the following code (inside &lt;em&gt;directiveIdentifier&lt;/em&gt; method):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// C++

case &#39;p&#39;:
{
    if ( expectKeyword( token.text, 6, &amp;quot;pragma&amp;quot; ) ) {
        nextToken( parser-&amp;gt;lexer, new_token );

        if ( expectKeyword( new_token.text, 7, &amp;quot;include&amp;quot; ) ) {
            nextToken( parser-&amp;gt;lexer, new_token );

            code_fragment.includes.emplace_back( new_token.text );
            code_fragment.includes_stage.emplace_back( code_fragment.current_stage );
        }

        return;
    }
    break;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This is simply saving the filename after the include, that being surrounded by &amp;quot;&amp;quot; is classified as string, and is using the current stage to know which stage should include that file!&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;h4 id=&#34;parsing-endif&#34;&gt;Parsing &amp;lsquo;#endif&amp;rsquo;&lt;/h4&gt;
&lt;p&gt;Final part is the &lt;strong&gt;#endif&lt;/strong&gt; identifier:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;case &#39;e&#39;:
{
    if ( expectKeyword( token.text, 5, &amp;quot;endif&amp;quot; ) ) {

        if ( code_fragment.stage_ifdef_depth[CodeFragment::Vertex] == code_fragment.ifdef_depth ) {
            
            code_fragment.stage_ifdef_depth[CodeFragment::Vertex] = 0xffffffff;
            code_fragment.current_stage = CodeFragment::Common;
        }
        else if ( code_fragment.stage_ifdef_depth[CodeFragment::Fragment] == code_fragment.ifdef_depth ) {

            code_fragment.stage_ifdef_depth[CodeFragment::Fragment] = 0xffffffff;
            code_fragment.current_stage = CodeFragment::Common;
        }
        else if ( code_fragment.stage_ifdef_depth[CodeFragment::Compute] == code_fragment.ifdef_depth ) {

            code_fragment.stage_ifdef_depth[CodeFragment::Compute] = 0xffffffff;
            code_fragment.current_stage = CodeFragment::Common;
        }

        --code_fragment.ifdef_depth;

        return;
    }
    break;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This is mirroring the &lt;strong&gt;#if defined&lt;/strong&gt; and simply goes back to set the current stage to common/shared and reset the per-stage ifdef depth.&lt;/p&gt;
&lt;p&gt;We can now proceed to the final part of the parsing, the &lt;strong&gt;passes&lt;/strong&gt;!&lt;!-- raw HTML omitted --&gt;
This is the glue to generate the different files from the code fragments.&lt;/p&gt;
&lt;h3 id=&#34;parsing-pass&#34;&gt;Parsing &amp;lsquo;pass&amp;rsquo;&lt;/h3&gt;
&lt;p&gt;Reading the HFX file, we are now in the final part of the file:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// HFX

pass ToScreen {
   vertex = ToScreen
   fragment = ToScreen
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;A pass is simply a collection of &lt;strong&gt;code fragments&lt;/strong&gt; associated with each shader stage (vertex, fragment, compute).&lt;!-- raw HTML omitted --&gt;
When we parsed the fragments, we saved them in the parser to be retrieved.&lt;/p&gt;
&lt;p&gt;To refresh our memory, this is the actual &lt;strong&gt;Pass struct&lt;/strong&gt; in C++:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// C++

struct Pass {

    StringRef                   name;

    const CodeFragment*         vs                  = nullptr;
    const CodeFragment*         fs                  = nullptr;
    const CodeFragment*         cs                  = nullptr;

}; // struct Pass
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Going back to the main directive method, we call the &lt;strong&gt;declarationPass&lt;/strong&gt; method when we encounter the &amp;lsquo;pass&amp;rsquo; identifier.&lt;!-- raw HTML omitted --&gt;
We will parse the following line:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// HFX

pass ToScreen {
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;With the following code (similar to everything else, it should be easier to read now):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// C++

inline void declarationPass( Parser* parser ) {

    Token token;
    if ( !expectToken( parser-&amp;gt;lexer, token, Token::Token_Identifier ) ) {
        return;
    }

    Pass pass = {};
    // Cache name string
    pass.name = token.text;

    if ( !expectToken( parser-&amp;gt;lexer, token, Token::Token_OpenBrace ) ) {
        return;
    }

&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;After we saved the pass name we can start reading the individual stages using the &lt;strong&gt;passIdentifier&lt;/strong&gt; method:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    while ( !equalToken( parser-&amp;gt;lexer, token, Token::Token_CloseBrace ) ) {
        passIdentifier( parser, token, pass );
    }
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;And then save the newly parsed pass.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    parser-&amp;gt;passes.emplace_back( pass );
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;For each identifier now, we will check which stage we are parsing.&lt;!-- raw HTML omitted --&gt;
Currently we are here, after the open brace and all the whitespace:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// HFX

pass ToScreen {
   (Here!)vertex = ToScreen
   fragment = ToScreen
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;What is next is thus checking the identifier and filling the corresponding &lt;strong&gt;shader stage&lt;/strong&gt; of the &lt;strong&gt;pass&lt;/strong&gt;.&lt;!-- raw HTML omitted --&gt;
I will post all the code of the method, because is similar to most code we seen and should be straightforward:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// C++

inline void passIdentifier( Parser* parser, const Token&amp;amp; token, Pass&amp;amp; pass ) {
    // Scan the name to know which stage we are parsing    
    for ( uint32_t i = 0; i &amp;lt; token.text.length; ++i ) {
        char c = *(token.text.text + i);

        switch ( c ) {
            
            case &#39;c&#39;:
            {
                if ( expectKeyword( token.text, 7, &amp;quot;compute&amp;quot;) ) {
                    declarationShaderStage( parser, &amp;amp;pass.cs );
                    return;
                }
                break;
            }

            case &#39;v&#39;:
            {
                if ( expectKeyword( token.text, 6, &amp;quot;vertex&amp;quot; ) ) {
                    declarationShaderStage( parser, &amp;amp;pass.vs );
                    return;
                }
                break;
            }

            case &#39;f&#39;:
            {
                if ( expectKeyword( token.text, 8, &amp;quot;fragment&amp;quot; ) ) {
                    declarationShaderStage( parser, &amp;amp;pass.fs );
                    return;
                }
                break;
            }
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The real &amp;lsquo;magic&amp;rsquo; here is the &amp;lsquo;declarationShaderStage&amp;rsquo; method.&lt;!-- raw HTML omitted --&gt;
This method parses the couple &amp;lsquo;identifier&amp;rsquo; &amp;lsquo;=&amp;rsquo; &amp;lsquo;identifier&amp;rsquo;, and searches the &lt;strong&gt;code fragment&lt;/strong&gt; with the same name:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;inline void declarationShaderStage( Parser* parser, const CodeFragment** out_fragment ) {

    Token token;
    if ( !expectToken( parser-&amp;gt;lexer, token, Token::Token_Equals ) ) {
        return;
    }

    if ( !expectToken( parser-&amp;gt;lexer, token, Token::Token_Identifier ) ) {
        return;
    }

    *out_fragment = findCodeFragment( parser, token.text );
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;After all the stages of the current pass are parsed, we save the pass and finish parsing the file!&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;h1 id=&#34;shader-permutation-generation&#34;&gt;Shader Permutation Generation&lt;/h1&gt;
&lt;p&gt;The final step of this amazing journey is the simplest, and it is actually to generate the single files we need.&lt;!-- raw HTML omitted --&gt;
In our case another specific class, &lt;strong&gt;CodeGenerator&lt;/strong&gt;, will generate the different files from the parsed HFX file.&lt;/p&gt;
&lt;p&gt;After we&amp;rsquo;ve done with the parsing, we can call the &lt;strong&gt;generateShaderPermutations&lt;/strong&gt; method that will generate files for each shader stage in each pass:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;void generateShaderPermutations( CodeGenerator* code_generator, const char* path ) {

    code_generator-&amp;gt;string_buffer_0.clear();
    code_generator-&amp;gt;string_buffer_1.clear();
    code_generator-&amp;gt;string_buffer_2.clear();

    // For each pass and for each pass generate permutation file.
    const uint32_t pass_count = (uint32_t)code_generator-&amp;gt;parser-&amp;gt;passes.size();
    for ( uint32_t i = 0; i &amp;lt; pass_count; i++ ) {

        // Create one file for each code fragment
        const Pass&amp;amp; pass = code_generator-&amp;gt;parser-&amp;gt;passes[i];
        
        if ( pass.cs ) {
            outputCodeFragment( code_generator, path, CodeFragment::Compute, pass.cs );
        }

        if ( pass.fs ) {
            outputCodeFragment( code_generator, path, CodeFragment::Fragment, pass.fs );
        }

        if ( pass.vs ) {
            outputCodeFragment( code_generator, path, CodeFragment::Vertex, pass.vs );
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The code should be straightforward, and the real action happens into the &lt;strong&gt;outputCodeFragment&lt;/strong&gt; method.&lt;!-- raw HTML omitted --&gt;
Let&amp;rsquo;s have a look at the code.&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;p&gt;First we define some data, like the file extensions for each shader stage or the defines to compile the code:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// Additional data to be added to output shaders.
static const char*              s_shader_file_extension[CodeFragment::Count] = { &amp;quot;.vert&amp;quot;, &amp;quot;.frag&amp;quot;, &amp;quot;.compute&amp;quot;, &amp;quot;.h&amp;quot; };
static const char*              s_shader_stage_defines[CodeFragment::Count] = { &amp;quot;#define VERTEX\r\n&amp;quot;, &amp;quot;#define FRAGMENT\r\n&amp;quot;, &amp;quot;#define COMPUTE\r\n&amp;quot;, &amp;quot;&amp;quot; };
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Then we start to write the file.&lt;!-- raw HTML omitted --&gt;
We will use the &lt;em&gt;string_buffer_0&lt;/em&gt; to dynamically generate the path of the file without allocating memory:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;void outputCodeFragment( CodeGenerator* code_generator, const char* path, CodeFragment::Stage stage, const CodeFragment* code_fragment ) {
    // Create file
    FILE* output_file;

    code_generator-&amp;gt;string_buffer_0.clear();
    code_generator-&amp;gt;string_buffer_0.append( path );
    code_generator-&amp;gt;string_buffer_0.append( code_fragment-&amp;gt;name );
    code_generator-&amp;gt;string_buffer_0.append( s_shader_file_extension[stage] );
    fopen_s( &amp;amp;output_file, code_generator-&amp;gt;string_buffer_0.data, &amp;quot;wb&amp;quot; );

    if ( !output_file ) {
        printf( &amp;quot;Error opening file. Aborting. \n&amp;quot; );
        return;
    }

&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;And then use &lt;em&gt;string_buffer_1&lt;/em&gt; to instead generate the actual code into the file.&lt;!-- raw HTML omitted --&gt;
First, and most important, we will add all the includes for this particular stage by opening the file, reading it into memory and adding it into the final code buffer.&lt;/p&gt;
&lt;p&gt;We will still use &lt;em&gt;string_buffer_0&lt;/em&gt; to generate the path of the file:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    code_generator-&amp;gt;string_buffer_1.clear();

    // Append includes for the current stage.
    for ( size_t i = 0; i &amp;lt; code_fragment-&amp;gt;includes.size(); i++ ) {
        if ( code_fragment-&amp;gt;includes_stage[i] != stage &amp;amp;&amp;amp; code_fragment-&amp;gt;includes_stage[i] != CodeFragment::Common ) {
            continue;
        }

        // Open and read file
        code_generator-&amp;gt;string_buffer_0.clear();
        code_generator-&amp;gt;string_buffer_0.append( path );
        code_generator-&amp;gt;string_buffer_0.append( code_fragment-&amp;gt;includes[i] );
        char* include_code = ReadEntireFileIntoMemory( code_generator-&amp;gt;string_buffer_0.data, nullptr );

        code_generator-&amp;gt;string_buffer_1.append( include_code );
        code_generator-&amp;gt;string_buffer_1.append( &amp;quot;\r\n&amp;quot; );
    }

&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;After that is done we can copy the define needed for the current shader stage:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    code_generator-&amp;gt;string_buffer_1.append( &amp;quot;\t\t&amp;quot; );
    code_generator-&amp;gt;string_buffer_1.append( s_shader_stage_defines[stage] );

&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;And finally the actual code:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    code_generator-&amp;gt;string_buffer_1.append( &amp;quot;\r\n\t\t&amp;quot; );
    code_generator-&amp;gt;string_buffer_1.append( code_fragment-&amp;gt;code );

&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Write to file and close it and we are done!&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    fprintf( output_file, &amp;quot;%s&amp;quot;, code_generator-&amp;gt;string_buffer_1.data );

    fclose( output_file );
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;And this will generate the shader permutations for each pass with a single file, using the standard GLSL convention for files extensions.&lt;/p&gt;
&lt;h1 id=&#34;conclusions-and-next-part&#34;&gt;Conclusions and next part&lt;/h1&gt;
&lt;p&gt;We parsed our simple &lt;em&gt;shader language&lt;/em&gt; to enhance and embed &lt;em&gt;glsl&lt;/em&gt; code fragments into our codebase by generating single files that can be used into any OpenGL based renderer.&lt;!-- raw HTML omitted --&gt;
We also laid out the foundation for a more powerful tool - namely code generation - even though there are some intermediate steps to be taken to arrive there.&lt;!-- raw HTML omitted --&gt;
First of all, we will need a target rendering library (something like the amazing &lt;a href=&#34;https://github.com/floooh/sokol&#34;&gt;Sokol&lt;/a&gt;), so we can specialize our CPU rendering code. I already wrote something like Sokol but with a more Vulkan/D3D12 interface in mind, and I will use that. Still unsure if I will write a specific post on that.&lt;/p&gt;
&lt;p&gt;In the next article we will add support for the new graphics library and develop the language more to generate code that will manage Constant buffers, automatically creating a CPU-side class, adding UI to edit it in realtime and possibly load/save the values.&lt;/p&gt;
&lt;p&gt;Of course, any feedback/improvements/suggestions on anything related here (article, code, etc) please let me know.&lt;/p&gt;
&lt;p&gt;Stay tuned!
Gabriel&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Writing a simple Code Generator</title>
      <link>https://jorenjoestar.github.io/post/writing_a_simple_code_generator/</link>
      <pubDate>Sat, 27 Jul 2019 18:46:03 -0400</pubDate>
      
      <guid>https://jorenjoestar.github.io/post/writing_a_simple_code_generator/</guid>
      <description>





&lt;figure&gt;

  &lt;a data-fancybox=&#34;&#34; href=&#34;front.png&#34; &gt;

&lt;img src=&#34;front.png&#34; &gt;
&lt;/a&gt;


&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;UI using ImGUI, SDL and the code generated with this article.&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;h1 id=&#34;motivation&#34;&gt;Motivation&lt;/h1&gt;
&lt;p&gt;Following my previous article about Flatbuffers and data reflection the quest for Data-Driven Rendering continues!&lt;!-- raw HTML omitted --&gt;
In this article I want to show how to write a very simple code-generator to help you automate writing of code in any language.&lt;!-- raw HTML omitted --&gt;
The code is here:&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/JorenJoestar/DataDrivenRendering&#34;&gt;https://github.com/JorenJoestar/DataDrivenRendering&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;There is a balance that constantly needs to be found between code and data, and having a code-generator in my opinion helps tremendously in focus on the code that is necessary to be written.&lt;!-- raw HTML omitted --&gt;
From a data perspective, normally the ‘baking’ pipeline is a series of DCC formats as source transformed into very project specific and optimized data.&lt;!-- raw HTML omitted --&gt;
Code-wise, depending on the engine/technology you are using, ‘baking’ of the code is more uncommon.&lt;!-- raw HTML omitted --&gt;
In a time in which iteration time has become almost more important than the tech itself, playing with this balance can be the key for any successful software. It could sound exaggerated, but I really believe in that.&lt;!-- raw HTML omitted --&gt;
As always, both ImGui and SDL will be our sword and shields for this adventure.&lt;!-- raw HTML omitted --&gt;
This will be the second step into data-driven rendering: code generation.&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;h2 id=&#34;are-we-writing-a-compiler-&#34;&gt;Are we writing a compiler ?&lt;/h2&gt;
&lt;p&gt;Short answer: yes!&lt;/p&gt;
&lt;p&gt;Long answer: we will be writing the simplest possible compiler that reads a source file and transform in a destination file, like Flatbuffers.&lt;/p&gt;
&lt;p&gt;There are few links on both theory and practice that can help shed some light on the subject:
The “Dragon Book” (called because of the dragon in the cover) is still THE to-go in compiler writing as far as I know.&lt;!-- raw HTML omitted --&gt;
It is an intense book and explores writing a full compiler with depth, starting from &lt;em&gt;Automata theory&lt;/em&gt; (just reminds me of how everything you study can be useful, I did 2 exams at University about that, wondering when I would use it! Hello prof &lt;a href=&#34;http://www.dia.uniroma3.it/~compunet/www/view/person.php?id=gdb&#34;&gt;Di Battista!&lt;/a&gt;) to full code examples:&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.amazon.com/Compilers-Principles-Techniques-Tools-2nd/dp/0321486811&#34;&gt;https://www.amazon.com/Compilers-Principles-Techniques-Tools-2nd/dp/0321486811&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This is for me the best website on the subject, very precise and readable and follows closely what is inside the Dragon Book:&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://craftinginterpreters.com/&#34;&gt;https://craftinginterpreters.com/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;And github page:&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/munificent/craftinginterpreters&#34;&gt;https://github.com/munificent/craftinginterpreters&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;My interest was rekindled in 2015, when I was following the amazing Casey Muratori and his &lt;a href=&#34;https://handmadehero.org/&#34;&gt;Handmade Hero&lt;/a&gt;.&lt;!-- raw HTML omitted --&gt;
He generates code for introspection purposes, and really show a simple and effective way of generating code that works for you.&lt;/p&gt;
&lt;p&gt;Wikipedia itself also contains a lot of good articles on the subject. The more you know about the it, the more you want to know.
It is fascinating and very, very deep!&lt;/p&gt;
&lt;h1 id=&#34;compiler-101&#34;&gt;Compiler 101&lt;/h1&gt;
&lt;p&gt;A real compiler is a very complex and fascinating subject/software so I will try to get the simplest possible approach giving my (flawed and incomplete) perspective.&lt;/p&gt;
&lt;p&gt;A compiler is a series of transformations applied to data (you can apply this definition to every software actually…).&lt;/p&gt;
&lt;p&gt;The input data is a text, and normally the output is still text, but with very different meaning.&lt;/p&gt;
&lt;p&gt;The raw depth of the subject is astonishing, consider that we are defining a grammar and thus a language, and how to express concepts into it.&lt;/p&gt;
&lt;p&gt;The main steps are the following:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Lexer/scanner/tokenizer&lt;/li&gt;
&lt;li&gt;Parser&lt;/li&gt;
&lt;li&gt;Code generation&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;We will define the code generator from a custom language called HDF (&lt;strong&gt;Hydra Definition Format&lt;/strong&gt;) to C++.
HDF will be a subset of &lt;strong&gt;Flatbuffers&lt;/strong&gt; in this exercise, but once the concepts are clear it can be expanded to more stuff.&lt;/p&gt;
&lt;h1 id=&#34;lexerscannertokenizer&#34;&gt;Lexer/Scanner/Tokenizer&lt;/h1&gt;
&lt;p&gt;A &lt;strong&gt;lexer&lt;/strong&gt; or &lt;strong&gt;scanner&lt;/strong&gt; (or &lt;strong&gt;tokenizer&lt;/strong&gt;) is a software that translates an input string into a list of Tokens based on Lexemes.
A &lt;strong&gt;Lexeme&lt;/strong&gt; is one or more characters that create a Token. Think of a keyword (like ‘if’, ‘class’, ‘static’ …).&lt;/p&gt;
&lt;p&gt;A Token is identified by a unique Lexeme and abstracts the Lexeme itself.
It normally contains a type and some attributes, for example it can save where that lexeme is into the input text, the line. The final structure of the token can vary a bit.&lt;/p&gt;
&lt;p&gt;In trying to find a simple definition for this step:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The act of Tokenizing is the act of abstracting the input text.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;For example, given the following input text:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;static void amazing_method() {};
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;It will generate the list of tokens ‘&lt;strong&gt;keyword, identifier, identifier, open parenthesis, close parenthesis, open brace, close brace, semicolon&lt;/strong&gt;’.&lt;/p&gt;
&lt;p&gt;This IS abstracting the text!&lt;/p&gt;
&lt;p&gt;Normally a lexer/scanner is used by the parser to go through the code and retrieve a token and use it in some way. Let’s start seeing what a lexer could be!&lt;/p&gt;
&lt;h2 id=&#34;code&#34;&gt;Code&lt;/h2&gt;
&lt;p&gt;Let&amp;rsquo;s see the code used by the lexer.&lt;/p&gt;
&lt;p&gt;First thing will be to define the Token:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// Lexer/Tokenizer code. It is abstract enough so is not grammar specific.
//
struct Token {

    enum Type {
        Token_Unknown,

        Token_OpenParen,
        Token_CloseParen,
        Token_Colon,
        Token_Semicolon,
        Token_Asterisk,
        Token_OpenBracket,
        Token_CloseBracket,
        Token_OpenBrace,
        Token_CloseBrace,
        Token_OpenAngleBracket,
        Token_CloseAngleBracket,

        Token_String,
        Token_Identifier,
        Token_Number,

        Token_EndOfStream,
    }; // enum Type

    Type                            type;
    StringRef                       text;

}; // struct Token
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;It is basically a enum with a StringRef.&lt;!-- raw HTML omitted --&gt;
A StringRef is basically a substring - used to avoid allocations when parsing by simply saving where the Token is in the parsed text and how long it is.&lt;/p&gt;
&lt;p&gt;Next is the Lexer itself:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;//
// The role of the Lexer is to divide the input string into a list of Tokens.
struct Lexer {
    
    char*                           position            = nullptr;    
    uint32_t                        line                = 0;
    uint32_t                        column              = 0;

    bool                            error               = false;
    uint32_t                        error_line          = 0;

}; // struct Lexer
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The most important variable is &lt;strong&gt;position&lt;/strong&gt; - it saves where the Lexer is in the current text for parsing.&lt;/p&gt;
&lt;p&gt;From now on there will be only methods.&lt;/p&gt;
&lt;p&gt;First some character classification that will help the Lexer:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;//
// All those methods are to classify a character.
//
inline bool IsEndOfLine( char c ) {
    bool Result = ((c == &#39;\n&#39;) || (c == &#39;\r&#39;));
    return(Result);
}

inline bool IsWhitespace( char c ) {
    bool Result = ((c == &#39; &#39;) || (c == &#39;\t&#39;) || (c == &#39;\v&#39;) || (c == &#39;\f&#39;) || IsEndOfLine( c ));
    return(Result);
}

inline bool IsAlpha( char c ) {
    bool Result = (((c &amp;gt;= &#39;a&#39;) &amp;amp;&amp;amp; (c &amp;lt;= &#39;z&#39;)) || ((c &amp;gt;= &#39;A&#39;) &amp;amp;&amp;amp; (c &amp;lt;= &#39;Z&#39;)));
    return(Result);
}

inline bool IsNumber( char c ) {
    bool Result = ((c &amp;gt;= &#39;0&#39;) &amp;amp;&amp;amp; (c &amp;lt;= &#39;9&#39;));
    return(Result);
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;These should be quite straightforward.&lt;/p&gt;
&lt;p&gt;Then we have &lt;strong&gt;the most important method for the lexer: nextToken&lt;/strong&gt;.&lt;!-- raw HTML omitted --&gt;
This method will contain all the logic to go to the next token, and we will see it step by step.&lt;/p&gt;
&lt;p&gt;First is skipping all the whitespaces (empty characters, tabs, returns, etc) to arrive at the correct character in the text.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;//
// This is the main method. Skip whitespaces and get next token. Save also the current position in the input string.
//
void nextToken( Lexer* lexer, Token&amp;amp; token ) {

    // Skip all whitespace first so that the token is without them.
    skipWhitespace( lexer );
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The code for skipping the whitespace is pretty straight-forward.
First it checks if it is a pure whitespace:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;void skipWhitespace( Lexer* lexer ) {
    // Scan text until whitespace is finished.
    for ( ;; ) {
        // Check if it is a pure whitespace first.
        if ( IsWhitespace( lexer-&amp;gt;position[0] ) ) {
            // Handle change of line
            if ( IsEndOfLine( lexer-&amp;gt;position[0] ) )
                ++lexer-&amp;gt;line;

            // Advance to next character
            ++lexer-&amp;gt;position;

&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Then it checks if it is a single line comment:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;        } // Check for single line comments (&amp;quot;//&amp;quot;)
        else if ( (lexer-&amp;gt;position[0] == &#39;/&#39;) &amp;amp;&amp;amp; (lexer-&amp;gt;position[1] == &#39;/&#39;) ) {
            lexer-&amp;gt;position += 2;
            while ( lexer-&amp;gt;position[0] &amp;amp;&amp;amp; !IsEndOfLine( lexer-&amp;gt;position[0] ) ) {
                ++lexer-&amp;gt;position;
            }
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;And last it checks for c-style multiline comments:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;        } // Check for c-style multi-lines comments
        else if ( (lexer-&amp;gt;position[0] == &#39;/&#39;) &amp;amp;&amp;amp; (lexer-&amp;gt;position[1] == &#39;*&#39;) ) {
            lexer-&amp;gt;position += 2;

            // Advance until the string is closed. Remember to check if line is changed.
            while ( !((lexer-&amp;gt;position[0] == &#39;*&#39;) &amp;amp;&amp;amp; (lexer-&amp;gt;position[1] == &#39;/&#39;)) ) {
                // Handle change of line
                if ( IsEndOfLine( lexer-&amp;gt;position[0] ) )
                    ++lexer-&amp;gt;line;

                // Advance to next character
                ++lexer-&amp;gt;position;
            }

            if ( lexer-&amp;gt;position[0] == &#39;*&#39; ) {
                lexer-&amp;gt;position += 2;
            }
        }
        else {
            break;
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;After skipped all the whitespaces, we initialize the new token:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    // Initialize token
    token.type = Token::Token_Unknown;
    token.text.text = lexer-&amp;gt;position;
    token.text.length = 1;
    token.line = lexer-&amp;gt;line;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;We get the current character and advance the position, so we can analize it.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    char c = lexer-&amp;gt;position[0];
    ++lexer-&amp;gt;position;

&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Here comes the character analisys using a simple &lt;strong&gt;switch&lt;/strong&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
    switch ( c ) {
        case &#39;\0&#39;:
        {
            token.type = Token::Token_EndOfStream;
        } break;
        case &#39;(&#39;:
        {
            token.type = Token::Token_OpenParen;
        } break;
        case &#39;)&#39;:
        {
            token.type = Token::Token_CloseParen;
        } break;
        case &#39;:&#39;:
        {
            token.type = Token::Token_Colon;
        } break;
        case &#39;;&#39;:
        {
            token.type = Token::Token_Semicolon;
        } break;
        case &#39;*&#39;:
        {
            token.type = Token::Token_Asterisk;
        } break;
        case &#39;[&#39;:
        {
            token.type = Token::Token_OpenBracket;
        } break;
        case &#39;]&#39;:
        {
            token.type = Token::Token_CloseBracket;
        } break;
        case &#39;{&#39;:
        {
            token.type = Token::Token_OpenBrace;
        } break;
        case &#39;}&#39;:
        {
            token.type = Token::Token_CloseBrace;
        } break;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;There are some special cases left.&lt;!-- raw HTML omitted --&gt;
First parsing a string starting from a &amp;lsquo;&amp;quot;&amp;rsquo; character.&lt;!-- raw HTML omitted --&gt;
It requires to scan the text until it finds another &amp;lsquo;&amp;quot;&amp;rsquo; to indicate the end of the string.&lt;!-- raw HTML omitted --&gt;
It also supports multiple-line strings with the characters &amp;ldquo;\&amp;rdquo; (double back-slash)&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
        case &#39;&amp;quot;&#39;:
        {
            token.type = Token::Token_String;

            token.text.text = lexer-&amp;gt;position;

            while ( lexer-&amp;gt;position[0] &amp;amp;&amp;amp;
                    lexer-&amp;gt;position[0] != &#39;&amp;quot;&#39; )
            {
                if ( (lexer-&amp;gt;position[0] == &#39;\\&#39;) &amp;amp;&amp;amp;
                     lexer-&amp;gt;position[1] )
                {
                    ++lexer-&amp;gt;position;
                }
                ++lexer-&amp;gt;position;
            }

            // Saves total string length
            token.text.length = lexer-&amp;gt;position - token.text.text;

            if ( lexer-&amp;gt;position[0] == &#39;&amp;quot;&#39; ) {
                ++lexer-&amp;gt;position;
            }
        } break;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Then the final classification step: first is checking if the token is an identifier (a string literal that starts with a character and is followed by characters, underscores or numbers).&lt;!-- raw HTML omitted --&gt;
If not a identifier, check to see if it is a number. This should be expanded to correctly parse numbers, but for now is not used.&lt;!-- raw HTML omitted --&gt;.
If everything else fails, than we don&amp;rsquo;t recognize the token.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;        default:
        {
            // Identifier/keywords
            if ( IsAlpha( c ) ) {
                token.type = Token::Token_Identifier;

                while ( IsAlpha( lexer-&amp;gt;position[0] ) || IsNumber( lexer-&amp;gt;position[0] ) || (lexer-&amp;gt;position[0] == &#39;_&#39;) ) {
                    ++lexer-&amp;gt;position;
                }

                token.text.length = lexer-&amp;gt;position - token.text.text;
            } // Numbers
            else if ( IsNumber( c ) ) {
                token.type = Token::Token_Number;
            }
            else {
                token.type = Token::Token_Unknown;
            }
        } break;
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;With this code we already have a working Lexer!&lt;!-- raw HTML omitted --&gt;
I like to use the lexer in an abstract way - not knowing anything about the underlying language - so that it can be reused for different custom languages (Dr.Wily eyebrows movement goes here).&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;p&gt;If you want to dive deeper into this, the amazing Crafting Interpreters contains a great page on scanning:&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.craftinginterpreters.com/scanning.html&#34;&gt;https://www.craftinginterpreters.com/scanning.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Also, some c-style parsing can be found here from the amazing &lt;a href=&#34;https://twitter.com/niklasfrykholm&#34;&gt;Niklas Frykohlm&lt;/a&gt;:&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/niklasfrykholm/nflibs/blob/master/nf_json_parser.c&#34;&gt;https://github.com/niklasfrykholm/nflibs/blob/master/nf_json_parser.c&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;And another amazing parser from STB:&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/nothings/stb/blob/master/stb_c_lexer.h&#34;&gt;https://github.com/nothings/stb/blob/master/stb_c_lexer.h&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;parser&#34;&gt;Parser&lt;/h1&gt;
&lt;p&gt;So far we have abstracted the input text into a list of &lt;strong&gt;Tokens&lt;/strong&gt;, and now we need to generate some more information before arriving at generating new code.&lt;/p&gt;
&lt;p&gt;As far as &lt;em&gt;I understood it&lt;/em&gt;, a parser reads the tokens and generates an &lt;strong&gt;Abstract Syntax Tree&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Sometimes, and in simpler parsers, the act of parsing itself can generates a new code if the language we are targeting is simple.
Again, I prefer to separate Lexer and Parser to reuse the Lexer for different languages and separate the responsabilities!&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Given a list of tokens and a grammar, a parser generates an Abstract Syntax Tree.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;It gives meaning to the input text, and is responsible to check the syntax correctness.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;A simple definition for a grammar is the following:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;A grammar is a set of production rules that transforms a series of non-terminals into terminals.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Putting everything in the perspective of data and transformations we can define:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Terminals&lt;/strong&gt; are finalized data&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Non-terminals&lt;/strong&gt; are data that must be transformed&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Production rules&lt;/strong&gt; are transformations of &lt;strong&gt;non-terminals&lt;/strong&gt; to &lt;strong&gt;terminals&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Another definition of a parser than it could be :&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;A parser is a software that transforms non-terminals in terminals following production rules.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;grammar&#34;&gt;Grammar&lt;/h2&gt;
&lt;p&gt;It is time to write the formal grammar (a context-free grammar) and see how it maps to code.&lt;!-- raw HTML omitted --&gt;
It will be very simple — much simpler than many examples you find around — but it is a starting point.&lt;!-- raw HTML omitted --&gt;
We will not deal with any expression, statements and such, not in the context of this code generator. I will point out some examples for more complex stuff, but I want to study more the subject for that to be more precise about the subject.&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;p&gt;Each line will be a &lt;strong&gt;production rule&lt;/strong&gt; (a transformation), with the left-side being always a non-terminal.&lt;!-- raw HTML omitted --&gt;
We are using regular expressions syntax here:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;alphabet → [a-zA-z]&lt;/li&gt;
&lt;li&gt;number →[0–9]&lt;/li&gt;
&lt;li&gt;identifier → alphabet (alphabet | number | “_”)*&lt;/li&gt;
&lt;li&gt;variable_declaration → identifier identifier “;”&lt;/li&gt;
&lt;li&gt;struct_declaration → “struct” identifier “{“ (variable_declaration)+ “}” “;”&lt;/li&gt;
&lt;li&gt;enum_declaration → “enum” identifier “{“ (identifier)+ “}”&lt;/li&gt;
&lt;li&gt;module → (struct_declaration | enum_declaration)+*&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;First we define what an identifier is — a sequence of alpha-numerical characters that can contains also the underscore character.&lt;!-- raw HTML omitted --&gt;Notice that with the identifier production rule, the identifier cannot start with an underscore.&lt;!-- raw HTML omitted --&gt;
A variable then is declared simply by two identifiers: the first for the type and the second for the name, following a semicolon.&lt;!-- raw HTML omitted --&gt;
A struct is simply a list of variable declarations. Notice the “+” in the rule — this means that at least one element must be present.&lt;!-- raw HTML omitted --&gt;
Enums are literally a name for the enum and a list of identifiers in curly braces.&lt;!-- raw HTML omitted --&gt;
Finally the module is the root of our grammar. It will contain all the declarations we describe. See it as the data file we are writing to generate the code — one file is one module.&lt;!-- raw HTML omitted --&gt;
Now that we defined a simple grammar, we can move to the theory behind the parser.&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;h2 id=&#34;predictive-recursive-descent-parser&#34;&gt;Predictive Recursive Descent Parser&lt;/h2&gt;
&lt;p&gt;The grammar we defined is a context-free-grammar.&lt;!-- raw HTML omitted --&gt;
Depending on the type of grammar we can write different parsers.&lt;!-- raw HTML omitted --&gt;
One of the most common type of parser (and easier to start with) is the &lt;a href=&#34;https://en.wikipedia.org/wiki/Recursive_descent_parser&#34;&gt;Predictive Recursive Descent Parser&lt;/a&gt;, and that is what we will write given our grammar. You can dive into all the details of writing a context-free grammar, writing a &lt;a href=&#34;https://en.wikipedia.org/wiki/LL_parser&#34;&gt;Left-to-right Leftmost-derivation grammar (LL(k))&lt;/a&gt; and such and be amazed by all the concepts behind.&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;p&gt;Again, I am personally starting on this subject, so my knowledge is not deep.&lt;/p&gt;
&lt;p&gt;Back to the parser, the main characteristics of this parser are:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Descent = top-down. Start from root and generate the Abstract Syntax Tree.&lt;/li&gt;
&lt;li&gt;Recursive = the parser has mutually recursive methods, one for each non-terminal.&lt;/li&gt;
&lt;li&gt;Predictive = no backtracking needed. For our simple grammar we do not need any backtracking.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;So the parser will start from the root (module non-terminal) and by sequentially reading all the tokens will generate a tree that represent our syntax.&lt;/p&gt;
&lt;p&gt;Let’s see some code!&lt;/p&gt;
&lt;h2 id=&#34;code-1&#34;&gt;Code&lt;/h2&gt;
&lt;p&gt;The central piece of code is the Parser.&lt;!-- raw HTML omitted --&gt;
It uses the Lexer and saves the Types by parsing the input text.&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;//
// The Parser parses Tokens using the Lexer and generate an Abstract Syntax Tree.
struct Parser {

    Lexer*                          lexer               = nullptr;

    ast::Type*                      types               = nullptr;
    uint32_t                        types_count         = 0;
    uint32_t                        types_max           = 0;

}; // struct Parser
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Let&amp;rsquo;s have a look at the class &lt;strong&gt;Type&lt;/strong&gt;.&lt;!-- raw HTML omitted --&gt;
This class will let us identify correctly primitive types, enums, struct and &lt;em&gt;commands&lt;/em&gt; - a special keyword I create to show a concept that can be used away from the canonical C/C++ languages.&lt;!-- raw HTML omitted --&gt;
By saving a list of names and types we can successfully parse all the types listed above.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;//
// Define the language specific structures.
namespace ast {

    struct Type {

        enum Types {
            Types_Primitive, Types_Enum, Types_Struct, Types_Command, Types_None
        };

        enum PrimitiveTypes {
            Primitive_Int32, Primitive_Uint32, Primitive_Int16, Primitive_Uint16, Primitive_Int8, Primitive_Uint8, Primitive_Int64, Primitive_Uint64, Primitive_Float, Primitive_Double, Primitive_Bool, Primitive_None
        };

        Types                       type;
        PrimitiveTypes              primitive_type;
        StringRef                   name;

        std::vector&amp;lt;StringRef&amp;gt;      names;
        std::vector&amp;lt;const Type*&amp;gt;    types;
        bool                        exportable = true;

    }; // struct Type

} // namespace ast
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;And now the actual code making the magic happens!&lt;!-- raw HTML omitted --&gt;
Entry point for the parsing is generateAST.&lt;!-- raw HTML omitted --&gt;
It simply goes through ALL the tokens until it reaches the end of the file.&lt;!-- raw HTML omitted --&gt;
At this level of parsing, we parse only identifiers (keywords like &amp;lsquo;struct&amp;rsquo;, &amp;lsquo;enum&amp;rsquo;, &amp;hellip;).&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;void generateAST( Parser* parser ) {

    // Read source text until the end.
    // The main body can be a list of declarations.
    bool parsing = true;

    while ( parsing ) {

        Token token;
        nextToken( parser-&amp;gt;lexer, token );

        switch ( token.type ) {

            case Token::Token_Identifier:
            {
                identifier( parser, token );
                break;
            }

            case Token::Type::Token_EndOfStream:
            {
                parsing = false;
                break;
            }
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The method &amp;lsquo;identifier&amp;rsquo; searches for the language keywords and acts accordingly.&lt;!-- raw HTML omitted --&gt;
The method &amp;lsquo;expectKeyword&amp;rsquo; simply checks that the keywords are the same.&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;inline void identifier( Parser* parser, const Token&amp;amp; token ) {

    // Scan the name to know which 
    for ( uint32_t i = 0; i &amp;lt; token.text.length; ++i ) {
        char c = *(token.text.text + i);

        switch ( c ) {
            case &#39;s&#39;:
            {
                if ( expectKeyword( token.text, 6, &amp;quot;struct&amp;quot; ) ) {
                    declarationStruct( parser );
                    return;
                }
                    
                break;
            }

            case &#39;e&#39;:
            {
                if ( expectKeyword( token.text, 4, &amp;quot;enum&amp;quot; ) ) {
                    declarationEnum( parser );
                    return;
                }
                break;
            }

            case &#39;c&#39;:
            {
                if ( expectKeyword( token.text, 7, &amp;quot;command&amp;quot; ) ) {
                    declarationCommand( parser );
                    return;
                }
                break;
            }
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The next methods are the real core of parsing a language.
When declaring a struct, the token we have are:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Identifier &amp;lsquo;struct&amp;rsquo; (parsed already by generateAST method)&lt;/li&gt;
&lt;li&gt;Name of the struct&lt;/li&gt;
&lt;li&gt;Open braces&lt;/li&gt;
&lt;li&gt;Zero or more variables&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The method expectToken checks the presence of the expected token and saves the line if an error occurs.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;inline void declarationStruct( Parser* parser ) {
    // name
    Token token;
    if ( !expectToken( parser-&amp;gt;lexer, token, Token::Token_Identifier ) ) {
        return;
    }

    // Cache name string
    StringRef name = token.text;
    
    if ( !expectToken( parser-&amp;gt;lexer, token, Token::Token_OpenBrace ) ) {
        return;
    }

    // Add new type
    ast::Type&amp;amp; type = parser-&amp;gt;types[parser-&amp;gt;types_count++];
    type.name = name;
    type.type = ast::Type::Types_Struct;
    type.exportable = true;

    // Parse struct internals
    while ( !equalToken( parser-&amp;gt;lexer, token, Token::Token_CloseBrace ) ) {

        if ( token.type == Token::Token_Identifier ) {
            declarationVariable( parser, token.text, type );
        }
    }
}

&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The parsing of a variable is even simpler, just a type followed by the name.
When reading the type, it searches through the list of all types saved until then.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;inline void declarationVariable( Parser* parser, const StringRef&amp;amp; type_name, ast::Type&amp;amp; type ) {
    const ast::Type* variable_type = findType( parser, type_name );
    Token token;
    // Name
    if ( !expectToken( parser-&amp;gt;lexer, token, Token::Token_Identifier ) ) {
        return;
    }

    // Cache name string
    StringRef name = token.text;

    if ( !expectToken( parser-&amp;gt;lexer, token, Token::Token_Semicolon ) ) {
        return;
    }

    type.types.emplace_back( variable_type );
    type.names.emplace_back( name );
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The parsing of the enum is:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&amp;lsquo;enum&amp;rsquo; keyword&lt;/li&gt;
&lt;li&gt;Enum name&lt;/li&gt;
&lt;li&gt;(optional) Semicolon and type, taken from Flatbuffers syntax&lt;/li&gt;
&lt;li&gt;Open brace&lt;/li&gt;
&lt;li&gt;List of identifiers that corresponds to the enum values&lt;/li&gt;
&lt;/ol&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;pre&gt;&lt;code&gt;
inline void declarationEnum( Parser* parser ) {
    Token token;
    // Name
    if ( !expectToken( parser-&amp;gt;lexer, token, Token::Token_Identifier ) ) {
        return;
    }

    // Cache name string
    StringRef name = token.text;

    // Optional &#39;: type&#39; for the enum
    nextToken( parser-&amp;gt;lexer, token );
    if ( token.type == Token::Token_Colon ) {
        // Skip to open brace
        nextToken( parser-&amp;gt;lexer, token );
        // Token now contains type_name
        nextToken( parser-&amp;gt;lexer, token );
        // Token now contains open brace.
    }
    
    if ( token.type != Token::Token_OpenBrace ) {
        return;
    }

    // Add new type
    ast::Type&amp;amp; type = parser-&amp;gt;types[parser-&amp;gt;types_count++];
    type.name = name;
    type.type = ast::Type::Types_Enum;
    type.exportable = true;

    // Parse struct internals
    while ( !equalToken( parser-&amp;gt;lexer, token, Token::Token_CloseBrace ) ) {

        if ( token.type == Token::Token_Identifier ) {
            type.names.emplace_back( token.text );
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;A command is a special construct that I use in my code, normally with a CommandBuffer, and with the current syntax from HDF:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;command WindowEvents {
    Click {
      int16 x;
      int16 y;
      int16 button;
    }
    Move {
      int16 x;
      int16 y;
    }
    Wheel {
       int16 z;
    }
};
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;And this is the parsing of the command.&lt;!-- raw HTML omitted --&gt;
I think this can be the best example of mapping between the language and the parsing.&lt;!-- raw HTML omitted --&gt;
Parsing is:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Name&lt;/li&gt;
&lt;li&gt;Open brace&lt;/li&gt;
&lt;li&gt;Scan of identifiers until close brace&lt;/li&gt;
&lt;li&gt;For each identifier, add a type and scan for internal variables.&lt;/li&gt;
&lt;/ol&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;pre&gt;&lt;code&gt;inline void declarationCommand( Parser* parser ) {
    // name
    Token token;
    if ( !expectToken( parser-&amp;gt;lexer, token, Token::Token_Identifier ) ) {
        return;
    }

    // Cache name string
    StringRef name = token.text;

    if ( !expectToken( parser-&amp;gt;lexer, token, Token::Token_OpenBrace ) ) {
        return;
    }

    // Add new type
    ast::Type&amp;amp; command_type = parser-&amp;gt;types[parser-&amp;gt;types_count++];
    command_type.name = name;
    command_type.type = ast::Type::Types_Command;
    command_type.exportable = true;

    // Parse struct internals
    while ( !equalToken( parser-&amp;gt;lexer, token, Token::Token_CloseBrace ) ) {

        if ( token.type == Token::Token_Identifier ) {
            // Create a new type for each command
            // Add new type
            ast::Type&amp;amp; type = parser-&amp;gt;types[parser-&amp;gt;types_count++];
            type.name = token.text;
            type.type = ast::Type::Types_Struct;
            type.exportable = false;

            while ( !equalToken( parser-&amp;gt;lexer, token, Token::Token_CloseBrace ) ) {
                if ( token.type == Token::Token_Identifier ) {
                    declarationVariable( parser, token.text, type );
                }
            }

            command_type.names.emplace_back( type.name );
            command_type.types.emplace_back( &amp;amp;type );
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;abstract-syntax-tree&#34;&gt;Abstract Syntax Tree&lt;/h2&gt;
&lt;p&gt;We choose to simply have data definitions, and I’ve decided that the nodes of the tree will be types.&lt;!-- raw HTML omitted --&gt;
A type can be a primitive type, a container of variables (like a Struct in C, but without methods) enums and commands.&lt;!-- raw HTML omitted --&gt;
Commands are just a way of showing the creation of a construct that I use and requires some boilerplate code, but I don’t want to write that code.&lt;!-- raw HTML omitted --&gt;
If we remember the definition of the class Type from the code before, it all boils down to a name,a list of names and optionally types.&lt;!-- raw HTML omitted --&gt;
With this simple definition I can express primitive types, structs and enums all in one!&lt;!-- raw HTML omitted --&gt;
For enums, I save the anme of the enum and in the name list all the different values. That is enough to later generate the code.&lt;!-- raw HTML omitted --&gt;
For structs, again the name is saved, and then the variables. A variable is a tuple of identifiers ‘type, name’. When parsing them, the type is searched in the registered ones.&lt;!-- raw HTML omitted --&gt;
A trick here is to initialize the parser with primitive types, and then add each type (both struct and enums) when parsing them.&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;h1 id=&#34;code-generation&#34;&gt;Code Generation&lt;/h1&gt;
&lt;p&gt;The last stage will generate the files in the language that we want, using the informations from the &lt;strong&gt;AST&lt;/strong&gt;.&lt;!-- raw HTML omitted --&gt;
This part will literally write the code for us, the all purpose of this code.&lt;!-- raw HTML omitted --&gt;
The most fundamental question is: &lt;em&gt;“what code do I want to generate?”&lt;/em&gt;.&lt;!-- raw HTML omitted --&gt;
A simple but deep question.&lt;!-- raw HTML omitted --&gt;
We are trying to remove the writing of boilerplate code from or lives, so anything that you consider boilerplate and easy to automate goes here.
Even if until here we wrote in C++, the final output can be any language.&lt;!-- raw HTML omitted --&gt;
This means that you can define data and translate it to multiple languages!&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;p&gt;For our example, we will output C++ code and add UI using ImGui, similar to the Flatbuffers example I wrote before.&lt;!-- raw HTML omitted --&gt;
Let’s see the three different construct we can output with our language.&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;h2 id=&#34;enum&#34;&gt;Enum&lt;/h2&gt;
&lt;p&gt;We defined an enum as a name and a list of named values.
For the simplicity of this example, we are not assigning manual values to the enum, but it is something easily changeable, and I will do it in the future.
Given the enum in HDF:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;enum BlendOperation : byte { Add, Subtract, RevSubtract, Min, Max }
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Which code do we want to generate ?&lt;/p&gt;
&lt;p&gt;When I write enums, I almost always need the stringed version of the values. Also I want to add a last value, Count, so that I can use it if I need to allocate anything based on the enum.&lt;!-- raw HTML omitted --&gt;
As a bonus, I can create a second enum with the bit shifts — called mask — for some use cases.&lt;!-- raw HTML omitted --&gt;
All of this will be automatically done by the code generator, starting with a simple enum!&lt;!-- raw HTML omitted --&gt;
In this piece of code, I will use three different streams for the different parts of the enum (enum itself, value names and mask) and combine them into the final generated file.&lt;!-- raw HTML omitted --&gt;
Also to note that the strings here are ‘String Ref’ — basically a string that points to the input source code and stores the length of the string, so that there is no need to allocate it newly.&lt;!-- raw HTML omitted --&gt;
I will use a temporary buffer to null terminate it and write into the output file.&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;p&gt;This will be the generated code:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;namespace BlendOperation {
	enum Enum {
		Add, Subtract, RevSubtract, Min, Max, Count
	};

	enum Mask {
		Add_mask = 1 &amp;lt;&amp;lt; 0, Subtract_mask = 1 &amp;lt;&amp;lt; 1, RevSubtract_mask = 1 &amp;lt;&amp;lt; 2, Min_mask = 1 &amp;lt;&amp;lt; 3, Max_mask = 1 &amp;lt;&amp;lt; 4, Count_mask = 1 &amp;lt;&amp;lt; 5
	};

	static const char* s_value_names[] = {
		&amp;quot;Add&amp;quot;, &amp;quot;Subtract&amp;quot;, &amp;quot;RevSubtract&amp;quot;, &amp;quot;Min&amp;quot;, &amp;quot;Max&amp;quot;, &amp;quot;Count&amp;quot;
	};

	static const char* ToString( Enum e ) {
		return s_value_names[(int)e];
	}
} // namespace BlendOperation
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The enum itself (inside a namespace), a mask and the string version for debugging purposes.&lt;!-- raw HTML omitted --&gt;
All generated from that one line!&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s go into a step by step review of the code.&lt;!-- raw HTML omitted --&gt;
First there is the initialization of some auxiliary buffers to handle dynamic strings without allocating memory.&lt;!-- raw HTML omitted --&gt;
These are the usages:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Values will contain all the enum comma separated values&lt;/li&gt;
&lt;li&gt;Value_names will contain the string version of the values&lt;/li&gt;
&lt;li&gt;Value_masks will contain an optional bitmask for the values.
&lt;!-- raw HTML omitted --&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;void outputCPPEnum( CodeGenerator* code_generator, FILE* output, const ast::Type&amp;amp; type ) {

    // Empty enum: skip output.
    if ( type.names.size() == 0 )
        return;

    code_generator-&amp;gt;string_buffer_0.clear();
    code_generator-&amp;gt;string_buffer_1.clear();
    code_generator-&amp;gt;string_buffer_2.clear();

    StringBuffer&amp;amp; values = code_generator-&amp;gt;string_buffer_0;
    StringBuffer&amp;amp; value_names = code_generator-&amp;gt;string_buffer_1;
    StringBuffer&amp;amp; value_masks = code_generator-&amp;gt;string_buffer_2;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;We start by adding the character &amp;lsquo;&amp;quot;&amp;rsquo; in the names - they will be C strings!&lt;!-- raw HTML omitted --&gt;
Then we have a couple of options, just as demonstration: add mask (for the bitmask) and add max, that adds a last element to the generated enum.&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    value_names.append( &amp;quot;\&amp;quot;&amp;quot; );

    bool add_max = true;
    bool add_mask = true;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Next step is the core: go through all the names saved in the enum &lt;strong&gt;ast::Type&lt;/strong&gt; during the &lt;strong&gt;parsing&lt;/strong&gt; phase, and add the literal as is in the enum, the literal in string version and optional mask.&lt;!-- raw HTML omitted --&gt;
We also need to take care of the enum with 1 values, they behave in a different way.&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    char name_buffer[256];

    // Enums with more than 1 values
    if ( type.names.size() &amp;gt; 1 ) {
        const uint32_t max_values = type.names.size() - 1;
        for ( uint32_t v = 0; v &amp;lt; max_values; ++v ) {

            if ( add_mask ) {
                value_masks.append( type.names[v] );
                value_masks.append( &amp;quot;_mask = 1 &amp;lt;&amp;lt; &amp;quot; );
                value_masks.append( _itoa( v, name_buffer, 10 ) );
                value_masks.append( &amp;quot;, &amp;quot; );
            }

            values.append( type.names[v] );
            values.append( &amp;quot;, &amp;quot; );

            value_names.append( type.names[v] );
            value_names.append( &amp;quot;\&amp;quot;, \&amp;quot;&amp;quot; );
        }

        if ( add_mask ) {
            value_masks.append( type.names[max_values] );
            value_masks.append( &amp;quot;_mask = 1 &amp;lt;&amp;lt; &amp;quot; );
            value_masks.append( _itoa( max_values, name_buffer, 10 ) );
        }

        values.append( type.names[max_values] );

        value_names.append( type.names[max_values] );
        value_names.append( &amp;quot;\&amp;quot;&amp;quot; );
    }
    else {
        
        if ( add_mask ) {
            value_masks.append( type.names[0] );
            value_masks.append( &amp;quot;_mask = 1 &amp;lt;&amp;lt; &amp;quot; );
            value_masks.append( _itoa( 0, name_buffer, 10 ) );
        }

        values.append( type.names[0] );

        value_names.append( type.names[0] );
        value_names.append( &amp;quot;\&amp;quot;&amp;quot; );
    }

&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;After writing all the values we can add the optional max value in the output:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    if ( add_max ) {
        values.append( &amp;quot;, Count&amp;quot; );

        value_names.append( &amp;quot;, \&amp;quot;Count\&amp;quot;&amp;quot; );

        if ( add_mask ) {
            value_masks.append( &amp;quot;, Count_mask = 1 &amp;lt;&amp;lt; &amp;quot; );
            value_masks.append( _itoa( type.names.size(), name_buffer, 10 ) );
        }
    }
    
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Until now we just saved all those values in the StringBuffers, but still not in the file.&lt;!-- raw HTML omitted --&gt;
The final piece of code output to file the enum with all the additional data:&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    copy( type.name, name_buffer, 256 );

    fprintf( output, &amp;quot;namespace %s {\n&amp;quot;, name_buffer );

    fprintf( output, &amp;quot;\tenum Enum {\n&amp;quot; );
    fprintf( output, &amp;quot;\t\t%s\n&amp;quot;, values.data );
    fprintf( output, &amp;quot;\t};\n&amp;quot; );

    // Write the mask
    if ( add_mask ) {
        fprintf( output, &amp;quot;\n\tenum Mask {\n&amp;quot; );
        fprintf( output, &amp;quot;\t\t%s\n&amp;quot;, value_masks.data );
        fprintf( output, &amp;quot;\t};\n&amp;quot; );
    }

    // Write the string values
    fprintf( output, &amp;quot;\n\tstatic const char* s_value_names[] = {\n&amp;quot; );
    fprintf( output, &amp;quot;\t\t%s\n&amp;quot;, value_names.data );
    fprintf( output, &amp;quot;\t};\n&amp;quot; );

    fprintf( output, &amp;quot;\n\tstatic const char* ToString( Enum e ) {\n&amp;quot; );
    fprintf( output, &amp;quot;\t\treturn s_value_names[(int)e];\n&amp;quot; );
    fprintf( output, &amp;quot;\t}\n&amp;quot; );

    fprintf( output, &amp;quot;} // namespace %s\n\n&amp;quot;, name_buffer );
}
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;struct&#34;&gt;Struct&lt;/h2&gt;
&lt;p&gt;Structs are the bread-and-butter of data definition.
In this simple example we do not handle pointers or references, so it is pretty straight-forward, but as a start in coding generation this could already be powerful for many cases.
Let’s start with a definition for our dream Data-Driven-Rendering:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// file.hdf
struct RenderTarget {
    uint16 			width;
    uint16 			height;
    float 			scale_x;
    float 			scale_y;
    TextureFormat 	format;
};

struct RenderPass {
    RenderTarget 	rt0;
};
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;We want to generate both the ready to use header in C++ and UI using ImGui.&lt;!-- raw HTML omitted --&gt;
The output for this struct will be obtained by simply iterating through all its members and, based on the type of the member, write some code.&lt;!-- raw HTML omitted --&gt;
For primitive types there is a translation that must be done to the C++ language — thus we saved a list of c++ primitive types keyword into the code.&lt;!-- raw HTML omitted --&gt;
For the UI area we will define two methods: reflectMembers, that simply adds the ImGui commands needed, and reflectUI, that embeds the members into a Window. This is done so that when starting from a root type I can create a window that let me edit its value, and recursively it can add other member’s UI if they are coming from another struct.&lt;!-- raw HTML omitted --&gt;
This is shown with the RenderPass struct.&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;p&gt;This will be the generated code, that includes ImGui too:&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// CodeGenerated.h

struct RenderTarget {

	uint16_t width;
	uint16_t height;
	float scale_x;
	float scale_y;
	TextureFormat::Enum format;

	void reflectMembers() {
		ImGui::InputScalar( &amp;quot;width&amp;quot;, ImGuiDataType_U16, &amp;amp;width );
		ImGui::InputScalar( &amp;quot;height&amp;quot;, ImGuiDataType_U16, &amp;amp;height );
		ImGui::InputScalar( &amp;quot;scale_x&amp;quot;, ImGuiDataType_Float, &amp;amp;scale_x );
		ImGui::InputScalar( &amp;quot;scale_y&amp;quot;, ImGuiDataType_Float, &amp;amp;scale_y );
		ImGui::Combo( &amp;quot;format&amp;quot;, (int32_t*)&amp;amp;format, TextureFormat::s_value_names, TextureFormat::Count );
	}

	void reflectUI() {
		ImGui::Begin(&amp;quot;RenderTarget&amp;quot;);
		reflectMembers();
		ImGui::End();
	}


}; // struct RenderTarget
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Now let&amp;rsquo;s have a look at the code that will generate that.&lt;!-- raw HTML omitted --&gt;
First some init steps: clear and alias the StringBuffer, allocate some char buffers on the stack, copy the StringRef into the name buffer:&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
void outputCPPStruct( CodeGenerator* code_generator, FILE* output, const ast::Type&amp;amp; type ) {
    const char* tabs = &amp;quot;&amp;quot;;

    code_generator-&amp;gt;string_buffer_0.clear();

    StringBuffer&amp;amp; ui_code = code_generator-&amp;gt;string_buffer_0;

    char name_buffer[256], member_name_buffer[256], member_type_buffer[256];
    copy( type.name, name_buffer, 256 );

&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Next is already a powerful piece of code.&lt;!-- raw HTML omitted --&gt;
Outputting the UI code and iterating through each member.&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    if ( code_generator-&amp;gt;generate_imgui ) {
        ui_code.append( &amp;quot;\n\tvoid reflectMembers() {\n&amp;quot; );
    }

    fprintf( output, &amp;quot;%sstruct %s {\n\n&amp;quot;, tabs, name_buffer );

    for ( int i = 0; i &amp;lt; type.types.size(); ++i ) {
        const ast::Type&amp;amp; member_type = *type.types[i];
        const StringRef&amp;amp; member_name = type.names[i];

        copy( member_name, member_name_buffer, 256 );

&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;We are in the middle of the loop, and we want to check if the current member type is a primitive one, then it needs some work to do.&lt;!-- raw HTML omitted --&gt;
First, output the language specific primitive type keyword (using the s_primitive_type_cpp array).&lt;!-- raw HTML omitted --&gt;
Second, add some ImGui code to edit the field directly.&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
        // Translate type name based on output language.
        switch ( member_type.type ) {
            case ast::Type::Types_Primitive:
            {
                strcpy_s( member_type_buffer, 256, s_primitive_type_cpp[member_type.primitive_type] );
                fprintf( output, &amp;quot;%s\t%s %s;\n&amp;quot;, tabs, member_type_buffer, member_name_buffer );
                
                if ( code_generator-&amp;gt;generate_imgui ) {
                    switch ( member_type.primitive_type ) {
                        case ast::Type::Primitive_Int8:
                        case ast::Type::Primitive_Uint8:
                        case ast::Type::Primitive_Int16:
                        case ast::Type::Primitive_Uint16:
                        case ast::Type::Primitive_Int32:
                        case ast::Type::Primitive_Uint32:
                        case ast::Type::Primitive_Int64:
                        case ast::Type::Primitive_Uint64:
                        case ast::Type::Primitive_Float:
                        case ast::Type::Primitive_Double:
                        {
                            ui_code.append( &amp;quot;\t\tImGui::InputScalar( \&amp;quot;%s\&amp;quot;, %s, &amp;amp;%s );\n&amp;quot;, member_name_buffer, s_primitive_type_imgui[member_type.primitive_type], member_name_buffer );
                            
                            break;
                        }
                        
                        case ast::Type::Primitive_Bool:
                        {
                            ui_code.append( &amp;quot;\t\tImGui::Checkbox( \&amp;quot;%s\&amp;quot;, &amp;amp;%s );\n&amp;quot;, member_name_buffer, member_name_buffer );
                            break;
                        }
                    }
                }

                break;
            }

&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;In case of a struct as a member, use the typename as is and call the &amp;lsquo;reflectMembers&amp;rsquo; method for the UI generation:&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;            case ast::Type::Types_Struct:
            {
                copy( member_type.name, member_type_buffer, 256 );
                fprintf( output, &amp;quot;%s\t%s %s;\n&amp;quot;, tabs, member_type_buffer, member_name_buffer );

                if ( code_generator-&amp;gt;generate_imgui ) {
                    ui_code.append( &amp;quot;\t\tImGui::Text(\&amp;quot;%s\&amp;quot;);\n&amp;quot;, member_name_buffer );
                    ui_code.append( &amp;quot;\t\t%s.reflectMembers();\n&amp;quot;, member_name_buffer );
                }

                break;
            }

&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;For enums use the format namespace::Enum that comes with the generated code (and can be anything else) and add a Combo for ImGui. The combo is using the string array generated previously! This is powerful!&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;            case ast::Type::Types_Enum:
            {
                copy( member_type.name, member_type_buffer, 256 );
                fprintf( output, &amp;quot;%s\t%s::Enum %s;\n&amp;quot;, tabs, member_type_buffer, member_name_buffer );

                if ( code_generator-&amp;gt;generate_imgui ) {
                    ui_code.append( &amp;quot;\t\tImGui::Combo( \&amp;quot;%s\&amp;quot;, (int32_t*)&amp;amp;%s, %s::s_value_names, %s::Count );\n&amp;quot;, member_name_buffer, member_name_buffer, member_type_buffer, member_type_buffer );
                }

                break;
            }

&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;To finish up simlpy add the reflectUI method, that embed the members reflection in a window and finish.&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;            default:
            {
                break;
            }
        }
    }

    ui_code.append( &amp;quot;\t}&amp;quot; );
    ui_code.append( &amp;quot;\n\n\tvoid reflectUI() {\n\t\tImGui::Begin(\&amp;quot;%s\&amp;quot;);\n\t\treflectMembers();\n\t\tImGui::End();\n\t}\n&amp;quot;, name_buffer );

    fprintf( output, &amp;quot;%s\n&amp;quot;, ui_code.data );

    fprintf( output, &amp;quot;\n%s}; // struct %s\n\n&amp;quot;, tabs, name_buffer );
}

&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;command&#34;&gt;Command&lt;/h2&gt;
&lt;p&gt;I wanted to include an example of something that does not exist in any language, but it shows the power of removing boilerplate code.&lt;/p&gt;
&lt;p&gt;I define commands as little structs with a type used anytime I need to do some command parsing, normally from a ring buffer.&lt;/p&gt;
&lt;p&gt;The command should have an enum with all the types already, and each struct should have its type assigned.
The type is normally used to cycle through the commands and do something accordingly.&lt;/p&gt;
&lt;p&gt;It will output structs because of the need to allocate them in the ring buffer, thus must be simple.&lt;/p&gt;
&lt;p&gt;First let&amp;rsquo;s see the HDF file. The example are window events commands:&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;command WindowEvents {

	Click {
		int16 x;
        int16 y;
        int16 button;
	}

	Move {
		int16 x;
		int16 y;
	}

    Wheel {
        int16 z;
    }
};
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The generated code will be:&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;namespace WindowEvents {
	enum Type {
		Type_Click, Type_Move, Type_Wheel
	};

	struct Click {

		int16_t x;
		int16_t y;
		int16_t button;

		static Type GetType() { return Type_Click; }

	}; // struct Wheel

	struct Move {

		int16_t x;
		int16_t y;

		static Type GetType() { return Type_Move; }

	}; // struct Wheel

	struct Wheel {

		int16_t z;

		static Type GetType() { return Type_Wheel; }

	}; // struct Wheel

}; // namespace WindowEvents
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;And finally the C++ code that generates the output.&lt;!-- raw HTML omitted --&gt;
The output starts with an enum with all the types, that I normally use to switch commands:&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;void outputCPPCommand( CodeGenerator* code_generator, FILE* output, const ast::Type&amp;amp; type ) {

    char name_buffer[256], member_name_buffer[256], member_type_buffer[256];
    copy( type.name, name_buffer, 256 );

    fprintf( output, &amp;quot;namespace %s {\n&amp;quot;, name_buffer );

    // Add enum with all types
    fprintf( output, &amp;quot;\tenum Type {\n&amp;quot; );
    fprintf( output, &amp;quot;\t\t&amp;quot; );
    for ( int i = 0; i &amp;lt; type.types.size() - 1; ++i ) {
        const ast::Type&amp;amp; command_type = *type.types[i];
        copy( command_type.name, name_buffer, 256 );
        fprintf( output, &amp;quot;Type_%s, &amp;quot;, name_buffer );
    }

    const ast::Type* last_type = type.types[type.types.size() - 1];
    copy( last_type-&amp;gt;name, name_buffer, 256 );
    fprintf( output, &amp;quot;Type_%s&amp;quot;, name_buffer );
    fprintf( output, &amp;quot;\n\t};\n\n&amp;quot; );
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Then we output all the command structs (like Click, Move, &amp;hellip;).&lt;!-- raw HTML omitted --&gt;
For each command type we output a struct with all its members. This is similar to the output of the structs:&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    const char* tabs = &amp;quot;\t&amp;quot;;

    for ( int i = 0; i &amp;lt; type.types.size(); ++i ) {
        const ast::Type&amp;amp; command_type = *type.types[i];

        copy( command_type.name, member_type_buffer, 256 );
        fprintf( output, &amp;quot;%sstruct %s {\n\n&amp;quot;, tabs, member_type_buffer );
        
        for ( int i = 0; i &amp;lt; command_type.types.size(); ++i ) {
            const ast::Type&amp;amp; member_type = *command_type.types[i];
            const StringRef&amp;amp; member_name = command_type.names[i];

            copy( member_name, member_name_buffer, 256 );

            // Translate type name based on output language.
            switch ( member_type.type ) {
                case ast::Type::Types_Primitive:
                {
                    strcpy_s( member_type_buffer, 256, s_primitive_type_cpp[member_type.primitive_type] );
                    fprintf( output, &amp;quot;%s\t%s %s;\n&amp;quot;, tabs, member_type_buffer, member_name_buffer );

                    break;
                }

                case ast::Type::Types_Struct:
                {
                    copy( member_type.name, member_type_buffer, 256 );
                    fprintf( output, &amp;quot;%s\t%s %s;\n&amp;quot;, tabs, member_type_buffer, member_name_buffer );

                    break;
                }

                case ast::Type::Types_Enum:
                {
                    copy( member_type.name, member_type_buffer, 256 );
                    fprintf( output, &amp;quot;%s\t%s::Enum %s;\n&amp;quot;, tabs, member_type_buffer, member_name_buffer );

                    break;
                }

                default:
                {
                    break;
                }
            }
        }

        copy( command_type.name, member_type_buffer, 256 );

        fprintf( output, &amp;quot;\n%s\tstatic Type GetType() { return Type_%s; }\n&amp;quot;, tabs, member_type_buffer );
        fprintf( output, &amp;quot;\n%s}; // struct %s\n\n&amp;quot;, tabs, name_buffer );
    }

    copy( type.name, name_buffer, 256 );
    fprintf( output, &amp;quot;}; // namespace %s\n\n&amp;quot;, name_buffer );

}
&lt;/code&gt;&lt;/pre&gt;&lt;h1 id=&#34;conclusions&#34;&gt;Conclusions&lt;/h1&gt;
&lt;p&gt;We learnt how to write a complete Code Generator, an incredible tool that can speed up the development if used correctly and remove most boilerplate code possible.&lt;/p&gt;
&lt;p&gt;The usage of the &lt;em&gt;command&lt;/em&gt; keyword was an example of something I use and I don’t want to write code, something that is custom enough and hopefully will give you more ideas on how you can break free from languages constriction when you write…your own language!&lt;/p&gt;
&lt;p&gt;In the quest for data-driven rendering, the next step will be to use the knowledge from code generation to create a &lt;em&gt;shader effect language&lt;/em&gt;, that can generate both CPU and GPU code for you.&lt;/p&gt;
&lt;p&gt;This article is the longest and more code-heavy I have ever written. There are many concepts that I am beginning to be familiar with, but still not so used to.&lt;/p&gt;
&lt;p&gt;So please comment, give feedback, share!
Thank you for reading!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Emulation: where to start? A use case.</title>
      <link>https://jorenjoestar.github.io/post/emulation_where_to_start/</link>
      <pubDate>Sat, 27 Jul 2019 18:45:35 -0400</pubDate>
      
      <guid>https://jorenjoestar.github.io/post/emulation_where_to_start/</guid>
      <description>





&lt;figure&gt;

  &lt;a data-fancybox=&#34;&#34; href=&#34;front.png&#34; &gt;

&lt;img src=&#34;front.png&#34; &gt;
&lt;/a&gt;


&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;Some of the UI for the Hydra NES emulator, using ImGUI.&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;Writing an emulator is an incredibly fun learning experience.&lt;/p&gt;
&lt;p&gt;It is an exquisite exercise in reverse-engineering from both documentation and code.&lt;/p&gt;
&lt;p&gt;In this post I want to share some tips on how and where to start based on my experience on the NES emulator I am writing.&lt;/p&gt;
&lt;h1 id=&#34;information&#34;&gt;Information&lt;/h1&gt;
&lt;p&gt;The gathering of information is the most important (and hard!) process that will live through all the writing process.&lt;/p&gt;
&lt;p&gt;Luckily for us there are many websites to help in this:&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://wiki.nesdev.com/w/index.php/NES_reference_guide&#34;&gt;https://wiki.nesdev.com/w/index.php/NES_reference_guide&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://forums.nesdev.com/&#34;&gt;http://forums.nesdev.com/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://obelisk.me.uk/6502/reference.html&#34;&gt;http://obelisk.me.uk/6502/reference.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://www.oxyron.de/html/opcodes02.html&#34;&gt;http://www.oxyron.de/html/opcodes02.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;It is paramount to create a list of websites and resources (maybe through some notes, like in Evernote or such) about different topics regarding the hardware to be emulated.&lt;/p&gt;
&lt;p&gt;Having a central hub is powerful and counteract the sparseness of the different informations (some in txt files, different websites, forum blogposts, …).&lt;/p&gt;
&lt;p&gt;I can’t stress enough how important it is.&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;p&gt;The amazing NesDev Wiki is the hub you need. Almost every possible information is there.&lt;/p&gt;
&lt;h1 id=&#34;architecture&#34;&gt;Architecture&lt;/h1&gt;
&lt;p&gt;Next step is to understand the architecture.&lt;!-- raw HTML omitted --&gt;
Write diagrams, take notes, search for the relationships of the component.&lt;!-- raw HTML omitted --&gt;
What does every hardware component do ?&lt;!-- raw HTML omitted --&gt;
What can that specific hardware piece access to ?&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;p&gt;As you will see, writing the emulator is an iterative process of improving each component until you have something that works very well, and then refine for an infinite amount of time.&lt;!-- raw HTML omitted --&gt;
On a very basic level, there should be a CPU, some form of GPU (PPU, Picture Processing Unit), some audio chip, some input peripheral and cartridge/disc/rom.&lt;/p&gt;
&lt;h1 id=&#34;nes-architecture&#34;&gt;NES architecture&lt;/h1&gt;
&lt;p&gt;The NES is a beautiful machine equipped with the following:&lt;/p&gt;
&lt;h4 id=&#34;cpu--ricoh-rp2a03-ntsc--rp2a07-pal&#34;&gt;CPU : Ricoh RP2A03 (NTSC) / RP2A07 (PAL)&lt;/h4&gt;
&lt;p&gt;8 bit processor that contains both CPU and APU (audio) hardware. The addresses are 16 bit, but the data is 8.
It contains only specific registers: 2 indices, accumulator, stack pointer, program counter and status.&lt;/p&gt;
&lt;h4 id=&#34;ppu--ricoh-rp2c02-ntsc--rp2c07-pal&#34;&gt;PPU : Ricoh RP2C02 (NTSC) / RP2C07 (PAL)&lt;/h4&gt;
&lt;p&gt;This is what today would be called GPU.
It outputs to a 256x240 pixels buffer, it has 2kib or RAM, 32 bytes for palette RAM and 288 bytes for sprite RAM.
The PPU is tile based and it takes 8 PPU cycles to load a line of a background tile.
Sprites are sent through DMA and background is filled during Vertical Blank state normally.
A frame lasts more scanline that the one visible, so that the game can upload data to the PPU when not rendering.&lt;/p&gt;
&lt;h4 id=&#34;apu--ricoh-rp2a03-ntsc--rp2a07-pal-contained-in-the-cpu-itself&#34;&gt;APU : Ricoh RP2A03 (NTSC) / RP2A07 (PAL) (Contained in the CPU itself.)&lt;/h4&gt;
&lt;p&gt;The sound is analogic and it comes from 5 different channels: 2 pulse, 1 triangle, 1 noise and 1 DMC. All the channels aside from the DMC create signals that are combined to output the sounds and music.
The DMC loads samples using the DMA.&lt;/p&gt;
&lt;h4 id=&#34;cartridgemappers-&#34;&gt;Cartridge/Mappers :&lt;/h4&gt;
&lt;p&gt;This is a very unique topic strict to the NES as far as I know.
Cartridges had unique hardware and they were used to swap banks of memory in realtime to access different parts of the cartridge.
There are hundred of mappers that have unique behaviours!
The biggest gist of the mappers is how they switch banks: by WRITING to the address where the execution code is it triggers the bank-switching logic.
There can be internal batteries and working RAMs too, but they are very rare.&lt;/p&gt;
&lt;h4 id=&#34;memory-mapped-io&#34;&gt;Memory mapped I/O&lt;/h4&gt;
&lt;p&gt;The different hardware access using ‘memory mapped I/O’, that is a way of saying that when you read or write to a specific address it could be memory or it could be an hardware-component.&lt;/p&gt;
&lt;p&gt;Examples: reading from address &lt;strong&gt;0x4016&lt;/strong&gt; gives you the &lt;strong&gt;gamepad&lt;/strong&gt; status, while reading from &lt;strong&gt;0x1000&lt;/strong&gt; reads from the &lt;strong&gt;CPU ram&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Having clear these accesses will help in understanding even better the machine.&lt;/p&gt;
&lt;p&gt;Both CPU and PPU have different memory maps. Let&amp;rsquo;s see them, it will help in understanding the internal of the NES better.&lt;/p&gt;
&lt;h2 id=&#34;cpu-memory-map&#34;&gt;CPU Memory Map&lt;/h2&gt;






&lt;figure&gt;

  &lt;a data-fancybox=&#34;&#34; href=&#34;cpu_map.png&#34; &gt;

&lt;img src=&#34;cpu_map.png&#34; &gt;
&lt;/a&gt;

&lt;/figure&gt;

&lt;p&gt;The &lt;strong&gt;CPU&lt;/strong&gt; can access basically every hardware component in the NES.&lt;!-- raw HTML omitted --&gt;
&lt;strong&gt;PPU, APU, gamepads&lt;/strong&gt;, both read and write.&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;p&gt;It reads the &lt;strong&gt;ROM&lt;/strong&gt; part of a cartridge (called &lt;strong&gt;PRG&lt;/strong&gt;) and executes its instructions.&lt;!-- raw HTML omitted --&gt;
Through &lt;strong&gt;PPU&lt;/strong&gt; registers it can instruct the &lt;strong&gt;PPU&lt;/strong&gt; to read graphical informations from the &lt;strong&gt;CHR&lt;/strong&gt; part of the cartridge.&lt;!-- raw HTML omitted --&gt;
It can upload sprites on the &lt;strong&gt;PPU Sprite Memory&lt;/strong&gt; through &lt;strong&gt;DMA&lt;/strong&gt;, upload data to the &lt;strong&gt;APU&lt;/strong&gt;, or manage its internal RAM.&lt;/p&gt;
&lt;p&gt;From the source code, this is a working example of CPU Reading method:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;uint8 Nes::MemoryController::CpuRead( uint16 address ) {

    if ( address &amp;lt; 0x2000 ) {
        return cpu-&amp;gt;ram[address &amp;amp; 0x7FF];
    }
    else if ( address &amp;lt; 0x4000 ) {
        return ppu-&amp;gt;CpuRead( address );
    }
    else if ( address &amp;lt; 0x4014 ) {
        return apu-&amp;gt;CpuRead( address );
    }
    else if ( address &amp;gt;= 0x4018 ) {
        return mapper-&amp;gt;PrgRead( address );
    }

    switch ( address ) {
        case 0x4015: {
            return apu-&amp;gt;ReadStatus();
            break;
        }

        case 0x4016: {
            return controllers-&amp;gt;ReadState();
            break;
        }
                     
        case 0x4017: {
            return 0x40;
            break;
        }
    }

    return 0;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;And CPU Write:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;void Nes::MemoryController::CpuWrite( uint16 address, uint8 data ) {

    if ( address &amp;lt; 0x2000 ) {
        cpu-&amp;gt;ram[address &amp;amp; 0x7FF] = data;
    }
    else if ( address &amp;lt; 0x4000 ) {
        ppu-&amp;gt;CpuWrite( address, data );
        return;
    }
    else if ( address &amp;lt; 0x4014 ) {
        return apu-&amp;gt;CpuWrite( address, data );
    }
    else if ( address &amp;gt;= 0x4018 ) {
        mapper-&amp;gt;PrgWrite( address, data );
        return;
    }

    switch ( address ) {
        // Sprite DMA
        case 0x4014: {
            cpu-&amp;gt;ExecuteSpriteDMA( data );
            return;
            break;
        }

        case 0x4015:
        case 0x4017: {
            apu-&amp;gt;CpuWrite( address, data );
            return;
            break;
        }

        case 0x4016: {
            controllers-&amp;gt;WriteState( data );
            return;
            break;
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The pattern is always the same: check the address of the instruction and choose which hardware component to interact with.&lt;/p&gt;
&lt;p&gt;Hopefully its clear that based on the address different components can be accessed.
Let&amp;rsquo;s have a look at the PPU too.&lt;/p&gt;
&lt;h2 id=&#34;ppu-memory-map&#34;&gt;PPU Memory Map&lt;/h2&gt;






&lt;figure&gt;

  &lt;a data-fancybox=&#34;&#34; href=&#34;ppu_map.png&#34; &gt;

&lt;img src=&#34;ppu_map.png&#34; &gt;
&lt;/a&gt;

&lt;/figure&gt;

&lt;p&gt;Similar to the &lt;strong&gt;CPU&lt;/strong&gt;, reading and writing on the &lt;strong&gt;PPU&lt;/strong&gt; access different components, even though they are far less.&lt;!-- raw HTML omitted --&gt;
The &lt;strong&gt;PPU&lt;/strong&gt; either accesses its 2 rams (&lt;strong&gt;palette&lt;/strong&gt; and &lt;strong&gt;nametable&lt;/strong&gt;, normally from the &lt;strong&gt;CPU&lt;/strong&gt;) or reads the &lt;strong&gt;CHR&lt;/strong&gt; (that is the graphical data stored in the cartridge) memory.&lt;/p&gt;
&lt;p&gt;Reading:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;uint8 Nes::MemoryController::PpuRead( uint16 address ) {
    
    address &amp;amp;= 0X3FFF;

    if ( address &amp;lt;= 0x1FFF ) {
        return mapper-&amp;gt;ChrRead( address );
    }
    else if ( address &amp;lt;= 0x3EFF ) {
        return ppu-&amp;gt;nametableRam[NameTableMirroring( address, mapper-&amp;gt;mirroring )];
    }
    else if ( address &amp;lt;= 0x3FFF ) {
        // Palette mirroring is handled in the write code.
        return ppu-&amp;gt;paletteRam[address &amp;amp; 0x1F] &amp;amp; ((ppu-&amp;gt;mask &amp;amp; Nes::Ppu::MaskFlag_GreyScale ? 0x30 : 0xFF));
    }
    return 0;
}

&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;On the writing side, there the code shows the intricancy of emulation.
When writing to the paletter ram, there is a mirroring mechanism happening in the hardware that is emulated with a lookup table.
Something to look out to: &lt;strong&gt;writing to CHR is 99% of the time useless, unless there is an additional RAM in the cartdige&lt;/strong&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;void Nes::MemoryController::PpuWrite( uint16 address, uint8 data ) {

    address &amp;amp;= 0X3FFF;

    if ( address &amp;lt;= 0x1FFF ) {
        mapper-&amp;gt;ChrWrite( address, data );
        return;
    }
    else if ( address &amp;lt;= 0x3EFF ) {
        ppu-&amp;gt;nametableRam[NameTableMirroring( address, mapper-&amp;gt;mirroring )] = data;
        return;
    }
    else if ( address &amp;lt;= 0x3FFF ) {

        static uint8 const palette_write_mirror[0x20] = { 
            0x10, 0x01, 0x02, 0x03, 0x14, 0x05, 0x06, 0x07,
            0x18, 0x09, 0x0A, 0x0B, 0x1C, 0x0D, 0x0E, 0x0F,
            0x00, 0x11, 0x12, 0x13, 0x04, 0x15, 0x16, 0x17,
            0x08, 0x19, 0x1A, 0x1B, 0x0C, 0x1D, 0x1E, 0x1F };

        ppu-&amp;gt;paletteRam[palette_write_mirror[address &amp;amp; 0x1F]] = data;
        return;
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;takeaways&#34;&gt;Takeaways&lt;/h2&gt;
&lt;p&gt;I created the &lt;strong&gt;memory controller&lt;/strong&gt; as the main dispatcher of data between hardware components, to separate the duties better.
We can see the following relationships based on that:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;CPU can access PPU, APU, controllers and cartridge (PRG)&lt;/li&gt;
&lt;li&gt;PPU can access screen, its own rams and cartridge (CHR)&lt;/li&gt;
&lt;li&gt;memory controller is the hub that connects everything&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I am not sure this is the best emulator architecture, but that is what I figured out.&lt;/p&gt;
&lt;h1 id=&#34;test-roms&#34;&gt;Test roms&lt;/h1&gt;
&lt;p&gt;A fundamental approach to create a robust emulator is to have some tests to rely on.&lt;!-- raw HTML omitted --&gt;
Sadly it is not common for all hardware, but again the NES provide plenty of roms that tests almost every aspect of your emulator!&lt;!-- raw HTML omitted --&gt;
It quickly becomes a test-driven development.&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://wiki.nesdev.com/w/index.php/Emulator_tests&#34;&gt;NES test roms link&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Find roms, read the source code and try to understand what they are doing and why.&lt;/p&gt;
&lt;h1 id=&#34;coding-start&#34;&gt;Coding start&lt;/h1&gt;
&lt;p&gt;If you are writing your first emulator, I suggest to focus mostly on the emulation part.&lt;/p&gt;
&lt;p&gt;What do I mean by that ?&lt;!-- raw HTML omitted --&gt;
Avoid trying too many things at once!&lt;!-- raw HTML omitted --&gt;
Focus your energies towards the emulation.&lt;!-- raw HTML omitted --&gt;
Use libraries that are reliable and simple and that you know.&lt;!-- raw HTML omitted --&gt;
GLFW, SDL2, etc are your friends here.&lt;!-- raw HTML omitted --&gt;
You want to eliminate most unknowns unknowns before hand.&lt;!-- raw HTML omitted --&gt;
Of course, if you are brave enough, you can also write an emulator in a new language.&lt;/p&gt;
&lt;p&gt;But for me, I preferred to concentrate on the emulation side first, in C++, using my core library, especially knowing that I could dedicate some night-time here and there,
No surprises (not really true, still some happened!).&lt;/p&gt;
&lt;p&gt;I will possibly port the emulator to use SDL if needed, but right now the emulation code is the most important.&lt;/p&gt;
&lt;p&gt;This is the mantra that helped me concentrate only on the emulation code. Again, writing-wise I am not happy about the code quality. But what I am learning from different perspectives is invaluable!&lt;/p&gt;
&lt;h1 id=&#34;nes-coding-start&#34;&gt;NES coding start&lt;/h1&gt;
&lt;p&gt;The quintessential basic steps to start a NES emulator coding are:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Write CPU basics (fetch/decode/execute loop, registers)&lt;/li&gt;
&lt;li&gt;Basic memory bus (read/write to/from memory and registers)&lt;/li&gt;
&lt;li&gt;Load a rom and start executing instruction step by step.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;It is already a lot, and it will require to read multiple times the different wiki pages and forum posts.&lt;/p&gt;
&lt;p&gt;For a typical console, the main loop (simplified) can be something like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;void CpuTick() {
    uint8_t opcode = Read(program_counter++);
    uint8_t operand = FetchOperand(opcode);
    ExecuteOpcode(opcode, operand);
}

void ExecuteFrame() {
    uint32_t cycles_per_frame = …
 
    while (cycles_per_frame — ) {
        CpuTick();
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;To jumpstart your NES emulator you can use the majestic rom nestest.nes and its log file: it gives you a test of all instructions of the CPU and prints the status of the CPU after each one.&lt;/p&gt;
&lt;p&gt;Also it does not require any PPU rendering: compare the status of your CPU with the text file line by line and its done!&lt;/p&gt;
&lt;p&gt;You can see some ugly but useful code in &lt;a href=&#34;https://github.com/JorenJoestar/HydraNes/blob/68d705ef400c1ab930dce0fa51c5353aa8b32396/src/main.cpp#L607&#34;&gt;MainState::ExecuteCpuTest&lt;/a&gt; in my emulator for an idea.&lt;/p&gt;
&lt;p&gt;A line from the nestest.log file looks like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// C000 4C F5 C5 JMP $C5F5 A:00 X:00 Y:00 P:24 SP:FD PPU: 0, 0 CYC:7
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;it gives you the ProgramCounter (C000), byte code (1, 2 or 3 bytes depending on the instructions), human-readable-instruction (JMP) , the CPU register contents (A, X, Y, P, SP) and the theorethical PPU scanline, pixel and clock cycle.&lt;/p&gt;
&lt;p&gt;There are two interesting points:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The ProgramCounter before execution should be set to C000 for this rom only and only when logging.&lt;/li&gt;
&lt;li&gt;The CPU cycles STARTS at 7. In a power-up/reset method there is some work done BEFORE executing any code. This is needed only if you want to have a precise cycle-to-cycle comparison.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;You can create a simple test method like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;void TestEmulatorCPU() {
    Reset();
 
    while(true) {
        CpuTick();
        CompareCpuStatusWithLog();
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;and catch the problems in your CPU instructions implementation!&lt;/p&gt;
&lt;h1 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;This is a little help in understanding how to start with an emulator.&lt;/p&gt;
&lt;p&gt;It is a beautiful journey, but it is full of trial and errors.&lt;/p&gt;
&lt;p&gt;I am myself far from over with my emulator, and also far from being happy on HOW I write the emulator itself.&lt;/p&gt;
&lt;p&gt;There are emulators of much more complex machines out there (almost every machine you can imagine!) and it blows my mind to know there are people that can emulate such complex hardware.&lt;/p&gt;
&lt;p&gt;The ideal situation would be to being able of not being lost in visual emulation of the circuitry, but for now that is out of my league.&lt;/p&gt;
&lt;p&gt;I am thinking of creating some a series of videos and code associated starting from scratch, if anyone is interested.
Please leave a comment/feedback on the article, the source code, anything!&lt;/p&gt;
&lt;p&gt;I hope it will help.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Flatbuffers, Reflection and Data-Driven Rendering</title>
      <link>https://jorenjoestar.github.io/post/flatbuffers_reflection_data_driven_rendering/</link>
      <pubDate>Fri, 26 Jul 2019 07:37:26 -0400</pubDate>
      
      <guid>https://jorenjoestar.github.io/post/flatbuffers_reflection_data_driven_rendering/</guid>
      <description>





&lt;figure&gt;

  &lt;a data-fancybox=&#34;&#34; href=&#34;front.png&#34; &gt;

&lt;img src=&#34;front.png&#34; &gt;
&lt;/a&gt;


&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;Auto generated UI from Flatbuffers files.&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;h1 id=&#34;motivation&#34;&gt;Motivation&lt;/h1&gt;
&lt;p&gt;Finding a good balance between code and data in Rendering.&lt;!-- raw HTML omitted --&gt;
What is the necessary code that should be written ?&lt;!-- raw HTML omitted --&gt;
Why ?&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;p&gt;In rendering many areas can be described in a fast and robust way using data.&lt;!-- raw HTML omitted --&gt;
A &lt;em&gt;pipeline (in D3D12/Vulkan lingo)&lt;/em&gt; for example is a collection of different states: &lt;em&gt;depth stencil, alpha blend, rasterizer, shaders&lt;/em&gt;, etc.&lt;!-- raw HTML omitted --&gt;
All those state can be &lt;em&gt;hard-coded&lt;/em&gt; or defined in &lt;em&gt;data&lt;/em&gt;.&lt;!-- raw HTML omitted --&gt;
Moving them to data can help with the visibility of them, that instead of being buried somewhere into the code can be retrieved before even running the application.&lt;/p&gt;
&lt;p&gt;As a bigger-scope example, a &lt;em&gt;frame-graph&lt;/em&gt; can be implicitly defined inside the code, if different areas, or in data.&lt;!-- raw HTML omitted --&gt;
Recent posts about it started raising attention to the problem, especially after the introduction of lower-level APIs like D3D12 and Vulkan and their resource barriers.&lt;!-- raw HTML omitted --&gt;
I’ve personally used something like &lt;em&gt;json&lt;/em&gt; (xml back in the day) since 2009, after asking myself the very silly question:&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;what is the biggest dependency in rendering?&lt;!-- raw HTML omitted --&gt;Render Targets!&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Since then I saw only in the Codemasters postprocess system (since Dirt 2) a similar approach, and have never being able to advocate towards it.&lt;!-- raw HTML omitted --&gt;
The only full use case I have is my personal indie game (a full deferred rendering pipeline with many different rendering needs) all defined in a json file (render_pipeline.json).&lt;!-- raw HTML omitted --&gt;
Anyway, a couple of examples of this data-driven mentality can be found here:&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;&lt;a href=&#34;http://bitsquid.blogspot.com/2017/03/stingray-renderer-walkthrough-7-data.html&#34;&gt;http://bitsquid.blogspot.com/2017/03/stingray-renderer-walkthrough-7-data.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I chose to see what is a good way of &lt;em&gt;describing low-level rendering resources, the bricks towards data-driven rendering&lt;/em&gt;.&lt;!-- raw HTML omitted --&gt;
I’ve already tried defining them in a json file, but wanted something more direct — something I can copy easily with minimal parsing.&lt;/p&gt;
&lt;p&gt;I found 4 possible approaches:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Custom data language&lt;/li&gt;
&lt;li&gt;Already existing data language&lt;/li&gt;
&lt;li&gt;Json (already used)&lt;/li&gt;
&lt;li&gt;Hard-coding everything&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;In this experiment I’ve chosen &lt;strong&gt;Flatbuffers&lt;/strong&gt; for the easy of use, the good performances and the feature set that seems complete.&lt;!-- raw HTML omitted --&gt;
As an exercise, I wanted to create some UI based on the data coming from Flatbuffers without having to write too much code.&lt;/p&gt;
&lt;h1 id=&#34;flatbuffers&#34;&gt;Flatbuffers&lt;/h1&gt;
&lt;p&gt;Flatbuffers is a serialization library developer by Google used by many companies.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://google.github.io/flatbuffers/&#34;&gt;https://google.github.io/flatbuffers/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Compared to &lt;strong&gt;Protocol Buffers&lt;/strong&gt; (still developed by Google) it tries to go towards a very simple parsing/unpacking (actually ABSENT in Flatbuffers, so much faster to read/write) and serialization speed.&lt;/p&gt;
&lt;p&gt;Flatbuffers is mainly a compiler that accepts .fbs (FlatBuffers Schema) files and can generate code for serialization purposes.&lt;/p&gt;
&lt;p&gt;The advantage is that it automatically generates the parsing files in the language you prefer (C++, Java, C#, Go, C, Lua, Javascript, Rust) without you needing to write the always tedious serialize/deserialize methods.&lt;/p&gt;
&lt;p&gt;It is largely based on either simple c-structs or tables with offsets for more complex object.&lt;/p&gt;
&lt;p&gt;The objective here will be to create a schema file, define a couple of resources (like textures) and use those to automatically generate UI.&lt;!-- raw HTML omitted --&gt;
I will be using the SDL + ImGUI sample from the amazing ImGUI as a base.&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;p&gt;The flow will be the following:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Write schema files&lt;/li&gt;
&lt;li&gt;Generate reflection informations&lt;/li&gt;
&lt;li&gt;Parse schemas&lt;/li&gt;
&lt;li&gt;Generate UI&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&#34;schema-files&#34;&gt;Schema Files&lt;/h1&gt;
&lt;p&gt;Let’s write our first schema file.
A bigger version (that I am using for my low-level renderer) is included in the &lt;a href=&#34;https://github.com/JorenJoestar/FlatbuffersReflection&#34;&gt;github&lt;/a&gt; repository.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;namespace rendering;

enum TextureFormat : ushort { UNKNOWN, R32G32B32A32_TYPELESS, R32G32B32A32_FLOAT, R32G32B32A32_UINT, R32G32B32A32_SINT, R32G32B32_TYPELESS, R32G32B32_FLOAT, R32G32B32_UINT, R32G32B32_SINT, R16G16B16A16_TYPELESS, R16G16B16A16_FLOAT, R16G16B16A16_UNORM, R16G16B16A16_UINT, R16G16B16A16_SNORM, R16G16B16A16_SINT, R32G32_TYPELESS, R32G32_FLOAT, R32G32_UINT, R32G32_SINT, R10G10B10A2_TYPELESS, R10G10B10A2_UNORM, R10G10B10A2_UINT, R11G11B10_FLOAT, R8G8B8A8_TYPELESS, R8G8B8A8_UNORM, R8G8B8A8_UNORM_SRGB, R8G8B8A8_UINT, R8G8B8A8_SNORM, R8G8B8A8_SINT, R16G16_TYPELESS, R16G16_FLOAT, R16G16_UNORM, R16G16_UINT, R16G16_SNORM, R16G16_SINT, R32_TYPELESS, R32_FLOAT, R32_UINT, R32_SINT, R8G8_TYPELESS, R8G8_UNORM, R8G8_UINT, R8G8_SNORM, R8G8_SINT, R16_TYPELESS, R16_FLOAT, R16_UNORM, R16_UINT, R16_SNORM, R16_SINT, R8_TYPELESS, R8_UNORM, R8_UINT, R8_SNORM, R8_SINT, R9G9B9E5_SHAREDEXP, D32_FLOAT_S8X24_UINT, D32_FLOAT, D24_UNORM_S8_UINT, D24_UNORM_X8_UINT, D16_UNORM, S8_UINT, BC1_TYPELESS, BC1_UNORM, BC1_UNORM_SRGB, BC2_TYPELESS, BC2_UNORM, BC2_UNORM_SRGB, BC3_TYPELESS, BC3_UNORM, BC3_UNORM_SRGB, BC4_TYPELESS, BC4_UNORM, BC4_SNORM, BC5_TYPELESS, BC5_UNORM, BC5_SNORM, B5G6R5_UNORM, B5G5R5A1_UNORM, B8G8R8A8_UNORM, B8G8R8X8_UNORM, R10G10B10_XR_BIAS_A2_UNORM, B8G8R8A8_TYPELESS, B8G8R8A8_UNORM_SRGB, B8G8R8X8_TYPELESS, B8G8R8X8_UNORM_SRGB, BC6H_TYPELESS, BC6H_UF16, BC6H_SF16, BC7_TYPELESS, BC7_UNORM, BC7_UNORM_SRGB, FORCE_UINT }

attribute &amp;quot;ui&amp;quot;;

struct RenderTarget {
    width                   : ushort (ui: &amp;quot;min:1, max:16384&amp;quot;);
    height                  : ushort;
    scale_x                 : float;
    scale_y                 : float;
    format                  : TextureFormat;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;There are few things here to discuss.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Enums. Flatbuffers can generate enums with string version of each values and conversions between enum and string.&lt;/li&gt;
&lt;li&gt;Struct. It is exactly like C/C++: a simple struct that can be memcopied. Different than a Table (that can point to other structs and Tables).&lt;/li&gt;
&lt;li&gt;Attributes. This can be used to define custom parsable attributes linked to a member of a struct/table. They can be used, for example, to drive the UI generation.&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&#34;generating-reflection-informations&#34;&gt;Generating Reflection Informations&lt;/h1&gt;
&lt;p&gt;After we generated the schema file, we can serialize it and load/save it from disk.
But we need reflection data to be able to automatically generate the UI we need!
There are two main reflection mechanisms in Flatbuffers: mini-reflection and full-reflection.
We will use both to generate a UI using ImGUI and see the differences.&lt;/p&gt;
&lt;h2 id=&#34;mini-reflection&#34;&gt;Mini-Reflection&lt;/h2&gt;
&lt;p&gt;This is the simplest of the two and works by generating an additional header file for each .fbs file we use.
The command line is the following:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;flatc --cpp RenderDefinitions.fbs --reflect-names
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This will generate the &lt;em&gt;RenderDefinitions_Generated.h&lt;/em&gt; file that must be included in your application and has the downside of needing you to recompile every time you change the data.&lt;/p&gt;
&lt;p&gt;Also, and this is the biggest downside, I could not find any way to parse custom per-member attributes.&lt;/p&gt;
&lt;p&gt;I hope I am wrong, but could not find any documentation on the topic: everything seems to point towards the full reflection mechanism.&lt;/p&gt;
&lt;p&gt;So why bothering with the &lt;strong&gt;mini-reflection&lt;/strong&gt; ?&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Mini-reflection&lt;/strong&gt; generates code, and this became useful for one of the most tedious C/C++ code to write: &lt;strong&gt;enums&lt;/strong&gt;!&lt;/p&gt;
&lt;p&gt;I can’t count how many times I wrote an enum, I wanted the string with the same value for it (for example to read from a json file and get the proper enum value) and every time an enum is changed is painful.&lt;/p&gt;
&lt;p&gt;So a lesson from the mini-reflection is to have a code-generator for enums for C/C++, and I will show an example soon in another article.&lt;/p&gt;
&lt;p&gt;Back to the enums, Flatbuffers generates:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Enum&lt;/li&gt;
&lt;li&gt;Name array&lt;/li&gt;
&lt;li&gt;Value array&lt;/li&gt;
&lt;li&gt;Enum to name method&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;A nice property of the generated code for the enum is that it is easy to copy-paste in any c++ file — no Flatbuffers involved!&lt;/p&gt;
&lt;p&gt;This is my first choice now when I want to write an enum in any c++ application.&lt;/p&gt;
&lt;h2 id=&#34;full-reflection&#34;&gt;Full-reflection&lt;/h2&gt;
&lt;p&gt;This is the most used (or at least documented) form of reflection in Flatbuffers.&lt;/p&gt;
&lt;p&gt;It use a very elegant solution, totally data-driven: &lt;em&gt;it reads a reflection schema file that can parse…ANY other schema&lt;/em&gt;!&lt;/p&gt;
&lt;p&gt;This very Inception-esque mechanism gives the full access to all the types, including Attributes.&lt;/p&gt;
&lt;p&gt;By executing this command:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;flatc.exe -b --schema reflection.fbs RenderDefinitions.fbs
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;the RenderDefinitions.bfbs (binary fbs) file is generated.&lt;/p&gt;
&lt;p&gt;This is the file that needs to be read to fully reflect the types inside the .fbs file.
The order of operations is the following:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Generate a binary fbs with flatc (with the command line shown)&lt;/li&gt;
&lt;li&gt;Load the bfbs file generated&lt;/li&gt;
&lt;li&gt;Load the schema from the bfbs&lt;/li&gt;
&lt;li&gt;Reflect&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The fbfs file contains all the informations from the schema: types, enums, attributes.&lt;/p&gt;
&lt;h1 id=&#34;parsing-schemas-and-generating-ui&#34;&gt;Parsing schemas and Generating UI&lt;/h1&gt;
&lt;p&gt;For both reflection mechanisms the objective is the same: given a type (RenderTarget) generate an editor that can edit properties and potentially load/save them.&lt;/p&gt;
&lt;h2 id=&#34;mini-reflection-1&#34;&gt;Mini-Reflection&lt;/h2&gt;
&lt;p&gt;The UI generation is pretty straightforward with mini-reflection.&lt;/p&gt;
&lt;p&gt;Each type defined in the .fbs file contains a type_name-TypeTable() method that gives accent to a TypeTable.&lt;/p&gt;
&lt;p&gt;This contains a list of per-member type, name and default values.&lt;/p&gt;
&lt;p&gt;What is really missing here is the attributes, that could be used to generate custom UI in a more specific way (eg. adding a min/max/step to a slider).&lt;/p&gt;
&lt;p&gt;The code doing this is in the github sample.&lt;/p&gt;
&lt;p&gt;There are few interesting points here.&lt;/p&gt;
&lt;h3 id=&#34;imgui-usability&#34;&gt;ImGui usability&lt;/h3&gt;
&lt;p&gt;In order to use ImGui to modify a struct, I had to create the class FlatBuffersReflectionTable to instantiate a struct with a similar layout than the Flatbuffers struct.&lt;/p&gt;
&lt;p&gt;This is annoying but I could not find a way around different than this.&lt;/p&gt;
&lt;p&gt;With this in-place, a ImGUI slider can point to a memory area that can be used to save/load the data.
Let’s begin by retrieving the TypeTable:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;const TypeTable* rt_table = rendering::RenderTargetTypeTable();
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The TypeTable is what is included in the generated header and contains the reflection informations.
Listing the members and their type is pretty straight-forward:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;for ( uint32_t i = 0; i &amp;lt; type_table.num_elems; ++i ) {
    const flatbuffers::TypeCode&amp;amp; type_code = type_table.type_codes[i];
    ImGui::Text( &amp;quot;%s: %s&amp;quot;, type_table.names[i], flatbuffers::ElementaryTypeNames()[type_code.base_type] );
    sprintf_s( s_string_buffer, 128, &amp;quot;%s&amp;quot;, type_table.names[i] );
    
    if ( type_code.sequence_ref == 0 ) {
        if ( type_table.type_refs[type_code.sequence_ref] ) {
            const flatbuffers::TypeTable* enum_type = type_table.type_refs[type_code.sequence_ref]();
             ImGui::Combo( s_string_buffer, (int32_t*)reflection_table.GetData( i ), enum_type-&amp;gt;names, enum_type-&amp;gt;num_elems );
        }
    }
    else {
        switch ( type_code.base_type ) {
             case flatbuffers::ET_BOOL:
            {
                ImGui::Checkbox( s_string_buffer, (bool*)reflection_table.GetData( i ) );
                break;
            }
         }
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The interesting parts:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;flatbuffers::TypeCode&lt;/strong&gt;* contains the reflection information for a type.&lt;/p&gt;
&lt;p&gt;Given a &lt;strong&gt;type_code&lt;/strong&gt;, &lt;strong&gt;sequence_ref&lt;/strong&gt; can be used to check if it is an enum, pointer, or primitive type. In this case is used for enum, showing a combo with all the selectable values.&lt;/p&gt;
&lt;p&gt;Base_type contains instead the primitive type. In this example a bool can be mapped to a checkbox. This uses the custom reflection_table class to have a memory area for ImGUI.&lt;/p&gt;
&lt;p&gt;For mini-reflection this is basically it.&lt;/p&gt;
&lt;h2 id=&#34;full-reflection-1&#34;&gt;Full-reflection&lt;/h2&gt;
&lt;p&gt;Code here is longer but it follows the 4 steps highlighted before.&lt;/p&gt;
&lt;p&gt;All the code is inside the ReflectUIFull method.&lt;/p&gt;
&lt;p&gt;Here the binary fbs file and its corresponding schema are loaded.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// 1. Obtain the schema from the binary fbs generated
std::string bfbsfile;    
flatbuffers::LoadFile(&amp;quot;..\\data\\RenderDefinitions.bfbs&amp;quot;, true, &amp;amp;bfbsfile );     
const reflection::Schema&amp;amp; schema = *reflection::GetSchema( bfbsfile.c_str() );
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The schema can be used to list the types:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// 2. List all the types present in the fbs.    
auto types = schema.objects();    
for ( size_t i = 0; i &amp;lt; types-&amp;gt;Length(); i++ ) {        
   const reflection::Object* type = types-&amp;gt;Get( i );
   ImGui::Text( &amp;quot;    %s&amp;quot;, type-&amp;gt;name()-&amp;gt;c_str() );    
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;(Using the auto here because I am lazy. The type is some multiple templates of offsets…)
We can also list all the enums:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;auto enums = schema.enums();    
for ( size_t i = 0; i &amp;lt; enums-&amp;gt;Length(); i++ ) {        
    const reflection::Enum* enum_ = enums-&amp;gt;Get( i );
    ImGui::Text( &amp;quot;    %s&amp;quot;, enum_-&amp;gt;name()-&amp;gt;c_str() );    
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;A problem I found (with a workaround in the code) is that enums do not have an easily to access array of string values.&lt;/p&gt;
&lt;p&gt;So I generated one for the sake of example, but I am far from happy with the solution!&lt;/p&gt;
&lt;p&gt;Going forward, we can get the type we want to reflect (notice the full namespace.type):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;auto render_target_type = types-&amp;gt;LookupByKey( &amp;quot;rendering.RenderTarget&amp;quot; );
and begin the work on each field:
auto fields = render_target_type-&amp;gt;fields();    
if ( fields ) {
    // 5.1. List all the fields        
    for ( size_t i = 0; i &amp;lt; fields-&amp;gt;Length(); i++ ) {
            auto field = fields-&amp;gt;Get( i );
            ...

&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;and the UI can be generated.&lt;/p&gt;
&lt;p&gt;For each field, the primitive type can be accessed with the following:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;reflection::BaseType field_base_type = field-&amp;gt;type()-&amp;gt;base_type();
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;and again, I found a workaround to know if a type is primitive or an enum.&lt;/p&gt;
&lt;p&gt;Last piece of the puzzle: attributes!&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;auto field_attributes = field-&amp;gt;attributes();
if ( field_attributes ) {
    auto ui = field_attributes-&amp;gt;LookupByKey( &amp;quot;ui&amp;quot; );
    if ( ui ) {
      ImGui::Text(&amp;quot;UI attribute: %s&amp;quot;, ui-&amp;gt;value()-&amp;gt;c_str());
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;These can be parsed as strings and can be used to drive UI code (like a slider with min, max and steps).&lt;/p&gt;
&lt;h1 id=&#34;conclusions&#34;&gt;Conclusions&lt;/h1&gt;
&lt;p&gt;In the end, I’ve managed to generate UI based on a type without too much code.&lt;/p&gt;
&lt;p&gt;There was some reverse-engineering to do because I could not find proper documentation (I possibly miss some links to a in-depth example of reflection!) but nothing major.&lt;/p&gt;
&lt;p&gt;The full source code:&lt;/p&gt;
&lt;p&gt;(&lt;a href=&#34;https://github.com/JorenJoestar/FlatbuffersReflection&#34;&gt;https://github.com/JorenJoestar/FlatbuffersReflection&lt;/a&gt;)&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Releasing NES Emulator Source</title>
      <link>https://jorenjoestar.github.io/post/releasing_nes_emulator_source/</link>
      <pubDate>Tue, 23 Jul 2019 02:04:50 -0400</pubDate>
      
      <guid>https://jorenjoestar.github.io/post/releasing_nes_emulator_source/</guid>
      <description>





&lt;figure&gt;

  &lt;a data-fancybox=&#34;&#34; href=&#34;ZeldaNESEmulated.png&#34; &gt;

&lt;img src=&#34;ZeldaNESEmulated.png&#34; &gt;
&lt;/a&gt;


&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;Legend of Zelda emulated plus debugging windows.&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;Hello everyone!&lt;/p&gt;
&lt;p&gt;Today I release the source code of my bare-bone NES emulator, written in C++.&lt;/p&gt;
&lt;p&gt;I had the idea to write an emulator of one of my favorite console (after the SNES) years ago, and started in 2015 to write the first code (actually in 2008, but it was too daunting even to start).
Then I concentrated on my other big project (still ongoing) and left all the NES code on a side.
Years passed and finally last winter I decided to give it a go to arrive at a ‘usable’ emulator level and release the source code.&lt;/p&gt;
&lt;p&gt;Here it is!
(&lt;a href=&#34;https://github.com/JorenJoestar/HydraNes&#34;&gt;https://github.com/JorenJoestar/HydraNes&lt;/a&gt;)&lt;/p&gt;
&lt;h2 id=&#34;motivation&#34;&gt;Motivation&lt;/h2&gt;
&lt;p&gt;Main motivation both to write and to share this code is &lt;em&gt;knowledge&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;I shamelessly wrote bad code just with the purpose of seeing something on screen as fast as I could.
And I am very honest about that: not happy for the form, but happy for the knowledge I gained!
Also, I think that this code is compact enough to be followed and to understand the basics of NES emulation coding.&lt;/p&gt;
&lt;h2 id=&#34;the-code&#34;&gt;The code&lt;/h2&gt;
&lt;p&gt;The &lt;strong&gt;NES code&lt;/strong&gt; lives in the Nes.h/.cpp pair of files.
The &lt;strong&gt;APU&lt;/strong&gt; is implemented using &lt;strong&gt;Blargg’s implementation&lt;/strong&gt;: when I’ll have other time I will attemp to finish my own implementation, but for now it is ok like that.&lt;/p&gt;
&lt;p&gt;The flow is the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;NES is initialized&lt;/li&gt;
&lt;li&gt;After loading a rom (from the Cartridge window) the mapper will be selected and memory copied to local buffers.&lt;/li&gt;
&lt;li&gt;CPU starts its continuous emulation.&lt;/li&gt;
&lt;li&gt;CPU will execute until a frame is produced. This is checked by the PPU frame changing.&lt;/li&gt;
&lt;li&gt;PPU execution is bound to memory accesses, both read and write.&lt;/li&gt;
&lt;li&gt;Each CPU memory access corresponds to 3 PPU cycles (in NTSC, the only region emulated).&lt;/li&gt;
&lt;li&gt;After the frame is ended the APU emulation is advanced.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;interesting-spots&#34;&gt;Interesting spots&lt;/h2&gt;
&lt;p&gt;There are different areas of the code that are interesting, but I would like to highlight some.&lt;/p&gt;
&lt;h3 id=&#34;cpustep&#34;&gt;Cpu::Step()&lt;/h3&gt;
&lt;p&gt;This is where all the &lt;strong&gt;CPU&lt;/strong&gt; instructions are executed. I opted for a macro based approach instead of tables of function pointers.&lt;/p&gt;
&lt;p&gt;For each cpu cycle:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Fetch the instruction opcode&lt;/li&gt;
&lt;li&gt;Calculate the operand address (called ‘effectiveAddress’)&lt;/li&gt;
&lt;li&gt;Execute the operation&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;All the operations and addressing modes are in the Nes.h file.
&lt;em&gt;Addressing modes&lt;/em&gt; are the way the NES gets its operand for each operation.
Operations are the instruction themselves — using those operands.&lt;/p&gt;
&lt;h3 id=&#34;ppustep&#34;&gt;Ppu::Step()&lt;/h3&gt;
&lt;p&gt;PPU by itself is the most difficult part to emulate (APU is easier on the channels, but harder on the mix and signal generation!).&lt;/p&gt;
&lt;p&gt;I will make a post about that soon, but in the meantime here the code is and implements the behaviours described here:&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://wiki.nesdev.com/w/index.php/File:Ntsc_timing.png&#34;&gt;https://wiki.nesdev.com/w/index.php/File:Ntsc_timing.png&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The &lt;strong&gt;PPU&lt;/strong&gt; draws in tiles of &lt;strong&gt;8x8 pixels&lt;/strong&gt;, so for each pixels created on the screen there will be a gathering of all the data necessary to calculate the final color.&lt;/p&gt;
&lt;p&gt;The rendering is divided in &lt;strong&gt;background&lt;/strong&gt; and &lt;strong&gt;sprites&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Background is just &lt;strong&gt;8x8 pixel per tile&lt;/strong&gt; choosen from the &lt;strong&gt;nametable&lt;/strong&gt; (a screen table of which tiles are visible) and &lt;strong&gt;sprites&lt;/strong&gt; are either 8x8 or 8x16 rectangles coming from a different memory area (uploaded using &lt;strong&gt;DMA&lt;/strong&gt;).&lt;/p&gt;
&lt;p&gt;There are many quirks and uniqueness about the &lt;strong&gt;PPU&lt;/strong&gt;, like the &lt;strong&gt;pattern table&lt;/strong&gt; (a 16x16 grid storing the higher 2 bits of all the underlying background pixels), or the vertical blank period, or the open bus.&lt;/p&gt;
&lt;h3 id=&#34;ppudrawpixel&#34;&gt;Ppu::DrawPixel()&lt;/h3&gt;
&lt;p&gt;The color of a pixel comes from one of the 16 entries of the &lt;strong&gt;palette VRAM&lt;/strong&gt;, and to do so 4 bits must be calculated for background and for sprites.&lt;/p&gt;
&lt;p&gt;For background tiles, 2 pixels comes from the ‘texture’ (&lt;strong&gt;CHR-ROM&lt;/strong&gt;) and 2 from the attribute table.
&lt;!-- raw HTML omitted --&gt;Sprites contains all those informations together.&lt;/p&gt;
&lt;p&gt;The output is a silly &lt;em&gt;SSBO&lt;/em&gt; that contains RGBA colors to be used in a compute shader that outputs to the screen.&lt;/p&gt;
&lt;h3 id=&#34;cpureadwrite-ppureadwrite&#34;&gt;CpuRead/Write, PpuRead/Write&lt;/h3&gt;
&lt;p&gt;All those methods are essential because the NES uses memory mapping i/o to access the different hardware.&lt;/p&gt;
&lt;p&gt;For example the &lt;strong&gt;PPU&lt;/strong&gt; access the cartridge through the mapper in the memory controller to read drawing informations, the &lt;strong&gt;CPU&lt;/strong&gt; writes to the &lt;strong&gt;PPU&lt;/strong&gt; using address $2007, etc.&lt;/p&gt;
&lt;h2 id=&#34;ending-notes&#34;&gt;Ending notes&lt;/h2&gt;
&lt;p&gt;I will prepare more detailed posts about the &lt;strong&gt;NES architecture and emulation&lt;/strong&gt;, even though there are still some concepts that are not clear to me and require a deeper investigation.&lt;/p&gt;
&lt;p&gt;So far this is the most &lt;em&gt;satisfactory&lt;/em&gt; personal project I’ve done, and one of the few that arrived at a usable level.&lt;/p&gt;
&lt;p&gt;In the future I want to improve this emulator and use the knowledge to explore the writing of a SNES emulator!&lt;/p&gt;
&lt;p&gt;Any question or comment please let me know!&lt;/p&gt;
&lt;p&gt;Gabriel&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
