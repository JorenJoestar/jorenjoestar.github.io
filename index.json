[{"authors":["admin"],"categories":null,"content":"Video-games Lover. Guitar enthusiast. Life-surfer.\nPassion, mistakes and curiosity.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"Video-games Lover. Guitar enthusiast. Life-surfer.\nPassion, mistakes and curiosity.","tags":null,"title":"Gabriel Sassone","type":"authors"},{"authors":[],"categories":[],"content":" Overview   Model used in the demo.   Data Driven Rendering Series: 1. https://jorenjoestar.github.io/post/writing_shader_effect_language_1/ 2. https://jorenjoestar.github.io/post/writing_shader_effect_language_2/ 3. https://jorenjoestar.github.io/post/writing_shader_effect_language_3/ 4. https://jorenjoestar.github.io/post/data_driven_rendering_pipeline/\nWe finally arrived in the Rendering Pipeline realm.\nSome can write that it is useless, some can hate it.\nMany have some sort of abstraction for it since ages, and others have to now that new APIs like Vulkan and DX12 have it as an explicit part of their design (finally!).\nAfter we built a basic Material System in the previous article (https://jorenjoestar.github.io/post/writing_shader_effect_language_3/) we can add another layer on top of it and built a complete Rendering Frame.\nIn this article I will talk about a simplified version of Render Graph that I call Render Pipeline and came into my mind in the canteen of Codemasters after thinking:\n What is the biggest dependency in Rendering ?\n The answer is simple:\n Render Targets!\n Render Targets or Frame Buffers is just an intermediate buffer in which we can draw something and use it later.\nBasically a Read/Write texture!\nIt is not easy to shuffle around a Render Target, and having knowledge of which one are you using can make a huge difference for your rendering tech.\nTextures and Render Targets are the biggest memory lord in any rendering application, thus knowing where you are spending your memory can be really powerful.\nFrom a pure understanding of rendering techniques, having a clear visualization of this aspect makes a HUGE difference!\nOnce I started using to describe a frame of rendering with the Render Target Dependencies I never looked back.\nAs always, knowledge is power.\nRender Pipeline Thinking First of all, let\u0026rsquo;s start defining some general concepts to describe the problem we are trying to solve.\nThe problem we are trying to solve is:\n How to describe the inter-frame dependencies of Render Targets in a frame ?\n The dependencies are who writes and/or read from/to a Render Target.\nThat is exactly what is described in a Render Pipeline. Enter the Render Pipeline.\n A Render Pipeline is a list of Passes that read and writes Render Targets.\n That\u0026rsquo;s it.\nDone! See you next article!\nOf course I am kidding - but this is the gist of it.\nThe implications, however, are profound.\nNext logical question is:\n How can we read and write from/to a Render Target ?\n Let\u0026rsquo;s list how we can write to a Render Target\n Graphics - binding some geometry, render states and Render Targets Compute - write anything to the Render Target  Even a so called \u0026lsquo;post-process\u0026rsquo; is just a fullscreen triangle with a shader.\nAnd to read\u0026hellip;well any shader that takes reads a texture!\nIt is incredible to think that with this simple building blocks you can describe almost everything to render!\nFor example, let\u0026rsquo;s try to express some common rendering techniques using only those concepts.\nDeferred Rendering We can define the following simple steps:\n Meshes uses their materials (shaders + textures + constants) as input and write into GBuffer Render Target + depth. A Compute/Post-process shader will read the Gbuffer Render Target and depth (to reconstruct the pixel position), a light list of some sort and outputs a texture with the result. Transparent objects are drawn into this new Render Target using their materials. And so on\u0026hellip;  Exponential Variance Shadow Mapping in a Forward Rendering Pipeline  Meshes writes into a depth-only render target using the light as \u0026lsquo;camera/point of view\u0026rsquo;. Compute or Postprocess converts the depth-only render target into a EVSM one. Meshes uses their materials and the EVSM shadow map to render into a \u0026lsquo;main\u0026rsquo; Render Target.  Other Rendering Concepts To give a full description of the frame we need to add other concepts that will help us.\nThese are the less strict ones - and just a personal way of seeing things.\nRender View The concept of \u0026lsquo;Render View\u0026rsquo; is just a way or representing a camera and a list of visible objects from it.\nWe will see how we use it later, but a simple example of Render View would be the \u0026lsquo;Sun Shadow\u0026rsquo; render view - representing the sun (as a camera) and a list of visible objects from it.\nThe \u0026lsquo;Main\u0026rsquo; render view of course represent the main camera and visible objects.\nThis, combined with render managers becomes a powerful combination to describe what needs to be rendered.\nRender Manager If you think from an ECS mentality, this would be a \u0026lsquo;system\u0026rsquo;.\nEach render manager is responsible to render one or more render \u0026lsquo;aspects/entities\u0026rsquo; into a Render Pass.\nA render manager can subscribe to any \u0026lsquo;graphics\u0026rsquo; pass and render from there.\nFor example, a \u0026lsquo;static geometry\u0026rsquo; render manager could setup an instancing buffer for the gbuffer-generation pass and draw all objects.\nRender Pipeline Implementation After we defined the basic concepts let\u0026rsquo;s see an actual implementation of the Render Pipeline.\nWe will see the code of each component and arrive at the actual data definition (in json).\nThe code has changed a bit since last article, with the inclusion of CGLM as math library and other high-level rendering code, included in hydra_rendering.h/.cpp.\nRender View First element is the Render View:\n// // Render view is a 'contextualized' camera - a way of using the camera in the render pipeline. // struct RenderView { Camera camera; array( RenderScene ) visible_render_scenes; }; // struct RenderView  Using STB\u0026rsquo;s array (the macro is just an aid to know it is not just a pointer) we have a list of visible render scenes from that camera.\nIt should be pretty straighforward.\nRender Manager Next is Render Manager:\n// struct RenderManager { struct RenderContext { Device* device; const RenderView* render_view; CommandBuffer* commands; RenderScene* render_scene_array; uint16_t start; uint16_t count; uint16_t stage_index; }; // struct RenderContext virtual void render( RenderContext\u0026amp; render_context ) = 0; }; // struct RenderManager  The base class is really just a \u0026lsquo;render\u0026rsquo; method.\nHere the RenderContext is interesting, and it gives access to all you need to render:\n Device - used to map/unmap resources. RenderView - access to camera (and more, but that\u0026rsquo;s for the next article!). CommandBuffer - the actual draw commands are written here. RenderScene - the RenderScene from start to start + count.  In this very simple demo, we have just 2 render managers: Line Renderer and Scene Renderer.\nThe most interesting one is the second: Line Renderer has commands to draw lines that will be mapped into a GPU buffer and uses instancing to draw them.\n void LineRenderer::render( RenderContext\u0026amp; render_context ) { Device\u0026amp; device = *render_context.device; // Update camera matrix const Camera\u0026amp; camera = render_context.render_view-\u0026gt;camera; MapBufferParameters cb_map = { lines_cb, 0, 0 }; float L = 0, T = 0; float R = device.swapchain_width, B = device.swapchain_height; const float ortho_projection[4][4] = { { 2.0f / ( R - L ), 0.0f, 0.0f, 0.0f }, { 0.0f, 2.0f / ( T - B ), 0.0f, 0.0f }, { 0.0f, 0.0f, -1.0f, 0.0f }, { ( R + L ) / ( L - R ), ( T + B ) / ( B - T ), 0.0f, 1.0f }, }; LocalConstants* cb_data = (LocalConstants*)device.map_buffer( cb_map ); if ( cb_data ) { cb_data-\u0026gt;view_projection = camera.view_projection; memcpy( \u0026amp;cb_data-\u0026gt;projection, \u0026amp;ortho_projection, 64 ); cb_data-\u0026gt;resolution = { device.swapchain_width * 1.0f, device.swapchain_height * 1.0f, 1.0f / device.swapchain_width, 1.0f / device.swapchain_height }; device.unmap_buffer( cb_map ); } if ( current_line_index ) { const uint32_t mapping_size = sizeof( LinVertex ) * current_line_index; MapBufferParameters map_parameters_vb = { lines_vb, 0, mapping_size }; LinVertex* vtx_dst = (LinVertex*)device.map_buffer( map_parameters_vb ); if ( vtx_dst ) { memcpy( vtx_dst, \u0026amp;s_line_buffer[0], mapping_size ); device.unmap_buffer( map_parameters_vb ); } CommandBuffer* commands = render_context.commands; commands-\u0026gt;begin_submit( 2 ); ShaderInstance\u0026amp; shader_instance = line_material-\u0026gt;shader_instances[3]; commands-\u0026gt;bind_pipeline( shader_instance.pipeline ); commands-\u0026gt;bind_resource_list( shader_instance.resource_lists, shader_instance.num_resource_lists, nullptr, 0 ); commands-\u0026gt;bind_vertex_buffer( lines_vb, 0, 0 ); // Draw using instancing and 6 vertices. const uint32_t num_vertices = 6; commands-\u0026gt;draw( TopologyType::Triangle, 0, num_vertices, current_line_index / 2 ); commands-\u0026gt;end_submit(); current_line_index = 0; } }  Easy to notice how, with a Vulkan/DX12 interface, there are few less commands to write. Binding a pipeline sets everything considered \u0026lsquo;static\u0026rsquo; - render states, shaders - and with just resource lists (that sets textures and constants) and vertex/index buffers we have everything needed to render.\nNOTE: HFX has gone some improvements and now supports render states and vertex declarations/formats. I\u0026rsquo;ll write about it in the next post - but this has become crucial.\nShader Resources Management This is another personal preference - but not necessary at all.\nTwo concepts are really useful to me to be explicit and centralized: resources and bindings.\nResources are all referenced in a \u0026lsquo;Shader Resource Database\u0026rsquo;:\n// // Struct used to retrieve textures, buffers and samplers. // struct ShaderResourcesDatabase { struct BufferStringMap { char* key; BufferHandle value; }; // struct BufferStringMap struct TextureStringMap { char* key; TextureHandle value; }; // struct TextureStringMap struct SamplerStringMap { char* key; SamplerHandle value; }; // struct SamplerStringMap BufferStringMap* name_to_buffer = nullptr; TextureStringMap* name_to_texture = nullptr; SamplerStringMap* name_to_sampler = nullptr; void init(); void terminate(); void register_buffer( char* name, BufferHandle buffer ); void register_texture( char* name, TextureHandle texture ); void register_sampler( char* name, SamplerHandle sampler ); BufferHandle find_buffer( char* name ); TextureHandle find_texture( char* name ); SamplerHandle find_sampler( char* name ); }; // struct ShaderResourcesDatabase  Simply put, any resource used by rendering is here.\nBoth Materials, Pipelines and Render Managers register and use the database to create the resource lists used in rendering.\nNext and more convoluted is the shader resources lookup class:\n// // Struct to link between a Shader Binding Name and a Resource. Used both in Pipelines and Materials. // struct ShaderResourcesLookup { enum Specialization { Frame, Pass, View, Shader }; // enum Specialization struct NameMap { char* key; char* value; }; // struct NameMap struct SpecializationMap { char* key; Specialization value; }; // struct SpecializationMap NameMap* binding_to_resource = nullptr; SpecializationMap* binding_to_specialization = nullptr; NameMap* binding_to_sampler = nullptr; void init(); void terminate(); void add_binding_to_resource( char* binding, char* resource ); void add_binding_to_specialization( char* binding, Specialization specialization ); void add_binding_to_sampler( char* binding, char* sampler ); char* find_resource( char* binding ); Specialization find_specialization( char* binding ); char* find_sampler( char* binding ); void specialize( char* pass, char* view, ShaderResourcesLookup\u0026amp; final_lookup ); }; // struct ShaderResourcesLookup  This class specify the binding between a shader resource and an actual resource.\nAs a simple example to clarify, a shader could have an \u0026lsquo;albedo\u0026rsquo; texture defined in the code, but the actual texture is defined by the material.\nOr for a Render Stage, like a Post-Processing one, its input could be defined in the shader code as \u0026lsquo;input 0, input 1\u0026hellip;\u0026rsquo; and the render pipeline creates the binding.\nWith those in place, we can finalize any resource used by any shader/material/pipeline.\nThe actual usage is into the Shader Instance class. Let\u0026rsquo;s have a quick look.\n// struct ShaderInstance { void load_resources( const PipelineCreation\u0026amp; pipeline, PipelineHandle pipeline_handle, ShaderResourcesDatabase\u0026amp; database, ShaderResourcesLookup\u0026amp; lookup, Device\u0026amp; device ); PipelineHandle pipeline; ResourceListHandle resource_lists[k_max_resource_layouts]; uint32_t num_resource_lists; }; // struct ShaderInstance  This class is what actually contains the resource lists and pipeline used to render anything.\nNot very happy with the name - any suggestion welcome.\nA material contains a list of those - one for each pass - and is used to draw.\nAgain with the new Vulkan/DX12 mentality, Pipeline + Resource Lists + Geometry is all you need to render almost.\nThe magic happens when creating the resource lists:\nvoid ShaderInstance::load_resources( const PipelineCreation\u0026amp; pipeline_creation, PipelineHandle pipeline_handle, ShaderResourcesDatabase\u0026amp; database, ShaderResourcesLookup\u0026amp; lookup, Device\u0026amp; device ) { using namespace hydra::graphics; ResourceListCreation::Resource resources_handles[k_max_resources_per_list]; for ( uint32_t l = 0; l \u0026lt; pipeline_creation.num_active_layouts; ++l ) { // Get resource layout description ResourceListLayoutDescription layout; device.query_resource_list_layout( pipeline_creation.resource_list_layout[l], layout );  We know that a pipeline can have 1 or more resource lists, thus we just iterate through them.\nNext we look into each resource of the current list:\n // For each resource for ( uint32_t r = 0; r \u0026lt; layout.num_active_bindings; r++ ) { const ResourceBinding\u0026amp; binding = layout.bindings[r]; // Find resource name // Copy string_buffer char* resource_name = lookup.find_resource( (char*)binding.name ); switch ( binding.type ) { case hydra::graphics::ResourceType::Constants: case hydra::graphics::ResourceType::Buffer: { BufferHandle handle = resource_name ? database.find_buffer( resource_name ) : device.get_dummy_constant_buffer(); resources_handles[r].handle = handle.handle; break; } ... same for textures  For each binding coming from the shader (think \u0026lsquo;albedo\u0026rsquo; for a PBR shader) we search for the actual resource name (\u0026lsquo;WoodBeamAlbedo\u0026rsquo;) and query the database to find it.\nAfter we did that, we can create the list:\n } } ResourceListCreation creation = { pipeline_creation.resource_list_layout[l], resources_handles, layout.num_active_bindings }; resource_lists[l] = device.create_resource_list( creation ); } num_resource_lists = pipeline_creation.num_active_layouts; pipeline = pipeline_handle; }  With this mechanism we added another explicit connection between resources.\nIt is finally time to see the actual render pipeline!\nRender Stage/Pass This is the CORE of everything, and it must work with all both geometrical stages and post-process ones.\nYou can either create a base virtual class or doing something like here.\nImportant is understanding the concept!\n// // Encapsulate the rendering of anything that writes to one or more Render Targets. // struct RenderStage { enum Type { Geometry, Post, PostCompute, Swapchain, Count }; Type type = Count;  Simply we define the types:\n Geometry - uses render manager with meshes to draw. Post - fullscreen triangle + shader. PostCompute - any compute shader execution basically! Swapchain - special case of binding the window framebuffer and render the last time.  Next is the most important part: dependencies!\n array( TextureHandle ) input_textures = nullptr; array( TextureHandle ) output_textures = nullptr; TextureHandle depth_texture;  When we create the pipeline, we save all inputs and outputs textures.\nDepth/Stencil is a put in its own part.\n float scale_x = 1.0f; float scale_y = 1.0f; uint16_t current_width = 1; uint16_t current_height = 1;  Here we handle scaling. When using scale, we use the framebuffer\u0026rsquo;s window width/height to calculate the Render Target size of the output ones. When using the current width/height we instead define a specific size (like for a shadow map).\n RenderPassHandle render_pass;  hydra::graphics low level rendering needs this handle to actually handle the drawing.\n Material* material = nullptr; uint8_t pass_index = 0;  This is for PostProcesses : material and pass index to retrieve the \u0026lsquo;shader instance\u0026rsquo; containing the pipeline and the resource lists.\n RenderView* render_view = nullptr;  RenderView used by this stage.\nFor example the \u0026lsquo;Sun Shadow Render Stage\u0026rsquo; will use the \u0026lsquo;Shadow Render View\u0026rsquo; to dispatch all its objects to each render manager.\n float clear_color[4]; float clear_depth_value; uint8_t clear_stencil_value; uint8_t clear_rt : 1; uint8_t clear_depth : 1; uint8_t clear_stencil : 1; uint8_t resize_output : 1; uint8_t pad : 4;  If the stage needs to clear its output(s), these will tell what to do.\n uint64_t geometry_stage_mask; // Used to send render objects to the proper stage. Not used by compute or postprocess stages.  This creates a link between render managers and stages.\nAn object is rendered only if its stage mask equals at least one stage.\nWhy that ? Because when defining a render view, we have a list of objects visible from that camera, and we need a way of dispatching those objects to their respective managers.\nFor example a \u0026lsquo;dynamic render object\u0026rsquo; could have appear both on the gbuffer pass and an \u0026lsquo;object special effect\u0026rsquo; pass - both visible from the main camera.\nThis ideas comes from the AMAZING talk by Bungie:\nhttp://advances.realtimerendering.com/destiny/gdc_2015/Tatarchuk_GDC_2015__Destiny_Renderer_web.pdf\nA render manager is what they call a feature renderer - named differently because this version is much more basic!\n array( RenderManager* ) render_managers;  Render Managers can register to stages even if they don\u0026rsquo;t have objects, for example a \u0026lsquo;Lighting Manager\u0026rsquo; would want to submit a list of visible light in a certain pass.\n // Interface virtual void init(); virtual void terminate(); virtual void begin( Device\u0026amp; device, CommandBuffer* commands ); virtual void render( Device\u0026amp; device, CommandBuffer* commands ); virtual void end( Device\u0026amp; device, CommandBuffer* commands ); virtual void load_resources( ShaderResourcesDatabase\u0026amp; db, Device\u0026amp; device ); virtual void resize( uint16_t width, uint16_t height, Device\u0026amp; device ); void register_render_manager( RenderManager* manager ); }; // struct RenderStage  This is the final interface.\nLoad resources is used for PostProcesses - they have a material and need to load its resources.\nRender Pipeline We arrived at the last piece of the puzzle!\n// // A full frame of rendering using RenderStages. // struct RenderPipeline { struct StageMap { char* key; RenderStage* value; }; struct TextureMap { char* key; TextureHandle value; }; void init( ShaderResourcesDatabase* initial_db ); void terminate( Device\u0026amp; device ); void update(); void render( Device\u0026amp; device, CommandBuffer* commands ); void load_resources( Device\u0026amp; device ); void resize( uint16_t width, uint16_t height, Device\u0026amp; device ); StageMap* name_to_stage = nullptr; TextureMap* name_to_texture = nullptr; ShaderResourcesDatabase resource_database; ShaderResourcesLookup resource_lookup; }; // struct RenderPipeline  This is literally IT!\nThis class contains all the stages and resources needed to render.\nMost of the time it will just iterate over the stages and execute something per stage.\nResource database contains all the resources used actually - and the lookup instead is only for the PostProcess stages.\nRender Pipeline Description We really have all the part to render a frame!\nLet\u0026rsquo;s look at the data defining the pipeline.\nWe will define a simple-silly-non-effective PBR deferred rendering.\nProbably the worst shaders you saw, but it will still work.\nFirst we define the Render Targets:\n{ \u0026quot;name\u0026quot;: \u0026quot;PBR_Deferred\u0026quot;, \u0026quot;RenderTargets\u0026quot;: [ { \u0026quot;name\u0026quot;: \u0026quot;GBufferAlbedo\u0026quot;, \u0026quot;format\u0026quot;: \u0026quot;R8G8B8A8_UNORM\u0026quot; }, { \u0026quot;name\u0026quot;: \u0026quot;GBufferNormals\u0026quot;, \u0026quot;format\u0026quot;: \u0026quot;R16G16B16A16_SNORM\u0026quot; }, { \u0026quot;name\u0026quot;: \u0026quot;GBufferProperties0\u0026quot;, \u0026quot;format\u0026quot;: \u0026quot;R8G8B8A8_UNORM\u0026quot; }, { \u0026quot;name\u0026quot;: \u0026quot;MainDepth\u0026quot;, \u0026quot;format\u0026quot;: \u0026quot;D24_UNORM_S8_UINT\u0026quot; }, { \u0026quot;name\u0026quot;: \u0026quot;BackBufferColor\u0026quot;, \u0026quot;format\u0026quot;: \u0026quot;R16G16B16A16_FLOAT\u0026quot; } ],  by default they will have the same size as the window framebuffer, unless otherwise written (scale_x/y, width/height).\nNext are the actual render stages.\nThe first is the GBufferOpaque one:\n \u0026quot;RenderStages\u0026quot;: [ { \u0026quot;name\u0026quot;: \u0026quot;GBufferOpaque\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;Geometry\u0026quot;, \u0026quot;render_view\u0026quot;: \u0026quot;main\u0026quot;, \u0026quot;depth_stencil\u0026quot;: \u0026quot;Main\u0026quot;, \u0026quot;inputs\u0026quot;: [ ], \u0026quot;outputs\u0026quot;: { \u0026quot;rts\u0026quot;: [ \u0026quot;GBufferAlbedo\u0026quot;, \u0026quot;GBufferNormals\u0026quot;, \u0026quot;GBufferProperties0\u0026quot; ], \u0026quot;depth\u0026quot;: \u0026quot;MainDepth\u0026quot;, \u0026quot;flags\u0026quot;: \u0026quot;Common\u0026quot;, \u0026quot;clear_color\u0026quot;: \u0026quot;000000ff\u0026quot;, \u0026quot;clear_depth\u0026quot;: 1.0, \u0026quot;clear_stencil\u0026quot;: 0 } },  As you see it outputs to 3 Render Targets + Depth.\nIt also specify clear color, depth and stencil.\nNext is the silliest compute shader to calculate light:\n { \u0026quot;name\u0026quot;: \u0026quot;DeferredLights\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;PostCompute\u0026quot;, \u0026quot;material_name\u0026quot;: \u0026quot;SimpleFullscreen\u0026quot;, \u0026quot;material_pass_index\u0026quot;: 2, \u0026quot;inputs\u0026quot;: [ { \u0026quot;name\u0026quot;: \u0026quot;GBufferAlbedo\u0026quot;, \u0026quot;sampler\u0026quot;: \u0026quot;Point\u0026quot;, \u0026quot;binding\u0026quot;: \u0026quot;gbuffer_albedo\u0026quot; }, { \u0026quot;name\u0026quot;: \u0026quot;GBufferNormals\u0026quot;, \u0026quot;sampler\u0026quot;: \u0026quot;Point\u0026quot;, \u0026quot;binding\u0026quot;: \u0026quot;gbuffer_normals\u0026quot; }, { \u0026quot;name\u0026quot;: \u0026quot;GBufferProperties0\u0026quot;, \u0026quot;sampler\u0026quot;: \u0026quot;Point\u0026quot;, \u0026quot;binding\u0026quot;: \u0026quot;gbuffer_properties0\u0026quot; }, { \u0026quot;name\u0026quot;: \u0026quot;MainDepth\u0026quot;, \u0026quot;sampler\u0026quot;: \u0026quot;Point\u0026quot;, \u0026quot;binding\u0026quot;: \u0026quot;depth_texture\u0026quot; } ], \u0026quot;outputs\u0026quot;: { \u0026quot;images\u0026quot;: [ { \u0026quot;name\u0026quot;: \u0026quot;BackBufferColor\u0026quot;, \u0026quot;binding\u0026quot;: \u0026quot;destination_texture\u0026quot; } ], \u0026quot;flags\u0026quot;: \u0026quot;Common\u0026quot; } },  It will read all the previously generated textures and run a compute shader to calculate the final lighting.\nWorth noting \u0026lsquo;material\u0026rsquo; and \u0026lsquo;material pass index\u0026rsquo; - to retrieve the shader from the material. If you open SimpleFullscreen.hfx and go to the third defined pass, you will see the code.\nNext is an example of reusing a Render Target to add informations (like transparent objects).\nIt will add debug rendering on top of the other objects and write in the BackBufferColor render target.\nThe absence of clear parameters dictates that we don\u0026rsquo;t want to clear.\n { \u0026quot;name\u0026quot;: \u0026quot;DebugRendering\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;Geometry\u0026quot;, \u0026quot;render_view\u0026quot;: \u0026quot;main\u0026quot;, \u0026quot;inputs\u0026quot;: [ ], \u0026quot;outputs\u0026quot;: { \u0026quot;rts\u0026quot;: [ \u0026quot;BackBufferColor\u0026quot; ], \u0026quot;depth\u0026quot;: \u0026quot;MainDepth\u0026quot;, \u0026quot;flags\u0026quot;: \u0026quot;Common\u0026quot; } },  Last step is the swapchain.\nIt is simply using a simple shader to write to the window framebuffer as the last step of the frame.\n { \u0026quot;name\u0026quot;: \u0026quot;Swapchain\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;Swapchain\u0026quot;, \u0026quot;mask\u0026quot;: \u0026quot;FRAMEBUFFER\u0026quot;, \u0026quot;material_name\u0026quot;: \u0026quot;Swapchain\u0026quot;, \u0026quot;render_view\u0026quot;: \u0026quot;\u0026quot;, \u0026quot;depth_stencil\u0026quot;: \u0026quot;Post\u0026quot;, \u0026quot;inputs\u0026quot;: [ { \u0026quot;name\u0026quot;: \u0026quot;BackBufferColor\u0026quot;, \u0026quot;sampler\u0026quot;: \u0026quot;Point\u0026quot;, \u0026quot;binding\u0026quot;: \u0026quot;input_texture\u0026quot; } ], \u0026quot;outputs\u0026quot;: { \u0026quot;rts\u0026quot;: [ ], \u0026quot;depth\u0026quot;: \u0026quot;\u0026quot;, \u0026quot;flags\u0026quot;: \u0026quot;Common\u0026quot;, \u0026quot;clear_color\u0026quot;: \u0026quot;000000ff\u0026quot; } } ] }  Visualization With all this defined, we can arrive to have something incredibly useful as this (included in the demo!):\n  Render Pipeline   To me this is the quintessence of rendering: visualization.\nSeeing things helps me understanding much better.\nDebugging broken features, studying features, understanding dependencies, shuffling things around becomes MUCH easier.\nDemo and code In the code provided there is everything I am talking here.\n3 models are included from the free GLTF library.\nKudos to TinyGltf (https://github.com/syoyo/tinygltf) used to read the models.\nThere is also a simple shader reload to quickly iterate.\nLastly, this is not anywhere near production ready, but I am still happy to share it as a knowledge building block for others.\nConclusions We arrived at defining the Render Pipeline - a way of describing how a frame is rendered.\nIt is a very simplified version of the RenderGraph/FrameGraph - as seen in many talks - and this is something I\u0026rsquo;ve used in my home projects (and current indie game) with great success.\nNo mention of adding resource barriers, sharing memory, async compute and more.\nThe whole purpose of this article was instead to focus on the more high level architecture.\nWhat is next ?\nI would write about the improvements on the HFX shader effect and would like to cleanup and make that library more robust.\nThen there is the Vulkan backend to be wrote and many examples to be done.\nTalking deeper about dispatching rendering draws, render managers and such.\nPlease comment, share, send feedback! I am happy to answer any question!\nGabriel\n","date":1571064229,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1582383529,"objectID":"7c26dedfc7a8e73a1db210a4acccdded","permalink":"/post/data_driven_rendering_pipeline/","publishdate":"2019-10-14T10:43:49-04:00","relpermalink":"/post/data_driven_rendering_pipeline/","section":"post","summary":"Overview   Model used in the demo.   Data Driven Rendering Series: 1. https://jorenjoestar.github.io/post/writing_shader_effect_language_1/ 2. https://jorenjoestar.github.io/post/writing_shader_effect_language_2/ 3. https://jorenjoestar.github.io/post/writing_shader_effect_language_3/ 4. https://jorenjoestar.github.io/post/data_driven_rendering_pipeline/\nWe finally arrived in the Rendering Pipeline realm.\nSome can write that it is useless, some can hate it.\nMany have some sort of abstraction for it since ages, and others have to now that new APIs like Vulkan and DX12 have it as an explicit part of their design (finally!","tags":[],"title":"Data Driven Rendering: Pipelines","type":"post"},{"authors":[],"categories":[],"content":" Overview Data Driven Rendering Series: 1. https://jorenjoestar.github.io/post/writing_shader_effect_language_1/ 2. https://jorenjoestar.github.io/post/writing_shader_effect_language_2/ 3. https://jorenjoestar.github.io/post/writing_shader_effect_language_3/ 4. https://jorenjoestar.github.io/post/data_driven_rendering_pipeline/\nIn Part 2 of this series we added Resource Layouts and Properties to the HFX language, trying to arrive at a point in which we can describe the rendering of a Shader Effect almost entirely.\nIn this article I would like to explore further adds to HFX, especially a proper Material System to be used in conjunction with the HFX language.\nI also separated the code a little bit for clarity and added the usage of STB array and hash maps.\nWith that I would like to develop a Material System that is robust and easy to use, even though I am (DISCLAIMER!) far from it!\nI will first talk about the theory and thoughts behind those changes, and then go through the code changes and addition.\nMaterial System thoughts Following a nomenclature from the amazing guys at our_machinery, we are adding a Tier 1 Shader System - something that builds on top of the graphics API created in the previous article.\nFirst of all, a great series of article is again on their website:\n https://ourmachinery.com/post/the-machinery-shader-system-part-1/ https://ourmachinery.com/post/the-machinery-shader-system-part-2/ https://ourmachinery.com/post/the-machinery-shader-system-part-3/  We are building a Material System based on a graphics-API that exposes the following concepts:\n Buffer Texture Pipeline (that includes shaders) Render Pass Resource List Layout Resource List  We are using a Vulkan/D3D12 interface here, and these concepts map 1 to 1 with that.\nOne of the big changes from a typical low-level graphics API is both the \u0026lsquo;missing\u0026rsquo; concept of Shader as a resource, and the addition of Render Pass as resource.\nA new concept is the one of Resource List Layout and Resource List.\nThe Vulkan names are Descriptor Set Layout and Descriptor Set, but even though they reflect more the underlying driver nature of the term, I changed to Resource List just to have it clearer as a concept.\nThe King here is the Pipeline: it is a structure that contains all the immutable data of a pipeline. That includes our missing shaders, all the render states (DepthStencil, AlphaBlend, \u0026hellip;) and a Layout of the resources to be used by the shader.\nPart of the dynamic pipeline states are normally the geometry and the resource lists.\nNote that I am using the plural here: each pipeline can have 1 or more resource lists!!.\nThis is a good to organize your resources based on update frequencies, something coming from the numerous talks about Approaching Zero Driver Overhead.\nRemembering the simple interface of our API, now we have the following:\nstruct Device { ... BufferHandle create_buffer( const BufferCreation\u0026amp; creation ); TextureHandle create_texture( const TextureCreation\u0026amp; creation ); PipelineHandle create_pipeline( const PipelineCreation\u0026amp; creation ); SamplerHandle create_sampler( const SamplerCreation\u0026amp; creation ); ResourceListLayoutHandle create_resource_list_layout( const ResourceListLayoutCreation\u0026amp; creation ); ResourceListHandle create_resource_list( const ResourceListCreation\u0026amp; creation ); RenderPassHandle create_render_pass( const RenderPassCreation\u0026amp; creation ); ... };  If you look at the OpenGL implementation (the only I wrote for now :( ) you will find that Shaders are considered resources, but it is more for convenience of the attach/linking OpenGL need than anything else.\nLet\u0026rsquo;s finally introduce the new concept for this article!\nShader Effect  A Shader Effect is the blueprint of static data needed to draw something on the screen.\n It needs to include shaders (included in a Pipeline Description), properties (coming from the HFX file) and find its location into a render graph.\n A Shader Effect is 1 to 1 with a Binary HFX file.\n As a convenience we will add also informations about the local constants.\nWhen creating a Shader Effect, we can define properties, and we put all the numerical properties into one buffer.\nThis is the current code:\n struct ShaderEffect { // // struct PropertiesMap { char* key; hfx::ShaderEffectFile::MaterialProperty* value; }; // struct PropertiesMap struct Pass { PipelineCreation pipeline_creation; char name[32]; PipelineHandle pipeline_handle; uint32_t pool_id; }; // struct Pass Pass* passes; uint16_t num_passes = 0; uint16_t num_properties = 0; uint32_t local_constants_size = 0; char* local_constants_default_data = nullptr; char* properties_data = nullptr; PropertiesMap* name_to_property = nullptr; char name[32]; char pipeline_name[32]; uint32_t pool_id; }; // struct ShaderEffect  You see both a pipeline name and an array of passes with a name. These are to insert the pass into a very primordial render graph, that I wrote just because I didn\u0026rsquo;t want to hardcode the frame structure, especially because next article will be EXACTLY on this topic!\nHaving defined the Shader Effect, we can now move into the next big actor.\nMaterial  A Material is an instance of a Shader Effect.\n Given a HFX file, we generate a new file (HMT, Hydra Material) that will contain all the informations.\nThe concept of Material is really unique values for the properties of a Shader Effect.\nThat is basically it.\nFor example, if a shader contains a property like an albedo texture, the material answer the question \u0026ldquo;which albedo texture?\u0026rdquo;.\nThis is done for every property.\nLet\u0026rsquo;s have a look at our new material:\n{ \u0026quot;name\u0026quot;: \u0026quot;SimpleFullscreen\u0026quot;, \u0026quot;effect_path\u0026quot;: \u0026quot;SimpleFullscreen.hfx\u0026quot;, \u0026quot;properties\u0026quot;: [ { \u0026quot;scale\u0026quot;: 16.0, \u0026quot;albedo\u0026quot;: \u0026quot;AngeloCensorship.png\u0026quot;, \u0026quot;modulo\u0026quot;: 2.0 } ], \u0026quot;bindings\u0026quot;: [ { \u0026quot;LocalConstants\u0026quot;: \u0026quot;LocalConstants\u0026quot;, \u0026quot;destination_texture\u0026quot;: \u0026quot;compute_output_texture\u0026quot;, \u0026quot;input_texture\u0026quot;: \u0026quot;compute_output_texture\u0026quot;, \u0026quot;albedo_texture\u0026quot;: \u0026quot;albedo\u0026quot; } ] }  As you can see there is a name, the effect path, the properties and the bindings. These will be explained in the next section.\nProperties are just a name-value list, coming from the Shader Effect itself (the .bhfx file).\nThe texture is my horrible drawing after reading the fantastic rendering guide by Angelo Pesce and how he censored the parts that were internal to Roblox!\nShader Resource Database and Lookup A concept that I saw only in the our_machinery posts, but I personally adopted since a couple of years, is a way of automating a daunting task: setting shader resources.\nI still need to finish the correct implementation of those, but the concepts are simple.\nA Shader Resource Database is a database of resources that can be searched using a Shader Resources Lookup.\nThe name of the binding is the shader related name, while the value is the name into the database.\nOf course you can use hashes instead of names, and compile them into a binary version of this, but this is not important now.\nOne interesting bit (sadly not implemented here, sorry!) is the binding specialization. This is done so that resources can be specialized in the database.\nThis is done per pass and it let you write only one binding list for all the Material, and then gather the proper resource based on the specialization.\nFor example if there is a binding for a pass-dependent resource, writing a generic version can specialize the shader pass correctly. Or using special keywords in the bindings, you can retrieve input/output textures from the render pass in which the shader is rendered!\nFor now though it is more a manual written list, but it will be developed further.\nWhere is my code ? Having introduced the new concept, let\u0026rsquo;s look at the changes that happened in the last weeks of night coding.\nAs said before, in general I separated the code in header/cpp for clarity and building performances (after a good talk on Twitter, https://twitter.com/GabrielSassone/status/1179810419617275905?s=20).\nApplications First big changes was separating the code from the previous articles in an application: namely CustomShaderLanguageApplication in CustomShaderLanguage.h/cpp and MaterialSystemApplication in MaterialSystem.h/cpp.\nThe first contains all the application code that uses HDF and HFX, with code generation and HFX compilation.\nThe second contains both the new Material System and the application that uses it.\nI would love to say that is an usable app, but I really touched my limits in non designing clearly when night coding.\nPersonal note: I hope this could be the spark to create a FX Composer successor, open source and free for all!\nSTB As part of this experiment I wanted to try something different.\nInstead of re-writing array and hash maps with templates, I wanted to give a try to the STB libraries: namely stb_ds.h and stb_image.h.\nArrays and Hash Maps are now included in hydra_lib.h to be used across the code.\nHydra Graphics The device added render passes and the support for multiple resources layout.\nIt also creates FBOs for color passes and supports resize, especially thanks to the Render Pipeline.\nPrimitive Render Graph (called Render Pipeline) I use the term I used since the inception in 2010, and honestly it is more true to what it does.\nIt is not a graph but more a list of Render Stages with input/outputs defined clearly.\nIn the next article I will develop more on this, but for now I needed some structure like this to be explicit.\nIn the application there are 3 pipelines, one for a single pass ShaderToy shader, one for a silly compute to framebuffer shader(that for now loads a texture and outputs it to the framebuffer), and one for just a render to window.\nI use this in my indie project, with a fully custom and data driven (written in json) pipeline that includes compute deferred lighting and shadows, shadow passes, various post-process passes and such, everything very easy to debug and very easy to modify/add/delete.\nThere is a mechanism to send the correct draw calls to the correct pass through the usage of render systems, but again this will be a topic for the next article!\nIn the included code, there is also a small but powerful tool: a pipeline explorer.\nFor now it will just show the render targets for each stage, and in these simple examples does not matter much.\nIn the next article we will dive deep into the Render Pipeline/Graph subject and then all of this will make sense!\nBreak: a simple Resource Manager While being a very important topic, this is not the focus of this article.\nAnyway I wanted a Resource Manager that would be helpful to handle resource creation and loading.\nThis includes also resource compilation, something that normally happens at build time, but in our exercise can be triggered at run-time.\nThe resource manager is a class that simply manages resources using factories and manages dependencies between resources.\nWe have only 3 resources for now:\n Textures Shader Effects Materials  Resources A resource is a class that both has data and let the dependency with other data be clear.\nThe resource\u0026rsquo;s data is actually a pointer to actual raw data used by other systems, in this case rendering.\nLet\u0026rsquo;s see its definition:\nstruct Resource { struct ResourceReference { uint8_t type; char path[255]; }; // struct ResourceReference struct Header { char header[7]; uint8_t type; // ResourceType::enum size_t data_size; uint16_t num_external_references; uint16_t num_internal_references; }; // struct Header struct ResourceMap { char* key; Resource* value; }; Header* header; char* data; void* asset; Resource::ResourceReference* external_references; // External ResourceMap* name_to_external_resources; // Interal }; // struct Resource  A resource is loaded from a binary file and contains a header and some data coming from the file, and an asset containing a system specific pointer.\nWe added 3 system specific resources (Texture, Shader Effect and Material) but the class handled is always resource.\nTo access the system specific data, asset member is used.\nA resource contains also a map to the external resources loaded within it - to handle external references.\nCompilation Starting from a source file (.hfx, .png, .hmt) using the specific factory, the resource manager compiles the code to a binary resource.\nThis means both converting the source format to a binary representation but also adding external dependencies to the file.\nThese dependencies will be loaded when loading the resource, and before it.\nLoading Loading happens by first loading all the dependent resources and then using the specific factory to load the system specific asset.\nThis is a very semplicistic resource management - synchronous only, single threaded, not optimized - so really was an exercise in having something running for both compiling a resource and managing dependencies.\nThe whole point is the separation between a source and human-readable format to a binary one and encapsulate this.\nAfter this (very!) small break on resource management, let\u0026rsquo;s continue to the actual code for the materials!\nMaterial System implementation After all this thory let\u0026rsquo;s look at the code!\nShader Effect The main parts of a Shader Effect are Passes and Properties.\nPasses are the most important one, as they contain all the informations to create an actual Pipeline, called Pipeline Creation.\nRemembering the Vulkan/DX12 interface, we cannot create singularly a shader, but we need all the pipeline data (depth stencil, alpha blend, \u0026hellip;) to actually create the shaders too.\nThe gist here is to access all those informations in a hiearchical way, basically reading them from the RenderPipeline and then overwriting with what is defined in the HFX file.\nRight now there is almost nothing if not the shaders, so the creation is quite simple:\nfor ( uint16_t p = 0; p \u0026lt; shader_effect_file.header-\u0026gt;num_passes; p++ ) { hfx::ShaderEffectFile::PassHeader* pass_header = hfx::get_pass( shader_effect_file, p ); uint32_t shader_count = pass_header-\u0026gt;num_shader_chunks; memcpy( effect-\u0026gt;passes[p].name, pass_header-\u0026gt;stage_name, 32 ); PipelineCreation\u0026amp; pipeline_creation = effect-\u0026gt;passes[p].pipeline_creation; ShaderCreation\u0026amp; creation = pipeline_creation.shaders; bool compute = false; // Create Shaders for ( uint16_t i = 0; i \u0026lt; shader_count; i++ ) { hfx::get_shader_creation( pass_header, i, \u0026amp;creation.stages[i] ); if ( creation.stages[i].type == ShaderStage::Compute ) compute = true; } creation.name = pass_header-\u0026gt;name; creation.stages_count = shader_count; effect-\u0026gt;passes[p].pipeline_creation.compute = compute; // Create Resource Set Layouts for ( uint16_t l = 0; l \u0026lt; pass_header-\u0026gt;num_resource_layouts; l++ ) { uint8_t num_bindings = 0; const ResourceListLayoutCreation::Binding* bindings = get_pass_layout_bindings( pass_header, l, num_bindings ); ResourceListLayoutCreation resource_layout_creation = { bindings, num_bindings }; pipeline_creation.resource_list_layout[l] = context.device.create_resource_list_layout( resource_layout_creation ); } pipeline_creation.num_active_layouts = pass_header-\u0026gt;num_resource_layouts; // Create Pipeline effect-\u0026gt;passes[p].pipeline_handle = context.device.create_pipeline( pipeline_creation ); if ( effect-\u0026gt;passes[p].pipeline_handle.handle == k_invalid_handle ) { invalid_effect = true; break; } }  When we will have a proper RenderPipeline, we will get the basic pipeline creation from there, and overwrite the shaders and states that will be defined in the HFX.\nThere are 3 main steps here:\n Create Shaders Create Resource Set Layouts Create Pipelines  These are simple operations that rely heavily on the device.\nThe objective of the HFX is to embed most information possible to create a complete pipeline.\nAnother important step is to populate the properties map:\nstring_hash_init_arena( effect-\u0026gt;name_to_property ); for ( uint32_t p = 0; p \u0026lt; effect-\u0026gt;num_properties; ++p ) { hfx::ShaderEffectFile::MaterialProperty* property = hfx::get_property( effect-\u0026gt;properties_data, p ); string_hash_put( effect-\u0026gt;name_to_property, property-\u0026gt;name, property ); }  We are using the STB String Hashmap here with the property that are inside the shader effect file. Those will contain the type, name for UI and the pointer to a default value. The default value will be used based on the type of course.\nWe are also saving the local constant buffer size, so that we can allocate some memory in the Material and alter its property using the UI.\nWe will see the importance of this next.\nMaterial struct ShaderInstance { PipelineHandle pipeline; ResourceListHandle resource_lists[hydra::graphics::k_max_resource_layouts]; uint32_t num_resource_lists; }; // struct ShaderInstance struct Material { ShaderInstance* shader_instances = nullptr; uint32_t num_instances = 0; ShaderResourcesLookup lookups; // Per-pass resource lookup. Same count as shader instances. ShaderEffect* effect = nullptr; BufferHandle local_constants_buffer; char* local_constants_data = nullptr; const char* name = nullptr; StringBuffer loaded_string_buffer; uint32_t num_textures = 0; uint32_t pool_id = 0; Texture** textures = nullptr; }; // struct Material  This is the glue to actually render something on the screen.\nAs a recap, we need 3 informations to render something:\n Pipeline (shaders + render states) Resources (handles to buffers and textures) Geometry (in this case a fullscreen quad)  Material gives all those informations.\nA Shader Instance is defined for each pass, and actually contains the Pipeline Handle and the List of Resource Lists to be used.\nThis is one of the new concepts for Vulkan/DX12: you can use one of more lists of resources to render, and normally it is better to group them by frequency.\nFinally, a list of textures is saved to be modified by the editor.\nTo understand more the process, let\u0026rsquo;s look at the loading code of a Material.\nvoid* MaterialFactory::load( LoadContext\u0026amp; context ) { using namespace hydra::graphics; // 1. Read header from file MaterialFile material_file; material_file.header = (MaterialFile::Header*)context.data; material_file.property_array = (MaterialFile::Property*)(context.data + sizeof( MaterialFile::Header )); material_file.binding_array = (MaterialFile::Binding*)(context.data + sizeof( MaterialFile::Header ) + sizeof( MaterialFile::Property ) * material_file.header-\u0026gt;num_properties);  We are using the data from the material file to access properties and bindings.\nProperties are both numerical and path to textures, bindings are name to retrieve resources from the database. We will look into that later.\n // 2. Read shader effect Resource* shader_effect_resource = string_hash_get( context.resource-\u0026gt;name_to_external_resources, material_file.header-\u0026gt;hfx_filename ); ShaderEffect* shader_effect = shader_effect_resource ? (ShaderEffect*)shader_effect_resource-\u0026gt;asset : nullptr; if ( !shader_effect ) { return nullptr; } // 3. Search pipeline RenderPipeline* render_pipeline = string_hash_get( context.name_to_render_pipeline, shader_effect-\u0026gt;pipeline_name ); if ( !render_pipeline ) { return nullptr; }  Access the Shader Effect through the resource dependencies, and the Render Pipeline from the map.\n // 4. Load material char* material_name = material_file.header-\u0026gt;name; uint32_t pool_id = materials_pool.obtain_resource(); Material* material = new (materials_pool.access_resource(pool_id))Material(); material-\u0026gt;loaded_string_buffer.init( 1024 ); material-\u0026gt;pool_id = pool_id; // TODO: for now just have one lookup shared. material-\u0026gt;lookups.init(); // TODO: properly specialize. // For each pass //for ( uint32_t i = 0; i \u0026lt; effect-\u0026gt;num_pipelines; i++ ) { // PipelineCreation\u0026amp; pipeline = effect-\u0026gt;pipelines[i]; // //final ShaderBindings specializedBindings = bindings.specialize( shaderTechnique.passName, shaderTechnique.viewName ); // //shaderBindings.add( specializedBindings ); //} material-\u0026gt;effect = shader_effect; material-\u0026gt;num_instances = shader_effect-\u0026gt;num_passes; material-\u0026gt;shader_instances = new ShaderInstance[shader_effect-\u0026gt;num_passes]; material-\u0026gt;name = material-\u0026gt;loaded_string_buffer.append_use( material_name ); material-\u0026gt;num_textures = material_file.header-\u0026gt;num_textures; material-\u0026gt;textures = (Texture**)hydra::hy_malloc( sizeof( Texture* ) * material-\u0026gt;num_textures );  Here is the meaty part.\nWe create the Material, initialize a StringBuffer used to store all the names found in the file, init the db-\u0026gt;resource lookup and create the ShaderInstance array.\n // Init memory for local constants material-\u0026gt;local_constants_data = (char*)hydra::hy_malloc( shader_effect-\u0026gt;local_constants_size ); // Copy default values to init to sane valuess memcpy( material-\u0026gt;local_constants_data, material-\u0026gt;effect-\u0026gt;local_constants_default_data, material-\u0026gt;effect-\u0026gt;local_constants_size );  We cached the constant data size to allocate its memory, and we copy the default values in it. This memory will be overwritten by the other numerical properties and used to initialize the local constant buffer.\n // Add properties uint32_t current_texture = 0; for ( size_t p = 0; p \u0026lt; material_file.header-\u0026gt;num_properties; ++p ) { MaterialFile::Property\u0026amp; property = material_file.property_array[p]; hfx::ShaderEffectFile::MaterialProperty* material_property = string_hash_get( material-\u0026gt;effect-\u0026gt;name_to_property, property.name ); switch ( material_property-\u0026gt;type ) { case hfx::Property::Texture2D: { const char* texture_path = material-\u0026gt;loaded_string_buffer.append_use( property.data ); Resource* texture_resource = string_hash_get( context.resource-\u0026gt;name_to_external_resources, texture_path ); Texture* texture = (Texture*)texture_resource-\u0026gt;asset; texture-\u0026gt;filename = texture_path; render_pipeline-\u0026gt;resource_database.register_texture( property.name, texture-\u0026gt;handle ); material-\u0026gt;textures[current_texture] = texture; ++current_texture; break; } case hfx::Property::Float: { memcpy( material-\u0026gt;local_constants_data + material_property-\u0026gt;offset, property.data, sizeof( float ) ); break; } } }  When cycling through the properties, we are copying the numerical properties into the newly allocated memory (local_constant_data) and we load the textures from the dependencies.\n // Add bindings for ( size_t b = 0; b \u0026lt; material_file.header-\u0026gt;num_bindings; ++b ) { MaterialFile::Binding\u0026amp; binding = material_file.binding_array[b]; char* name = material-\u0026gt;loaded_string_buffer.append_use( binding.name ); char* value = material-\u0026gt;loaded_string_buffer.append_use( binding.value ); material-\u0026gt;lookups.add_binding_to_resource( name, value ); }  We populate the resource lookups.\n BufferCreation checker_constants_creation = {}; checker_constants_creation.type = BufferType::Constant; checker_constants_creation.name = s_local_constants_name; checker_constants_creation.usage = ResourceUsageType::Dynamic; checker_constants_creation.size = shader_effect-\u0026gt;local_constants_size; checker_constants_creation.initial_data = material-\u0026gt;local_constants_data; material-\u0026gt;local_constants_buffer = context.device.create_buffer( checker_constants_creation ); render_pipeline-\u0026gt;resource_database.register_buffer( (char*)s_local_constants_name, material-\u0026gt;local_constants_buffer );  Generate the actual constant buffer.\n // Bind material resources update_material_resources( material, render_pipeline-\u0026gt;resource_database, context.device );  And finally search the bindings for the resources.\nstatic void update_material_resources( hydra::graphics::Material* material, hydra::graphics::ShaderResourcesDatabase\u0026amp; database, hydra::graphics::Device\u0026amp; device ) { using namespace hydra::graphics; // Create resource list // Get all resource handles from the database. ResourceListCreation::Resource resources_handles[k_max_resources_per_list]; // For each pass for ( uint32_t i = 0; i \u0026lt; material-\u0026gt;effect-\u0026gt;num_passes; i++ ) { PipelineCreation\u0026amp; pipeline = material-\u0026gt;effect-\u0026gt;passes[i].pipeline_creation; for ( uint32_t l = 0; l \u0026lt; pipeline.num_active_layouts; ++l ) { // Get resource layout description ResourceListLayoutDescription layout; device.query_resource_list_layout( pipeline.resource_list_layout[l], layout ); // For each resource for ( uint32_t r = 0; r \u0026lt; layout.num_active_bindings; r++ ) { const ResourceBinding\u0026amp; binding = layout.bindings[r]; // Find resource name // Copy string_buffer char* resource_name = material-\u0026gt;lookups.find_resource( (char*)binding.name ); switch ( binding.type ) { case hydra::graphics::ResourceType::Constants: case hydra::graphics::ResourceType::Buffer: { BufferHandle handle = resource_name ? database.find_buffer( resource_name ) : device.get_dummy_constant_buffer(); resources_handles[r].handle = handle.handle; break; } case hydra::graphics::ResourceType::Texture: case hydra::graphics::ResourceType::TextureRW: { TextureHandle handle = resource_name ? database.find_texture( resource_name ) : device.get_dummy_texture(); resources_handles[r].handle = handle.handle; break; } default: { break; } } } ResourceListCreation creation = { pipeline.resource_list_layout[l], resources_handles, layout.num_active_bindings }; material-\u0026gt;shader_instances[i].resource_lists[l] = device.create_resource_list( creation ); } material-\u0026gt;shader_instances[i].num_resource_lists = pipeline.num_active_layouts; material-\u0026gt;shader_instances[i].pipeline = material-\u0026gt;effect-\u0026gt;passes[i].pipeline_handle; } }  For each Pass, Resource Layout and Binding, we search the Database to retrieve the actual resource and create the Resource List.\nThis can be improved - having a global database of resources and a \u0026lsquo;local\u0026rsquo; one based on material resources.\n // 5. Bind material to pipeline for ( uint8_t p = 0; p \u0026lt; shader_effect-\u0026gt;num_passes; ++p ) { char* stage_name = shader_effect-\u0026gt;passes[p].name; hydra::graphics::RenderStage* stage = string_hash_get( render_pipeline-\u0026gt;name_to_stage, stage_name ); if ( stage ) { stage-\u0026gt;material = material; stage-\u0026gt;pass_index = (uint8_t)p; } } return material; }  Finally, and this is hacky, we assing the current material and pass index to the found stage.\nOnce we have the real Render Pipeline/Graph working, we will use another dispatching mechanism.\nRendering of a Material After all of this we finally have created a Material.\nBut how can we render it ?\nThe magic here happens in a Render Pipeline!\nA Render Pipeline is a list of Render Stages and some resources with it. In this case resources are the render targets and the buffers that are shared amongst Stages (and Render Systems in the future).\nResources are inside a Shader Resources Database and they can be retrieved using a Shader Resource Lookup.\nEach Render Stage has defined a list of input and output textures plus some resize data. This data is needed to recreate textures when a resize event arrives if needed, or change size if an option is changed (like a Shadow Map resolution option).\nAs everthing in this articles, this is primordial and simple, but I think is a very good start, especially from a mindset perspective.\nIn this simple scenario we render 1 material only, and normally it simply 1 Material Pass for each Render Stage Pass, rendering either using a fullscreen quad or through compute.\nThere are 2 pipelines, both simple and used as a test, one is for a ShaderToy shader that I use as test, the other as a compute only pipeline. They are both hardcoded and created at the beginning of the Material Application, but as said before, it should be data-driven and reloadable to have great rendering power.\nRendering of a Pipeline The code is simple:\nvoid RenderPipeline::render( CommandBuffer* commands ) { for ( size_t i = 0; i \u0026lt; string_hash_length( name_to_stage ); i++ ) { RenderStage* stage = name_to_stage[i].value; stage-\u0026gt;begin( commands ); stage-\u0026gt;render( commands ); stage-\u0026gt;end( commands ); } }  We cycle through each stage and render.\nvoid RenderStage::begin( CommandBuffer* commands ) { commands-\u0026gt;begin_submit( 0 ); commands-\u0026gt;begin_pass( render_pass ); commands-\u0026gt;set_viewport( { 0, 0, (float)current_width, (float)current_height, 0.0f, 1.0f } ); if ( clear_rt ) { commands-\u0026gt;clear( clear_color[0], clear_color[1], clear_color[2], clear_color[3] ); } commands-\u0026gt;end_submit(); // Set render stage states (depth, alpha, ...) }  Before rendering anything this code will bind the correct FBO/Render Targets, clear and set viewport and set render states.\nAfter this we are ready to render the actual stage. In this simple implementation we have only 3 type of stages: Compute, Post and Swapchain.\nThey are very simple and similar, like this:\ncommands-\u0026gt;begin_submit( pass_index ); commands-\u0026gt;bind_pipeline( shader_instance.pipeline ); commands-\u0026gt;bind_resource_list( \u0026amp;shader_instance.resource_lists[0], shader_instance.num_resource_lists ); commands-\u0026gt;draw( graphics::TopologyType::Triangle, 0, 3 ); commands-\u0026gt;end_submit();  Set the pipeline, bind all the different resource lists and issue the draw (in this case a full screen triangle).\nIncluded in the code Material application I just added a simple Material Application to render the content of one of those simple shaders.\nHonestly not very happy about the code quality - and you can see why trying to add big features like memory management or multi-threading is a no-go.\nThe application let you switch between materials by right clicking on the .hmt file.\nThe whole purpose is to explore with the given code a couple of materials and their dependencies.\nStarnest is a shader by the amazing Pablo Roman Andrioli, so all credits are to him! I wanted something beautiful to show in this simple example from ShaderToy.\nConclusions and some thoughts We added a simple material system based on our HFX language.\nInterestingly enough code generation is used much less - if almost nothing - instead of serializing data into files and using them.\nAs stated in the other articles, the goal is to have a parsing and code generation knowledge under your belt, and understand when it is time to use it!\nWe also introduced a lot of connections to other topics that are lengthy enough - like resource management - that need more time and dedication to properly be explored.\nI am continuing working on this until it will become my rendering explorer - a tool I can use to easily explore ideas, much like ShaderToy but in an even more powerful way.\nHow ?\nIn the next article we will explore the final piece of the puzzle, and then we will probably start iterating and improving on what we have!\nWe will see how we can describe a frame and the rendering dependencies in an easy way, especially if done since the beginning, and how much having that knowledge upfront is GREAT to work on rendering.\nI am honestly not happy about the overall architecture though - here you have an example of exploring code - code written to explore a specific subject, and after venturing more into it you want to rewrite it.\nTo properly rewrite it you need to create solid foundations - namely Memory Management, Multi-Threading, Basic Data Structures, \u0026hellip; and choose to pick your battles!\nThis is a huge lesson: pick your battles, choose what to concentrate on.\nThese articles are more towards code generation and rendering, but defining the constraints of the articles helps in narrowing down what to do.\nIf, as I would like, you want to use this code to evolve into something like a \u0026lsquo;desktop\u0026rsquo; Shadertoy, then you can\u0026rsquo;t ignore all the foundational topics.\nOn the other end if you just quickly want to experiment with those topics, this should suffice.\nI have two paths here: rewriting most of this code with a solid foundations, and delaying a RenderPipeline/Graph article, or finishing with this architecture and then re-write everything with the \u0026lsquo;desktop Shadertoy\u0026rsquo;.\nAgain, pick your battles :)\nAs always, please comment, feedback, share!\nI really hope soon there will be some rendering joy!\nGabriel\n","date":1571064229,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1576767529,"objectID":"f35b15163ee0411fa4b054c437381030","permalink":"/post/writing_shader_effect_language_3/","publishdate":"2019-10-14T10:43:49-04:00","relpermalink":"/post/writing_shader_effect_language_3/","section":"post","summary":"Overview Data Driven Rendering Series: 1. https://jorenjoestar.github.io/post/writing_shader_effect_language_1/ 2. https://jorenjoestar.github.io/post/writing_shader_effect_language_2/ 3. https://jorenjoestar.github.io/post/writing_shader_effect_language_3/ 4. https://jorenjoestar.github.io/post/data_driven_rendering_pipeline/\nIn Part 2 of this series we added Resource Layouts and Properties to the HFX language, trying to arrive at a point in which we can describe the rendering of a Shader Effect almost entirely.\nIn this article I would like to explore further adds to HFX, especially a proper Material System to be used in conjunction with the HFX language.","tags":[],"title":"Writing a Shader Effect Language Part 3: Materials","type":"post"},{"authors":[],"categories":[],"content":" Overview Data Driven Rendering Series: 1. https://jorenjoestar.github.io/post/writing_shader_effect_language_1/ 2. https://jorenjoestar.github.io/post/writing_shader_effect_language_2/ 3. https://jorenjoestar.github.io/post/writing_shader_effect_language_3/ 4. https://jorenjoestar.github.io/post/data_driven_rendering_pipeline/\nIn Part 1 of this series we created a simple language to work as \u0026lsquo;shader effect\u0026rsquo; - a shader language superset to make our life easier, by adding missing features.\nThe fact that there is not an industry standard for a shader effect language leads to either hand-crafted (and secret) languages, or to hardcoded permutations, or to other gray-area solutions.\n(Personal though: part of me would like to help in contributing to the creation of a standard through these articles and code.)\nWhat is the goal of this article ?\nThe goal is to enrich the HFX language to generate more code possible and/or bake data for us, namely:\n Shader constants generation Shader resource bindings Render states (depth stencil, blend, rasterization) Render pass hints for a future framegraph  We will see Render States and Render Pass hints in a following article, because this is an already lengthy article!\nI hope that by now the way of adding an identifier, parsing it and generating code is clearer.\nIn this article we will focus more on the features than anything else, even though I will put a lot of code still.\nBut before that, we need to have a big addition to our example: a rendering API!\nWe will use this as target of our code generation, and it will be an amazing example to see something working.\nMaybe this will spark a new FX Composer ?\nThis article will be divided in 2 parts.\nPart 1 of this article will talk about the rendering API.\nPart 2 will be about the extended HFX language.\nIf you are not interested in that, jump to part 2 of this article.\nPart 1: adding a low-level rendering API Writing articles on rendering without some sort of API to use is tricky.\nCreating a language to speed up data driven rendering, either for generating code and/or for baking data needs a target API.\nThe main idea is to have an abstract API to map more easily rendering concepts instead of losing ourselves in specific API needs.\nThe search for an abstract API The first thing to do is to search for an existing abstract API.\nI have few criteria in mind:\n Simple and clear interface Compact and clear code Vulkan and D3D12 interface  With those in mind, I found 2 alternatives: BGFX and Sokol.\nI am an honest fan of both, they are brilliant, robust and well written.\nBut for the purpose of these articles, sadly they miss my search criteria.\nThere is also a huge disclaimer here: I used them too little, so it is possible I overlooked the usage of them.\nI will be more than glad to use either instead of my toy API!\nI respect the developers and the library a lot, they are doing an amazing job!\nBut we are handcrafting something, and to properly do that I personally need to know deeply the code. And I am not.\nBGFX is very complete, but the interface is a little confusing for me, possibly because I never used it but just read the code few times.\nThe main reason I chose not to use it is because the interface is missing the resource interface like Vulkan and D3D12 (DescriptorSets, \u0026hellip;), otherwise it would have been an amazing choice.\nSokol is also very good, I love the code and the simple interface.\nTwo main problems here: again no Vulkan/D3D12 resource interface, and in this case a different target: it does not support compute shaders.\nAgain, I want to make it clear: I am not saying these are not good libraries. They are amazing. They just don\u0026rsquo;t fit my search criteria, plus I LOVE to work on rendering architecture. Well actually, it is my favourite job!\nSo kudos to them (I also wrote to Andre Weissflog to ask for compute shader support, but it is not in his plans for now) but we are making a different choice.\nIf you ever find anything that I write useful guys, please let me know!\nHydra Graphics: design principles Small trivia: the name comes from my first ever graphics engine written in 2006 (I think), after devouring 3D Game Engine Design by Dave Eberly. I already knew I would write many engines and I would learn and grow stronger from every of them, so I chose the name Hydra from the Greek mythology monster.\nThe other name would have been Phoenx engine, but I remember finding already some tech with that name.\nAnyway, design principles!\nI really loved the interface of Sokol, and often I used something similar by myself.\nI opted for a pair of header/implementation files as the only needed files.\nThe backend is OpenGL for now, just because I have a working implementation in my indie project that works with pretty complex rendering, and I can use that as reference.\nInterface Rendering in general is a matter of creating, modifying and combining resources.\nThere are mainly 2 classes that do all the rendering work:\n Device Command Buffer  The Device is responsible for creation, destruction, modification and query of the resources.\nThe Command Buffer is responsible for the usage of resources for rendering.\nThe obvious fundamental concept is resource.\nA resource is handled externally through handles, can be created using creation structs and has both a common and an API-specific representation.\nBuffers are specialized in vertex/index/constant/\u0026hellip; depending on their creation parameters.\nThis is a small example on creation/usage/destruction of a resource.\nFirst, we can create a texture:\ngraphics::TextureCreation first_rt = {}; first_rt.width = 512; first_rt.height = 512; first_rt.render_target = 1; first_rt.format = graphics::TextureFormat::R8G8B8A8_UNORM; TextureHandle render_target = gfx_device.create_texture( first_rt );  Next we can create a command buffer:\nCommandBuffer* commands = gfx_device.get_command_buffer( graphics::QueueType::Graphics, 1024 );  Skipping other creations, we bind resources and add the commands:\ncommands-\u0026gt;bind_pipeline( first_graphics_pipeline ); commands-\u0026gt;bind_resource_set( gfx_resources ); commands-\u0026gt;bind_vertex_buffer( gfx_device.get_fullscreen_vertex_buffer() ); commands-\u0026gt;draw( graphics::TopologyType::Triangle, 0, 3 );  At this point we can execute the command buffer to draw.\ngfx_device.execute_command_buffer( commands );  Updating a resource can be done like that:\nhydra::graphics::MapBufferParameters map_parameters = { buffer.handle, 0, 0 }; LocalConstants* buffer_data = (LocalConstants*)device.map_buffer( map_parameters );  Everything uses structs to perform creation/updates.\nNothing new, but I always loved this design.\nResource layout and resource lists I wanted to bring the Vulkan/D3D12 resource interface as first class citizens, and remove completely old concepts (like single constants, render states as single objects, single bind of a resource) and add new ones: resource layout, resource lists and command buffers. Well command buffers are not new, but finally you can draw only with those!\nIn Vulkan/D3D12 you can bind resources through the usage of sets: basically tables that contains the resources used.\nThis is a welcomed difference from previous APIs, and I think it is a concept not too hard to grasp but very useful to have it explicit.\nThe first thing to define is the resource layout describes the layout of a set of resources.\nFor example, if we have a material that uses Albedo and Normals textures and a constant buffer, the layout will contain all the informations about that (like the type, the GPU registers and so on).\nThis though still does not contain the resources themselves!\nEnter resource list.\nA resource list is a list of actual resources relative to a layout.\nIt sets resources using a layout.\nFrom now on, when we draw we can bind one or more resource lists.\nIn Vulkan lingo, the resource layout is called descriptor set layout, and a resource list is a descriptor set.\nHere are a couple of articles for the Vulkan side:\nOfficial Vulkan Documentation on Descriptor Layouts and Sets\nIntel API Without Secrets Part 6\nSimilarly in D3D12 there are Root Tables and Descriptor Tables. The concepts do no map 1 to 1 but they are pretty similar:\nD3D12 Descriptor Tables\nI tried to map these concepts using different words that would make more sense to me, so from Descriptor Set or Root Table it became Resource List and Resource Layout.\nPipelines Finally a pipeline is the complete description of what is needed by the GPU to draw something on the screen (or to use a Compute Shader for any other purpose).\nBasically a pipeline must fill all the informations for all the GPU stages like this (thanks to RenderDoc):\n  RenderDoc Pipeline   What once was setup individually now is all in one place (reflecting what happened behind the scene, into the driver).\nDepthStencil, AlphaBlend, Rasterization, Shaders, all must be defined here.\nIn the currrent implementation of the graphics-API a lot of states are still missing!.\nNow that we say the basic principles of the target rendering API, we can finally concentrate on the new freatures of HFX.\nPart 2: forging the HFX language features Our HFX language needs some properties to be added but first there is a change: HFX will generate a binary version to embed all the informations needed to create a shader.\nHFX evolution: what files are generated ? In the previous article, we used a single HFX file to generate multiple glsl files, ready to be used by any OpenGL renderer:\n  Shader Generation   Remembering the article on Hydra Data Format, we instead were generating an header file.\nFor our needs, we will generate an embedded HFX (binary HFX) AND a C++ header:\n  Binary and Header Generation   What is the next step for HFX ?\nFor shader generation, we want ideally to load a HFX file without having to manually stick together the single shader files, and that is why the first step is to create embedded HFX files.\nThis will contain all the information to create a shader, and this includes also the resource layouts.\nFor constant handling, we want to have UI generated and easy update on the gpu. We want to automate these things.\nThis can be done in a more code-generated way or by generating data.\nIf we abstract the problem, all these articles are about understanding how you want to generate code or data to maximise iteration time, performances and control.\nBy moving the HFX to being binary, we are effectively generating data used by the renderer.\nFor the shader UI, we can do both: generate code or create data. We will see the generated code part here.\nLet\u0026rsquo;s see briefly the internals of the Embedded HFX file format:\nEmbedded HFX As a Recap, when parsing HFX we store some informations.\nFirst is the CodeFragment, including also (spoiler!) the addition of resources for the sake of this article:\n// C++ // struct CodeFragment { struct Resource { hydra::graphics::ResourceType::Enum type; StringRef name; }; // struct Resource std::vector\u0026lt;StringRef\u0026gt; includes; std::vector\u0026lt;Stage\u0026gt; includes_stage; // Used to separate which include is in which shader stage. std::vector\u0026lt;Resource\u0026gt; resources; // Used to generate the layout table. StringRef name; StringRef code; Stage current_stage = Stage::Count; uint32_t ifdef_depth = 0; uint32_t stage_ifdef_depth[Stage::Count]; }; // struct CodeFragment  The rest is unchanged from the previous article.\nWe have basically code and includes to bake the final shader.\nRemember, we are handling GLSL in these examples!\nNext is the Pass:\n// C++ // struct Pass { StringRef name; struct ShaderStage { const CodeFragment* code = nullptr; Stage stage = Stage::Count; }; // struct ShaderStage StringRef name; std::vector\u0026lt;ShaderStage\u0026gt; shader_stages; }; // struct Pass  Nothing changed here.\nA pass is a container of one of more shaders.\nIn general we will use the term shader state to describe the shaders that needs to be bound to the pipeline.\nMost common are the couple Vertex and Fragment shaders, or the Compute by itself.\nLast is the Shader itself:\n// C++ // struct Shader { StringRef name; std::vector\u0026lt;Pass*\u0026gt; passes; std::vector\u0026lt;Property*\u0026gt; properties; }; // struct Shader  Being just a collection of passes.\nAgain we are seeing the properties here, that I will talk later on in the article.\nThese will be used to \u0026lsquo;bake\u0026rsquo; data into a \u0026lsquo;bhfx\u0026rsquo; (binary HFX) file.\nBHFX layout In order to maximise efficiency, we are packing the data in the way we will use it.\nThe file is divided in two main sections: common and passes.\nThe overall layout is as follows:\n   The trick is to have the offset for each section easy to access.\nThe pass section contains several informations as following:\n   As we will see later we include shaders, resources layout and other data based on our target API (Hydra Graphics).\nWriting the BHFX file To write our file, we need to parse the HFX file.\nA quick code could be something like this:\n// C++ // ... char* text = ReadEntireFileIntoMemory( \u0026quot;..\\\\data\\\\SimpleFullscreen.hfx\u0026quot;, nullptr ); initLexer( \u0026amp;lexer, (char*)text, data_buffer ); hfx::initParser( \u0026amp;effect_parser, \u0026amp;lexer ); hfx::generateAST( \u0026amp;effect_parser ); hfx::initCodeGenerator( \u0026amp;hfx_code_generator, \u0026amp;effect_parser, 4096, 5 ); hfx::compileShaderEffectFile( \u0026amp;hfx_code_generator, \u0026quot;..\\\\data\\\\\u0026quot;, \u0026quot;SimpleFullscreen.bhfx\u0026quot; );  Here we are parsing the file (generateAST) and then using that to compile our shader effect file. This is where the magic happens.\n// C++ // void compileShaderEffectFile( CodeGenerator* code_generator, const char* path, const char* filename ) { // Create the output file FILE* output_file; // Alias the StringBuffer for better readability. StringBuffer\u0026amp; filename_buffer = code_generator-\u0026gt;string_buffers[0]; // Concatenate name filename_buffer.clear(); filename_buffer.append( path ); filename_buffer.append( filename ); fopen_s( \u0026amp;output_file, filename_buffer.data, \u0026quot;wb\u0026quot; ); if ( !output_file ) { printf( \u0026quot;Error opening file. Aborting. \\n\u0026quot; ); return; }  Typical file creation preamble.\nConcatenate the file using the StringBuffer, and try to create it.\nRemember that overall the file structure is:\n File header Pass offset list Pass sections  Let\u0026rsquo;s start with the file header:\n const uint32_t pass_count = (uint32_t)code_generator-\u0026gt;parser-\u0026gt;passes.size(); ShaderEffectFile shader_effect_file; shader_effect_file.num_passes = pass_count; fwrite( \u0026amp;shader_effect_file, sizeof(ShaderEffectFile), 1, output_file );  In this case we are writing straight to the file, because it is an in-order operation with the file layout.\nFor the rest of the file writing we will need to use String Buffers to accumulate data out-of-order and then write the file in the correct order.\nThink of the Pass Offset List: to calculate the offsets we need to know the size of the passes. To know the size we need to finalize the pass data. To finalize the pass data we need to finalize shaders, and that means adding the includes.\nAgain for code clarity I use aliases like this:\n StringBuffer\u0026amp; code_buffer = code_generator-\u0026gt;string_buffers[1]; StringBuffer\u0026amp; pass_offset_buffer = code_generator-\u0026gt;string_buffers[2]; StringBuffer\u0026amp; shader_offset_buffer = code_generator-\u0026gt;string_buffers[3]; StringBuffer\u0026amp; pass_buffer = code_generator-\u0026gt;string_buffers[4];  Let\u0026rsquo;s continue.\nWe start tracking the pass section memory offset knowing that it will be after the header and the pass offset list:\n pass_offset_buffer.clear(); pass_buffer.clear(); // Pass memory offset starts after header and list of passes offsets. uint32_t pass_offset = sizeof( ShaderEffectFile ) + sizeof(uint32_t) * pass_count;  Now into the most interesting part. We will avoid talking about the resource layout part, that will be added later.\n // Pass Section: // ---------------------------------------------------------------------------------------- // Shaders count | Name | Shader Offset+Count List | Shader Code 0, Shader Code 1 // ---------------------------------------------------------------------------------------- ShaderEffectFile::PassHeader pass_header; for ( uint32_t i = 0; i \u0026lt; pass_count; i++ ) { pass_offset_buffer.append( \u0026amp;pass_offset, sizeof( uint32_t ) ); const Pass\u0026amp; pass = code_generator-\u0026gt;parser-\u0026gt;passes[i]; const uint32_t pass_shader_stages = (uint32_t)pass.shader_stages.size(); const uint32_t pass_header_size = pass_shader_stages * sizeof( ShaderEffectFile::Chunk ) + sizeof( ShaderEffectFile::PassHeader ); uint32_t current_shader_offset = pass_header_size;  We start iterating the passes and calculate the shader offset.\nShader Chunks (the actual shader code) are written after the Pass Header and the dynamic list of shader chunk offset and size.\nNext we will calculate the offsets of the single shaders AFTER we finalize the code - that means after the includes are added!\n shader_offset_buffer.clear(); code_buffer.clear(); for ( size_t s = 0; s \u0026lt; pass.shader_stages.size(); ++s ) { const Pass::ShaderStage shader_stage = pass.shader_stages[s]; appendFinalizedCode( path, shader_stage.stage, shader_stage.code, filename_buffer, code_buffer, true, constants_buffer ); updateOffsetTable( \u0026amp;current_shader_offset, pass_header_size, shader_offset_buffer, code_buffer ); } // Update pass offset pass_offset += code_buffer.current_size + shader_offset;  At this point we have code_buffer containing all the shaders of the pass one after another (null terminated) and we can update the pass offset for the next pass.\nWe also calculated the single shader offsets with the updateOffsetTable method in shader_offset_buffer.\nWe need to finalize the Pass Header and then we can merge the pass memory in one block and proceed to the next pass:\n // Fill Pass Header copy( pass.name, pass_header.name, 32 ); pass_header.num_shader_chunks = pass.num_shaders;  This is a very IMPORTANT part.\nMerge in the pass_buffer all the pass section currently calculated: pass header, the single shader code offsets and the shader code itself.\n pass_buffer.append( (void*)\u0026amp;pass_header, sizeof( ShaderEffectFile::PassHeader ) ); pass_buffer.append( shader_offset_buffer ); pass_buffer.append( code_buffer ); }  After we finished with all the passes, we have 2 buffers: one containing the pass offset list, the other the pass sections.\nWe can write them off in the correct order finally and close the file:\n fwrite( pass_offset_buffer.data, pass_offset_buffer.current_size, 1, output_file ); fwrite( pass_buffer.data, pass_buffer.current_size, 1, output_file ); fclose( output_file ); }  We can see why we chose this format when looking at the code to actually create a shader state.\nFirst of all this is the struct to create a shader state:\n// hydra_graphics.h // struct ShaderCreation { struct Stage { ShaderStage::Enum type = ShaderStage::Compute; const char* code = nullptr; }; // struct Stage const Stage* stages = nullptr; const char* name = nullptr; uint32_t stages_count = 0; }; // struct ShaderCreation  It is very simple, each stage has a code and type.\nA shader state can have one or more stages.\nThis was already the case in OpenGL - compiling shaders and linking them - so the interface is similar - but it maps well to Vulkan/D3D12 as well, in which the Pipeline State, that describe almost everything the GPU needs to draw, needs an unique set of vertex/fragment/compute shaders.\nAnyway, we embed this data already in the binary HFX file, and thus we can easily create a shader state like this:\nstatic void compile_shader_effect_pass( hydra::graphics::Device\u0026amp; device, char* hfx_memory, uint16_t pass_index, hydra::graphics::ShaderHandle\u0026amp; out_shader ) { using namespace hydra; // Get pass section memory char* pass = hfx::getPassMemory( hfx_memory, pass_index ); hfx::ShaderEffectFile::PassHeader* pass_header = (hfx::ShaderEffectFile::PassHeader*)pass; const uint32_t shader_count = pass_header-\u0026gt;num_shader_chunks; graphics::ShaderCreation::Stage* stages = new graphics::ShaderCreation::Stage[shader_count]; // Get individual shader code and type for ( uint16_t i = 0; i \u0026lt; shader_count; i++ ) { hfx::getShaderCreation( shader_count, pass, i, \u0026amp;stages[i] ); } graphics::ShaderCreation first_shader = {}; first_shader.stages = stages; first_shader.stages_count = shader_count; first_shader.name = pass_header-\u0026gt;name; out_shader = device.create_shader( first_shader ); delete stages; }  Nothing really interesting here, but we read the file in memory and use the offsets we store to access the different sections of the file.\nTo access the Pass Section we first need to read its memory offset and then read from there.\nRemember from before that the offset is in the list AFTER the ShaderEffectFile header, and it is a single uint32:\nchar* getPassMemory( char* hfx_memory, uint32_t index ) { // Read offset form list after the ShaderEffectFile header. const uint32_t pass_offset = *(uint32_t*)(hfx_memory + sizeof( ShaderEffectFile ) + (index * sizeof( uint32_t ))); return hfx_memory + pass_offset; }  From the pass offset, the list of shader chunks (that are defined as code offset and size) is right after the pass header\nvoid getShaderCreation( uint32_t shader_count, char* pass_memory, uint32_t index, hydra::graphics::ShaderCreation::Stage* shader_creation ) { char* shader_offset_list_start = pass_memory + sizeof( ShaderEffectFile::PassHeader );  Read the single shader offset and access the memory there:\n const uint32_t shader_offset = *(uint32_t*)(shader_offset_list_start + (index * sizeof( ShaderEffectFile::Chunk ))); char* shader_chunk_start = pass_memory + shader_offset;  The baked informations are first the type (as a single char, but called hfx::ShaderEffectFile::ChunkHeader in case we change it) and the actual shader code is right after!\n shader_creation-\u0026gt;type = (hydra::graphics::ShaderStage::Enum)(*shader_chunk_start); shader_creation-\u0026gt;code = (const char*)(shader_chunk_start + sizeof( hfx::ShaderEffectFile::ChunkHeader )); }  In this case I chose to bake the file instead of generating a header file - just cause I can reuse this code for every shader effect. I could have generated an header instead of the binary BHFX file, but then including it would mean that you need to recompile at every change.\nWe will see some areas in which we can have both approaches!\nFinally done with the new embedded format, let\u0026rsquo;s see the new features!\nBrainstorming: what features are needed ? We already talked about the features at the beginning of the articles, but let\u0026rsquo;s write them again to refresh our memory:\n Shader constants generation Shader resource bindings Render states (depth stencil, blend, rasterization) (in the next article) Render pass hints for a future framegraph (in the next article)  There are few articles around this subject, but the most complete is from the amazing guys at OurMachinery, and in particular this article.\nThese guys does (as always honestly) an amazing job in describing the problem we are facing and the solutions, and how enriching a shader language can make a huge difference in making better rendering (faster iteration time, less error prone, more artist friendly..) so I would suggest to read those articles (and in general any article/presentation/blog post they write!).\nWe will go through each feature in depth so get ready!\nConstants: artists, programmers, both ? Constants\u0026hellip;uniforms\u0026hellip;whatever name you choose, they represent the same concept: numerical properties.\nEven if they are a simple concept, still it is hard to make both rendering citizens happy: artists and programmers!\nArtists want tweakable UI, simple variables and fast iteration.\nProgrammers want optimal layout, more CPU calculated variables possible, and ultimate control.\nHow to make them both happy ?\nI brainstormed and designed for few days (well evenings) to solve this problem.\nOne thought that came to me is that artists want to create a material interface, something they can tweak and change easily, and when you want to quickly prototype something, create and such, you don\u0026rsquo;t want to deal with low-level resource management and such.\nLet\u0026rsquo;s solve this first: give artists a simple way of creating a material interface!\nAfter searching for a bit, I chose to use a syntax very similar to Unity ShaderLab. Let\u0026rsquo;s see the HFX (finally!):\n// .HFX // // For the artist: create a material interface. properties { // Using Unity ShaderLab syntax: // AORemapMin0(\u0026quot;AORemapMin0\u0026quot;, Range(0.0, 1.0)) = 0.0 scale(\u0026quot;Scale\u0026quot;, Float) = 32.00 modulo(\u0026quot;Modulo\u0026quot;, Float) = 2.0 }  We added a new section in the language, named \u0026ldquo;properties\u0026rdquo;.\nWhy this name ?\nBecause properties contains both numerical properties and textures!\nThe name makes sense in this way. Naming \u0026lsquo;constants\u0026rsquo; and having also textures, not.\nThere are 2 possible outputs from this, one that is pure code-generation and the other that is more data-driven. I will dwelve into the code-generation one and talk about the data-driven one in another post.\nThere are 3 parts for the generated code of the properties:\n Properties UI GPU-ready constant buffer API-dependant buffer  For the Properties UI, we want to generate something like this:\n// C++ struct LocalConstantsUI { float scale = 32.000000f; float modulo = 2.000000f; void reflectMembers() { ImGui::InputScalar( \u0026quot;Scale\u0026quot;, ImGuiDataType_Float, \u0026amp;scale); ImGui::InputScalar( \u0026quot;Modulo\u0026quot;, ImGuiDataType_Float, \u0026amp;modulo); } void reflectUI() { ImGui::Begin( \u0026quot;LocalConstants\u0026quot; ); reflectMembers(); ImGui::End(); } }; // struct LocalConstantsUI  For the GPU-ready constants, we want to have a both a GPU and a CPU representation like this:\n// C++ // struct LocalConstants { float scale = 32.000000f; float modulo = 2.000000f; float pad_tail[2]; }; // struct LocalConstants // GLSL // layout (std140, binding=7) uniform LocalConstants { float scale; float modulo; float pad[2]; } local_constants;  And for the API-dependant buffer, we want to create code that takes care of everything for us. This is the real deal here - and something we will revisit in next articles to show some advanced features.\nvoid create( hydra::graphics::Device\u0026amp; device ) { using namespace hydra; graphics::BufferCreation constants_creation = {}; constants_creation.type = graphics::BufferType::Constant; constants_creation.name = \u0026quot;LocalConstants\u0026quot;; constants_creation.usage = graphics::ResourceUsageType::Dynamic; // NOTE: using LocalConstants struct - is the GPU ready one with padding and such! constants_creation.size = sizeof( LocalConstants ); // Struct is initialized with default values already, so it is safe to copy it to the GPU. constants_creation.initial_data = \u0026amp;constants; buffer = device.create_buffer( constants_creation ); } void destroy( hydra::graphics::Device\u0026amp; device ) { device.destroy_buffer( buffer ); } void updateUI( hydra::graphics::Device\u0026amp; device ) { // Draw UI constantsUI.reflectUI(); // TODO: // Ideally there should be a way to tell if a variable has changed and update only in that case. // Map buffer to GPU and upload parameters from the UI hydra::graphics::MapBufferParameters map_parameters = { buffer.handle, 0, 0 }; LocalConstants* buffer_data = (LocalConstants*)device.map_buffer( map_parameters ); if ( buffer_data ) { buffer_data-\u0026gt;scale = constantsUI.scale; buffer_data-\u0026gt;modulo = constantsUI.modulo; device.unmap_buffer( map_parameters ); } }  For the sake of the example this could be a possible implementation - but really depends on the rendering API. Let\u0026rsquo;s quickly check parsing and code-generation.\nConstants Parsing To parse the new property section, there is the new method void declarationProperties( Parser* parser ) that iterates through all properties, and inside that the void declarationProperty( Parser* parser, const StringRef\u0026amp; name ) one.\nWe are parsing the following HFX syntax:\n// Syntax // identifier(string, identifier[(arguments)]) [= default_value]  With this is an example:\n// HFX // properties { scale(\u0026quot;Scale\u0026quot;, Float) = 32.0 }  We will add a simple backtracking to the parsing because of the optional parameters.\nLet\u0026rsquo;s check the code!\ninline void declarationProperty( Parser* parser, const StringRef\u0026amp; name ) { Property* property = new Property(); // Cache name property-\u0026gt;name = name; Token token; if ( !expectToken( parser-\u0026gt;lexer, token, Token::Token_OpenParen ) ) { return; }  We just parsed the property name and the \u0026lsquo;(\u0026rsquo;. Next is the string containing the UI name:\n // Advance to the string representing the ui_name if ( !expectToken( parser-\u0026gt;lexer, token, Token::Token_String ) ) { return; } property-\u0026gt;ui_name = token.text;  Saved the ui name and then we have the type.\nTypes can be Float, Int, Range, Texture, Vector, Color and we will simply parse their text and convert it to an enum that we will use in the code generation phase.\n if ( !expectToken( parser-\u0026gt;lexer, token, Token::Token_Comma ) ) { return; } // Next is the identifier representing the type name if ( !expectToken( parser-\u0026gt;lexer, token, Token::Token_Identifier ) ) { return; } // Parse property type and convert it to an enum property-\u0026gt;type = propertyTypeIdentifier( token );  Now will come the most complicated part.\nWe have optional \u0026lsquo;(\u0026rsquo; open parenthesis for the parameters if the type needs it.\nFor the length of code and article, I skip this part and will add it in next article!\n // If an open parenthesis is present, then parse the ui arguments. nextToken( parser-\u0026gt;lexer, token ); if ( token.type == Token::Token_OpenParen ) { property-\u0026gt;ui_arguments = token.text; while ( !equalToken( parser-\u0026gt;lexer, token, Token::Token_CloseParen ) ) { // TODO: // Parse parameters! } // Advance to the last close parenthesis nextToken( parser-\u0026gt;lexer, token ); property-\u0026gt;ui_arguments.length = token.text.text - property-\u0026gt;ui_arguments.text; } if ( !checkToken( parser-\u0026gt;lexer, token, Token::Token_CloseParen ) ) { return; }  At this point we can either be at the end of the property or we could have a \u0026lsquo;=\u0026rsquo; token to add a default value. Being that the Lexer class is small, we can backtrack by saving the current Lexer status:\n // Cache lexer status and advance to next token. // If the token is '=' then we parse the default value. // Otherwise backtrack by one token. Lexer cached_lexer = *parser-\u0026gt;lexer;  Now we can advance to the next token and:\n If the token is \u0026lsquo;=\u0026rsquo;, parse the default value. If not, backtrack the position of the Lexer and finish the parsing.\nnextToken( parser-\u0026gt;lexer, token ); // At this point only the optional default value is missing, otherwise the parsing is over. if ( token.type == Token::Token_Equals ) { nextToken( parser-\u0026gt;lexer, token ); if ( token.type = Token::Token_Number ) { // Cache the data buffer entry index into the property for later retrieval. property-\u0026gt;data_index = parser-\u0026gt;lexer-\u0026gt;data_buffer-\u0026gt;current_entries - 1; } else { // TODO: // Handle vectors, colors and non single number default values } } else { *parser-\u0026gt;lexer = cached_lexer; } parser-\u0026gt;shader.properties.push_back( property ); }   An interesting point is that the numbers are parsed in a DataBuffer, and during the parsing of the token we will add the number to it.\nTo retrieve it, we have the data_index field of the Property struct.\nAlso here, for the sake of \u0026lsquo;brevity\u0026rsquo;, I am handling only floats and ints. Vectors, colors and texture property should be easy to add.\nFor vectors and colors we should parse a list of them and save them into the data buffer.\nFor textures we should just save the default value as text and use it in the code-generation part.\nCode Generation This should be pretty straight forward.\nWe can iterate the properties and generate both a C++ struct and a HLSL/GLSL buffer.\nThe only thing to be concerned is the padding: on the GPU normally the alignment is 16 bytes, so we can track that and insert padding when generating the code.\nIn the method void generateShaderResourceHeader( CodeGenerator* code_generator, const char* path ) we can see how we generate the different code for C++:\n// C++ // // Beginning fprintf( output_file, \u0026quot;\\n#pragma once\\n#include \u0026lt;stdint.h\u0026gt;\\n#include \\\u0026quot;hydra_graphics.h\\\u0026quot;\\n\\n// This file is autogenerated!\\nnamespace \u0026quot; ); fwrite( shader.name.text, shader.name.length, 1, output_file ); fprintf( output_file, \u0026quot; {\\n\\n\u0026quot; ); // Preliminary sections constants_ui.append( \u0026quot;struct LocalConstantsUI {\\n\\n\u0026quot; ); cpu_constants.append( \u0026quot;struct LocalConstants {\\n\\n\u0026quot; ); constants_ui_method.append(\u0026quot;\\tvoid reflectMembers() {\\n\u0026quot;); buffer_class.append( \u0026quot;struct LocalConstantsBuffer {\\n\\n\\thydra::graphics::BufferHandle\\tbuffer;\\n\u0026quot; ); buffer_class.append( \u0026quot;\\tLocalConstants\\t\\t\\t\\t\\tconstants;\\n\\tLocalConstantsUI\\t\\t\\t\\tconstantsUI;\\n\\n\u0026quot; ); buffer_class.append( \u0026quot;\\tvoid create( hydra::graphics::Device\u0026amp; device ) {\\n\\t\\tusing namespace hydra;\\n\\n\u0026quot; ); buffer_class.append( \u0026quot;\\t\\tgraphics::BufferCreation constants_creation = { graphics::BufferType::Constant, graphics::ResourceUsageType::Dynamic, sizeof( LocalConstants ), \u0026amp;constants, \\\u0026quot;LocalConstants\\\u0026quot; };\\n\u0026quot; ); buffer_class.append( \u0026quot;\\t\\tbuffer = device.create_buffer( constants_creation );\\n\\t}\\n\\n\u0026quot; ); buffer_class.append( \u0026quot;\\tvoid destroy( hydra::graphics::Device\u0026amp; device ) {\\n\\t\\tdevice.destroy_buffer( buffer );\\n\\t}\\n\\n\u0026quot; ); buffer_class.append( \u0026quot;\\tvoid updateUI( hydra::graphics::Device\u0026amp; device ) {\\n\\t\\t// Draw UI\\n\\t\\tconstantsUI.reflectUI();\\n\\t\\t// Update constants from UI\\n\u0026quot; ); buffer_class.append( \u0026quot;\\t\\thydra::graphics::MapBufferParameters map_parameters = { buffer.handle, 0, 0 };\\n\u0026quot; ); buffer_class.append( \u0026quot;\\t\\tLocalConstants* buffer_data = (LocalConstants*)device.map_buffer( map_parameters );\\n\\t\\tif (buffer_data) {\\n\u0026quot; ); // For GPU the struct must be 16 bytes aligned. Track alignment uint32_t gpu_struct_alignment = 0; DataBuffer* data_buffer = code_generator-\u0026gt;parser-\u0026gt;lexer-\u0026gt;data_buffer; // For each property write code for ( size_t i = 0; i \u0026lt; shader.properties.size(); i++ ) { hfx::Property* property = shader.properties[i]; switch ( property-\u0026gt;type ) { case Property::Float: { constants_ui.append(\u0026quot;\\tfloat\\t\\t\\t\\t\\t\u0026quot;); constants_ui.append( property-\u0026gt;name ); cpu_constants.append( \u0026quot;\\tfloat\\t\\t\\t\\t\\t\u0026quot; ); cpu_constants.append( property-\u0026gt;name ); if ( property-\u0026gt;data_index != 0xffffffff ) { float value = 0.0f; getData( data_buffer, property-\u0026gt;data_index, value ); constants_ui.append( \u0026quot;\\t\\t\\t\\t= %ff\u0026quot;, value ); cpu_constants.append( \u0026quot;\\t\\t\\t\\t= %ff\u0026quot;, value ); } constants_ui.append( \u0026quot;;\\n\u0026quot; ); cpu_constants.append( \u0026quot;;\\n\u0026quot; ); constants_ui_method.append(\u0026quot;\\t\\tImGui::InputScalar( \\\u0026quot;\u0026quot;); constants_ui_method.append( property-\u0026gt;ui_name ); constants_ui_method.append( \u0026quot;\\\u0026quot;, ImGuiDataType_Float, \u0026amp;\u0026quot; ); constants_ui_method.append( property-\u0026gt;name ); constants_ui_method.append( \u0026quot;);\\n\u0026quot; ); // buffer_data-\u0026gt;scale = constantsUI.scale; buffer_class.append(\u0026quot;\\t\\t\\tbuffer_data-\u0026gt;\u0026quot;); buffer_class.append( property-\u0026gt;name ); buffer_class.append( \u0026quot; = constantsUI.\u0026quot; ); buffer_class.append( property-\u0026gt;name ); buffer_class.append( \u0026quot;;\\n\u0026quot; ); ++gpu_struct_alignment; break; } } } // Post-property sections constants_ui.append( \u0026quot;\\n\u0026quot; ); constants_ui_method.append( \u0026quot;\\t}\\n\\n\u0026quot; ); constants_ui_method.append( \u0026quot;\\tvoid reflectUI() {\\n\\t\\tImGui::Begin( \\\u0026quot;LocalConstants\\\u0026quot; );\\n\u0026quot; ); constants_ui_method.append( \u0026quot;\\t\\treflectMembers();\\n\\t\\tImGui::End();\\n\\t}\\n\\n\u0026quot; ); constants_ui_method.append( \u0026quot;}; // struct LocalConstantsUI\\n\\n\u0026quot; ); // Add tail padding data uint32_t tail_padding_size = 4 - (gpu_struct_alignment % 4); cpu_constants.append( \u0026quot;\\tfloat\\t\\t\\t\\t\\tpad_tail[%u];\\n\\n\u0026quot;, tail_padding_size ); cpu_constants.append( \u0026quot;}; // struct LocalConstants\\n\\n\u0026quot; ); buffer_class.append( \u0026quot;\\t\\t\\tdevice.unmap_buffer( map_parameters );\\n\\t\\t}\\n\\t}\\n}; // struct LocalConstantBuffer\\n\\n\u0026quot; ); fwrite( constants_ui.data, constants_ui.current_size, 1, output_file ); fwrite( constants_ui_method.data, constants_ui_method.current_size, 1, output_file ); fwrite( cpu_constants.data, cpu_constants.current_size, 1, output_file ); fwrite( buffer_class.data, buffer_class.current_size, 1, output_file ); // End fprintf( output_file, \u0026quot;} // namespace \u0026quot; ); fwrite( shader.name.text, shader.name.length, 1, output_file ); fprintf( output_file, \u0026quot;\\n\\n\u0026quot; ); fclose( output_file );  This piece of code will generate a constant buffer from the properties:\n// GLSL // static void generateConstantsCode( const Shader\u0026amp; shader, StringBuffer\u0026amp; out_buffer ) { if ( !shader.properties.size() ) { return; } // Add the local constants into the code. out_buffer.append( \u0026quot;\\n\\t\\tlayout (std140, binding=7) uniform LocalConstants {\\n\\n\u0026quot; ); // For GPU the struct must be 16 bytes aligned. Track alignment uint32_t gpu_struct_alignment = 0; const std::vector\u0026lt;Property*\u0026gt;\u0026amp; properties = shader.properties; for ( size_t i = 0; i \u0026lt; shader.properties.size(); i++ ) { hfx::Property* property = shader.properties[i]; switch ( property-\u0026gt;type ) { case Property::Float: { out_buffer.append( \u0026quot;\\t\\t\\tfloat\\t\\t\\t\\t\\t\u0026quot; ); out_buffer.append( property-\u0026gt;name ); out_buffer.append( \u0026quot;;\\n\u0026quot; ); ++gpu_struct_alignment; break; } } } uint32_t tail_padding_size = 4 - (gpu_struct_alignment % 4); out_buffer.append( \u0026quot;\\t\\t\\tfloat\\t\\t\\t\\t\\tpad_tail[%u];\\n\\n\u0026quot;, tail_padding_size ); out_buffer.append( \u0026quot;\\t\\t} local_constants;\\n\\n\u0026quot; ); }  Expert constants: an interesting problem A problem many times surfaces is that the material interface does not correspond to the buffer sent to the GPU, because the programmers will do the following:\n Add system constants, that don\u0026rsquo;t need a UI Change order of the constants Change constants to more GPU friendly values, calculating some stuff on the CPU Pack constants into smaller ones  This is an interesting topic and I\u0026rsquo;ll cover it in another article, but a simple solution would be to add a mapping between the GPU constants and the UI, so that we can separate the UI constants from the GPU ones.\nI\u0026rsquo;ll give a brief example but it would be too much for this article and will not be included in the source code.\nBasically we are trying to create a mapping between the material interface:\n// C++ struct LocalConstantsUI { float scale = 32.000000f; float modulo = 2.000000f; void reflectMembers() { ImGui::InputScalar( \u0026quot;Scale\u0026quot;, ImGuiDataType_Float, \u0026amp;scale); ImGui::InputScalar( \u0026quot;Modulo\u0026quot;, ImGuiDataType_Float, \u0026amp;modulo); } void reflectUI() { ImGui::Begin( \u0026quot;LocalConstants\u0026quot; ); reflectMembers(); ImGui::End(); } }; // struct LocalConstantsUI  And the GPU constants:\n// C++ struct LocalConstants { float scale = 32.000000f; float modulo = 2.000000f; float pad_tail[2]; }; // struct LocalConstants  We could enhance HFX with some syntax to mark the derivate properties and just add the system ones in an explicit buffer layout, and add a layout section in the HFX:\n// HFX properties { // Using Unity ShaderLab syntax: scale(\u0026quot;Scale\u0026quot;, Range(0.0, 100.0)) = 100.0 modulo(\u0026quot;Modulo\u0026quot;, Float) = 2.0 } layout { CBuffer LocalConstants { float4x4 world_view_projection; // 'System' variable float scale01 = (scale); // Silly normalized version of scale interface property float modulo; float pad[2]; } }  we could completely override the automatic constant buffer generation from the properties.\nWith this we can:\n Add a system variable like world_view_projection Flag the property scale as UI only, by saying that property scale01 uses it.  I think that with this syntax both artists and programmers can be happy together!\nI will try to work on this on a later article.\nResource bindings: Vulkan and D3D12 mentality As stated multiple times, the shift in mentality is towards the new APIs, and that includes the concept of resource lists.\nThe problem is that we don\u0026rsquo;t want artists to have to handle this kind of things - especially if you want to quickly prototype things!\nBut at the same time, we want programmers to have the possibility to optimize the shaders the artists gave them.\nWhat is the solution?\nSimple: creating an optional resource layout section and automatically generate it if not present, so that artists (and not only) can happily create amazing tech and THEN worry about these details!\nAutomatic Resource Layout The easiest way to handle resource layout is to make them SIMPLE. Remember the K.I.S.S. principle.\nIn this case it means that we can create a Resource List for each pass, that will contain:\n One constant/uniform buffer containing all the properties All the textures used by the shader  How can we achieve that ?\nWe already saw how we can generate the constant buffer from the properties in the previous section. For textures we have a couple of options.\nList of Textures Being in automation land, there are 2 ways to add texture dependencies:\n Use reflection mechanism from the target shader language Parse identifiers in the current finalized shader  For the sake of fun we will look into the second of course!\nIf we go back to void declarationGlsl( Parser* parser ), we can add a new method to parse the keyword:\n// Parse hash for includes and defines if ( token.type == Token::Token_Hash ) { // Get next token and check which directive is nextToken( parser-\u0026gt;lexer, token ); directiveIdentifier( parser, token, code_fragment ); } else if ( token.type == Token::Token_Identifier ) { \u0026lt;------------ New Code! // Parse uniforms to add resource dependencies if not explicit in the HFX file. if ( expectKeyword( token.text, 7, \u0026quot;uniform\u0026quot; ) ) { nextToken( parser-\u0026gt;lexer, token ); uniformIdentifier( parser, token, code_fragment ); } }  In this way it will search for the identifier uniform and search for the other identifiers. This is GLSL centric of course.\ninline void uniformIdentifier( Parser* parser, const Token\u0026amp; token, CodeFragment\u0026amp; code_fragment ) { for ( uint32_t i = 0; i \u0026lt; token.text.length; ++i ) { char c = *(token.text.text + i); switch ( c ) { case 'i': { if ( expectKeyword( token.text, 7, \u0026quot;image2D\u0026quot; ) ) { // Advance to next token to get the name Token name_token; nextToken( parser-\u0026gt;lexer, name_token ); CodeFragment::Resource resource = { hydra::graphics::ResourceType::TextureRW, name_token.text }; code_fragment.resources.emplace_back( resource ); } break; } case 's': { if ( expectKeyword( token.text, 9, \u0026quot;sampler2D\u0026quot; ) ) { // Advance to next token to get the name Token name_token; nextToken( parser-\u0026gt;lexer, name_token ); CodeFragment::Resource resource = { hydra::graphics::ResourceType::Texture, name_token.text }; code_fragment.resources.emplace_back( resource ); } break; } } } }  Should be pretty straight-forward: if you find the identifier for texture, add a resource dependency with type and name to the current code fragment!\nIs this the ideal solution ?\nProbably not.\nBut I wanted to show what we can achieve once we have fun with parsing, including the understanding on when to say NO to it!\nManual Resource Layout Now that the effect can work without too much programmer time, it is time to give back to programmers the control they want.\nIn the previous paragraph about Expert Constants we talked about adding a new section, called layout.\nIn this section we can specify the resource list for each pass manually, and later on in the pass we can reference this lists as used by the pass.\nGoing on a more complete solution, layouts should be included and merged when including other HFX files.\nThis is something we want and we\u0026rsquo;ll look in another post, we can start simple by defining something local:\n// HFX // // For the developer layout { list LocalCompute { cbuffer LocalConstants; texture2Drw(rgba8) destination_texture; } list Local { texture2D input_texture; } }  This is a rather simple layout, but let\u0026rsquo;s see it.\nFirst of all, for each \u0026lsquo;list\u0026rsquo; keyword we define a single list with a unique name.\nWith that, we can reference in the pass which list to use.\nThe code that does the parsing is (at this point) pretty straight-forward, both in void declarationResourceList( Parser* parser, ResourceList\u0026amp; resource_list ) and void resourceBindingIdentifier( Parser* parser, const Token\u0026amp; token, ResourceBinding\u0026amp; binding ).\nI will not go over it, but basically it will parse the resource lists and add them to the shader.\nThe parsing itself will read the text and create the ResourceSetLayoutCreation::Binding and add it to the list of the resources.\nWe then add a new identifier in the pass to choose which resource list to be used:\n// HFX // pass FillTexture { resources = LocalCompute, ... dispatch = 32, 32, 1 render_pass = compute compute = ComputeTest } pass ToScreen { resources = Local render_pass = fullscreen vertex = ToScreen fragment = ToScreen }  The parsing will happen in void declarationPassResources( Parser* parser, Pass\u0026amp; pass ).\nAdding Resource Layout data to binary HFX So after this amazing journey we are ready to embed those informations into the BHFX and use it right away into the rendering API.\nThe big difference is if the hfx file contains a layout section.\nIf it is not present, then all the informations will be gathered automatically and will be added with the writeAutomaticResourcesLayout method.\nFirst we will add the LocalConstant buffer created from the properties:\nstatic void writeAutomaticResourcesLayout( const hfx::Pass\u0026amp; pass, StringBuffer\u0026amp; pass_buffer, uint32_t\u0026amp; pass_offset ) { using namespace hydra::graphics; // Add the local constant buffer obtained from all the properties in the layout. hydra::graphics::ResourceSetLayoutCreation::Binding binding = { hydra::graphics::ResourceType::Constants, 0, 1, \u0026quot;LocalConstants\u0026quot; }; pass_buffer.append( (void*)\u0026amp;binding, sizeof( hydra::graphics::ResourceSetLayoutCreation::Binding) ); pass_offset += sizeof( hydra::graphics::ResourceSetLayoutCreation::Binding );  Then we will cycle through all the shader stages and write the resources into the memory:\n for ( size_t s = 0; s \u0026lt; pass.shader_stages.size(); ++s ) { const Pass::ShaderStage shader_stage = pass.shader_stages[s]; for ( size_t p = 0; p \u0026lt; shader_stage.code-\u0026gt;resources.size(); p++ ) { const hfx::CodeFragment::Resource\u0026amp; resource = shader_stage.code-\u0026gt;resources[p]; switch ( resource.type ) { case ResourceType::Texture: { copy( resource.name, binding.name, 32 ); binding.type = hydra::graphics::ResourceType::Texture; pass_buffer.append( (void*)\u0026amp;binding, sizeof( hydra::graphics::ResourceSetLayoutCreation::Binding ) ); pass_offset += sizeof( hydra::graphics::ResourceSetLayoutCreation::Binding ); break; } case ResourceType::TextureRW: { copy( resource.name, binding.name, 32 ); binding.type = hydra::graphics::ResourceType::TextureRW; pass_buffer.append( (void*)\u0026amp;binding, sizeof( hydra::graphics::ResourceSetLayoutCreation::Binding ) ); pass_offset += sizeof( hydra::graphics::ResourceSetLayoutCreation::Binding ); break; } } } } }  If instead there is a layout section, the method writeResourcesLayout is called and will be pretty straight-forward:\nstatic void writeResourcesLayout( const hfx::Pass\u0026amp; pass, StringBuffer\u0026amp; pass_buffer, uint32_t\u0026amp; pass_offset ) { using namespace hydra::graphics; for ( size_t r = 0; r \u0026lt; pass.resource_lists.size(); ++r ) { const ResourceList* resource_list = pass.resource_lists[r]; const uint32_t resources_count = (uint32_t)resource_list-\u0026gt;resources.size(); pass_buffer.append( (void*)resource_list-\u0026gt;resources.data(), sizeof(ResourceBinding) * resources_count ); pass_offset += sizeof( ResourceBinding ) * resources_count; } }  And this will be put at the end of the current pass section:\npass_buffer.append( (void*)\u0026amp;pass_header, sizeof( ShaderEffectFile::PassHeader ) ); pass_buffer.append( shader_offset_buffer ); pass_buffer.append( code_buffer ); if ( automatic_layout ) { writeAutomaticResourcesLayout( pass, pass_buffer, pass_offset ); } else { writeResourcesLayout( pass, pass_buffer, pass_offset ); }  Conclusions and what\u0026rsquo;s next We arrived at the end of this article, and we started seeing how we can use HFX as a more complete language to embed different rendering features.\nWe saw how to embed shader code and resource lists so that the rendering API can create everything without hard-coded generation of resources. This also showed when it was useful to create data instead of code.\nOn the contrary, the UI and the Constants are generated in a new header file - thus code generation.\nThere are pros and cons to both approaches, but I hope that knowing how to generate code and create a custom language will let you play with the concepts and explore your own needs.\nAs next steps, there are some questions opened: how to reload shaders ? Can I add new material properties without recompiling code ?\nWe will also see a simple implementation of a frame-graph, that I use since my years in Codemasters and in my indie project. This will be much more data-driven than code-generated, but again, the purpose of these articles is to explore the concepts and understanding when to use what.\nAs always please comment, feedback, share!\nThanks for reading! Gabriel\n","date":1568176933,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1568176933,"objectID":"981a49821ad5e37fd95cd7c0c273e7a6","permalink":"/post/writing_shader_effect_language_2/","publishdate":"2019-09-11T00:42:13-04:00","relpermalink":"/post/writing_shader_effect_language_2/","section":"post","summary":"Overview Data Driven Rendering Series: 1. https://jorenjoestar.github.io/post/writing_shader_effect_language_1/ 2. https://jorenjoestar.github.io/post/writing_shader_effect_language_2/ 3. https://jorenjoestar.github.io/post/writing_shader_effect_language_3/ 4. https://jorenjoestar.github.io/post/data_driven_rendering_pipeline/\nIn Part 1 of this series we created a simple language to work as \u0026lsquo;shader effect\u0026rsquo; - a shader language superset to make our life easier, by adding missing features.\nThe fact that there is not an industry standard for a shader effect language leads to either hand-crafted (and secret) languages, or to hardcoded permutations, or to other gray-area solutions.","tags":[],"title":"Writing a Shader Effect Language Part 2","type":"post"},{"authors":[],"categories":[],"content":" Overview Data Driven Rendering Series: 1. https://jorenjoestar.github.io/post/writing_shader_effect_language_1/ 2. https://jorenjoestar.github.io/post/writing_shader_effect_language_2/ 3. https://jorenjoestar.github.io/post/writing_shader_effect_language_3/ 4. https://jorenjoestar.github.io/post/data_driven_rendering_pipeline/\nIn this article we will create a simple language that can encapsulate shader code (called code fragments) and output different files for each fragment.\nThis is the initial step to switch from an engine that loads single files for each shader stage (vertex, fragment, compute, \u0026hellip;) to one that uses an effect file that contains more than one shader.\nWe will start by motivation, then will define the language itself (very simple), then we will look at the Parser and last the Code Generator.\nHave a good read!\nMotivation In the incredible quest of data-driven rendering, after we defeated the dragon of code generation another multiple headed dragon arises: an hydra! We have different options here: be the brave warrior in shiny armor that tries to cut all the heads of the hydra, built some machines that can fight for us and send them, or both built the machines AND fight.\nOur code is invaluable, like our energies fighting the hydra. We need to carefully balance them and see how can we use for the BEST.\nWriting manual code is good, it is generally what is done, but it is slow and error prone. Going data-driven can be fast, but can give you a sense of losing control (not personally, but I heard few people saying that). Only generating code can quickly become a recipe for disaster: so many particular use cases need attention, that the code could be come a different kind of mess.\nWe will try to go down the route of code generation mixed with data-driven. As I wrote in my previous articles, it is a fine line and can be good to know when to go in which direction!\nI will divide the article in 2 parts. The first part (this one) will contain the new Shader Code Generator to generate shader permutations and add include support to GLSL. The second will require a low-level rendering library and will show Code Generation of more CPU areas of Rendering, the real goal of all these articles!\nThe code is available here:\nhttps://github.com/JorenJoestar/DataDrivenRendering\nEffect file structure Looking at effects, the first thing to do is to define a file that will represent our shaders. My choice is to create a simple language to embed shaders code and generate the CPU code necessary to render it.\nWhy not using Json ? While it is an amazing data-format, I still want a bigger degree of control of what to parse and what to generate. The decision is based on the fact that by writing a parser for the language, I can automate some code-generation that would be more intricate with Json. Also, this series itself is a personal exploration on the topic, so using Json was not an option for this level of complexity.\nThe HFX Format HFX (Hydra Effects) is a new language we will define to write out shaders. The first iteration will be barebone - it will simply be a shader permutation generator - but it will be the foundation to extensions that will allow us to write CPU rendering code that we want to automate.\nIn defining the format, there will be few keywords that will be defined, but the general architecture will make straightforward to copy-paste shader code fragments from any language into the HFX language. We will use the following keywords (and concepts).\nShader The root of a shader effect. It will contain everything we are writing.\nGlsl/Hlsl These will define the actual shader code, enclosed fragments. Fragments can be composed and reused. For Glsl in particular, code fragments needs to be embedded in defines for each stage. More on that later.\nPass, Technique, Variant This is the central part for the effects to work. I\u0026rsquo;ve researched a bit, between Microsoft effects, Unity effects, Godot and Bungie and the concepts are very similar, but they seem to differ a little and also each implementation becomes very engine-specific of course.\nThe presentation by Bungie is amazing and their system is by far the more extensive and complex, we will work on a much simpler shader effect system.\nLet\u0026rsquo;s define a pass as a combination of shader code for at least one stage of the shader pipeline. For example a single compute shader or a couple vertex-fragment shader.\nVariants and techniques are loose concept to help separating shader paths. For example a variant could be a different post-process shader, like different implementations of SSAO.\nA technique could be a whole set of passes that target a specific platform.\nNot having my mind set on those still, I will omit them for now, as they are concepts that are less central than the code generation, and can be very subjective opinion-wise. Possibly I\u0026rsquo;ll get them in part 2.\nProperties Final piece of the puzzle. This will define the resources used by the shader effect on a per-effect level. Keeping an eye on the newer rendering APIs (DX12 and Vulkan) this defines also the layout of the resources and how they are used. Possibly the most intense part from an automation possibility (and thus code-generation). We will define this in part 2 of this article.\nHigh level workflow From a high level perspective what will happen in all this code is enclosed in this code:\ntext = ReadEntireFileIntoMemory( \u0026quot;..\\\\data\\\\SimpleFullscreen.hfx\u0026quot;, nullptr ); initLexer( \u0026amp;lexer, (char*)text ); hfx::Parser effect_parser; hfx::initParser( \u0026amp;effect_parser, \u0026amp;lexer ); hfx::generateAST( \u0026amp;effect_parser ); hfx::CodeGenerator hfx_code_generator; hfx::initCodeGenerator( \u0026amp;hfx_code_generator, \u0026amp;effect_parser, 4096 ); hfx::generateShaderPermutations( \u0026amp;hfx_code_generator, \u0026quot;..\\\\data\\\\\u0026quot; );  We separated the Lexer from the Parser so we can reuse the lexer functionalities, thus we can reuse it from the previous example (parsing the HydraDataFormat files).\nThen we initialize the Parser and generate the AST. This will save all the passes and code fragments we defined in the HFX file.\nFinally we will get the parsing informations and give them to the code generator, that will write out the files for each pass and stage.\nLet\u0026rsquo;s dig into the example!\nParser: welcome HFX! In most rendering-API (OpenGL, Vulkan, Direct3D12, \u0026hellip;) shaders are compiled by compiling the individual stages (vertex, fragment, compute, geometry, \u0026hellip;) and in some APIs (especially the newer ones) are compiled into a Shader State.\nAs first step of this shader language, single shader files will be created by the shader generation method in our code.\nWe will define a simple fullscreen HFX with code fragments and passes.\nFirst, we define the root shader (SimpleFullscreen.hfx, under folder \u0026lsquo;data\u0026rsquo;):\nshader SimpleFullscreen {  This is simply the container for all the code and passes that will define the shader effect.\nNow we need some actual code, so we can define a shader fragment.\nThe keyword used in our language is glsl followed by a name and an open brace:\nglsl ToScreen {  This will define a code fragment named ToScreen, that can be referenced from the passes.\nNext we use a glsl trick to signal our parser to use includes:\n#pragma include \u0026quot;Platform.h\u0026quot;  This #pragma is actually ignored by the compiler, but will be used by the parser to actually add the include!\nBEWARE: this code will be included in BOTH vertex and fragment program!\nAnything outside of the VERTEX/FRAGMENT/COMPUTE macros will be, and this is done on purpose, like defining an interpolator struct only once or for common includes.\nNext we define the vertex program.\nBEWARE: vertex only code must be enclosed in VERTEX define!\n#if defined VERTEX out vec4 vTexCoord; void main() { vTexCoord.xy = vec2((gl_VertexID \u0026lt;\u0026lt; 1) \u0026amp; 2, gl_VertexID \u0026amp; 2); vTexCoord.zw = vTexCoord.xy; gl_Position = vec4(vTexCoord.xy * 2.0f + -1.0f, 0.0f, 1.0f); } #endif // VERTEX  This code is a simple fullscreen triangle that does not require any vertex buffer, but uses the vertex id to draw. Nothing fancy.\nNext is the fragment program, and again enclosed in FRAGMENT define:\n#if defined FRAGMENT in vec4 vTexCoord; out vec4 outColor; layout(binding=0) uniform sampler2D input_texture; void main() { vec3 color = texture2D(input_texture, vTexCoord.xy).xyz; outColor = vec4(color, 1); } #endif // FRAGMENT } // glsl ToScreen  This code simply reads a texture and outputs it to the screen.\nWe defined the code fragment ToScreen, containing both a vertex and a fragment program, and now we can actually generate the permutation that we need.\nThe code for this in our effect file is:\npass ToScreen { vertex = ToScreen fragment = ToScreen }  We are simply defining a pass with the vertex and fragment program defined in the ToScreen code fragment (yes I don\u0026rsquo;t like this term too).\nRunning the code generator on this simple effect file will generate the two files ToScreen.vert and ToScreen.frag.\nThese can be read directly into your favourite OpenGL renderer and used as is!\nThe Parser Now that we have defined the effect and we know what is the outcome of generating code from the effect file, let\u0026rsquo;s look into the different component of the parser and code generator needed.\nBy design, we chose the Lexer to know nothing about the language, so that we can use it between different languages. The entry point to parse the effect is the method generateAST:\nvoid generateAST( Parser* parser ) { // Read source text until the end. // The main body can be a list of declarations. bool parsing = true; while ( parsing ) { Token token; nextToken( parser-\u0026gt;lexer, token ); switch ( token.type ) { case Token::Token_Identifier: { identifier( parser, token ); break; } case Token::Type::Token_EndOfStream: { parsing = false; break; } } } }  This code simply process the file - using the lexer - until the end of it, and reads only identifiers.\nIt is the same as the previous article and the previous parser. What changes drastically is the identifier method!\nWe will have 3 different set of identifiers, usable in different parts of the HFX file:\n Main identifiers, \u0026lsquo;shader\u0026rsquo;, \u0026lsquo;glsl\u0026rsquo;, \u0026lsquo;pass\u0026rsquo; Pass identifiers, \u0026lsquo;compute\u0026rsquo;, \u0026lsquo;vertex\u0026rsquo;, \u0026lsquo;fragment\u0026rsquo; Directive identifiers, \u0026lsquo;if defined\u0026rsquo;, \u0026lsquo;pragma include\u0026rsquo;, \u0026lsquo;endif\u0026rsquo;  Let\u0026rsquo;s have a look at the code for parsing the main identifiers:\ninline void identifier( Parser* parser, const Token\u0026amp; token ) { // Scan the name to know which for ( uint32_t i = 0; i \u0026lt; token.text.length; ++i ) { char c = *(token.text.text + i); switch ( c ) { case 's': { if ( expectKeyword( token.text, 6, \u0026quot;shader\u0026quot; ) ) { declarationShader( parser ); return; } break; } case 'g': { if ( expectKeyword( token.text, 4, \u0026quot;glsl\u0026quot; ) ) { declarationGlsl( parser ); return; } break; } case 'p': { if ( expectKeyword( token.text, 4, \u0026quot;pass\u0026quot; ) ) { declarationPass( parser ); return; } break; } } } }  This code simply defers the parsing of a particular identifier using the declaration method corresponding to the identifier. We will look into detail on each method.\nParsing \u0026lsquo;shader\u0026rsquo; We are parsing now the following part from the HFX file:\n// HFX shader SimpleFullscreen {  This is the entry point of the effect itself.\nWhat should the parser do here ?\nSimply iterate through the main identifiers, \u0026lsquo;glsl\u0026rsquo; and \u0026lsquo;pass\u0026rsquo;.\nTechnically I could have separated the methods to have one with parsing shader only and the others parsing \u0026lsquo;glsl\u0026rsquo; and \u0026lsquo;pass\u0026rsquo;, but did not want to complicate the code further.\nLet\u0026rsquo;s look at how we parse the identifier \u0026lsquo;shader\u0026rsquo;:\n// C++ inline void declarationShader( Parser* parser ) { // Parse name Token token; if ( !expectToken( parser-\u0026gt;lexer, token, Token::Token_Identifier ) ) { return; } // Cache name string StringRef name = token.text; if ( !expectToken( parser-\u0026gt;lexer, token, Token::Token_OpenBrace ) ) { return; } while ( !equalToken( parser-\u0026gt;lexer, token, Token::Token_CloseBrace ) ) { identifier( parser, token ); } }  As the previous article\u0026rsquo;s code, this will get the tokens from the lexer and generate data if the syntax is correct.\nWhen we enter the method the Lexer will be just at the beginning of the name (SimpleFullscreen), so the code will parse the name, the open brace, and parse everything else until it encounter the close brace.\nThe method identifier will parse also identifiers \u0026lsquo;glsl\u0026rsquo; and \u0026lsquo;pass\u0026rsquo;.\nParsing \u0026lsquo;glsl\u0026rsquo; This is the most complex parsing in the code.\nI will put both the HFX part and C++ code so hopefully it will be clearer what the parser is doing and why.\nAs a refresh and reference, this is the code fragment ToScreen defined in SimpleFullscreen.hfx:\n// HFX glsl ToScreen { #pragma include \u0026quot;Platform.h\u0026quot; #if defined VERTEX out vec4 vTexCoord; void main() { vTexCoord.xy = vec2((gl_VertexID \u0026lt;\u0026lt; 1) \u0026amp; 2, gl_VertexID \u0026amp; 2); vTexCoord.zw = vTexCoord.xy; gl_Position = vec4(vTexCoord.xy * 2.0f + -1.0f, 0.0f, 1.0f); } #endif // VERTEX #if defined FRAGMENT in vec4 vTexCoord; out vec4 outColor; layout(binding=0) uniform sampler2D input_texture; void main() { vec3 color = texture2D(input_texture, vTexCoord.xy).xyz; outColor = vec4(1, 1, 0, 1); outColor = vec4(color, 1); } #endif // FRAGMENT }  Let\u0026rsquo;s start from the beginning.\nWhen the parser finds the \u0026lsquo;glsl\u0026rsquo; keyword in the identifier method:\n// C++ case 'g': { if ( expectKeyword( token.text, 4, \u0026quot;glsl\u0026quot; ) ) { declarationGlsl( parser ); return; } break; }  It calls the method void declarationGlsl( Parser* parser ).\nThe lexer reading the HFX is after the glsl keyword when entering the method, just before the ToScreen identifier:\n// HFX glsl (Here!)ToScreen {  Let\u0026rsquo;s see the C++ code step by step.\nFirst parsing the name \u0026lsquo;ToScreen\u0026rsquo;:\n// C++ inline void declarationGlsl( Parser* parser ) { // Parse name Token token; if ( !expectToken( parser-\u0026gt;lexer, token, Token::Token_Identifier ) ) { return; }  as seen in other methods as well.\nWe are defining a new code fragment, thus we need to initialize it. There is tracking of the #ifdef depths to manage when some code must be included in a code fragment and when not:\n CodeFragment code_fragment = {}; // Cache name string code_fragment.name = token.text; for ( size_t i = 0; i \u0026lt; CodeFragment::Count; i++ ) { code_fragment.stage_ifdef_depth[i] = 0xffffffff; } if ( !expectToken( parser-\u0026gt;lexer, token, Token::Token_OpenBrace ) ) { return; }  Next is simply arriving at the first token that contains all the glsl code:\n // Advance token and cache the starting point of the code. nextToken( parser-\u0026gt;lexer, token ); code_fragment.code = token.text;  And now some more parsing craftmanship.\nWe cannot use anymore the simple check to end parsing when encountering a closed brace, because there can be different structs defined that will break that mechanism.\nInstead we track the number of open braces and when we close the last one, we consider finished the parsing of the code fragment!\n uint32_t open_braces = 1; // Scan until close brace token while ( open_braces ) { if ( token.type == Token::Token_OpenBrace ) ++open_braces; else if ( token.type == Token::Token_CloseBrace ) --open_braces;  The only token that we care inside the code fragment is the hash, signalling either an include or a define, used for separating per-stage code.\nThe parsing of the hash token will be done inside the directiveIdentifier method:\n // Parse hash for includes and defines if ( token.type == Token::Token_Hash ) { // Get next token and check which directive is nextToken( parser-\u0026gt;lexer, token ); directiveIdentifier( parser, token, code_fragment ); }  Before diving deep into the directive identifiers, let\u0026rsquo;s finish the main parsing routine.\nWe advance to the next token until we close all the braces, and then save the text length of all the code fragment:\n nextToken( parser-\u0026gt;lexer, token ); } // Calculate code string length code_fragment.code.length = token.text.text - code_fragment.code.text;  Final step is to save the newly parsed code fragment into the parser data:\n parser-\u0026gt;code_fragments.emplace_back( code_fragment ); }  We can now dive deep into the parsing of directives, namely #if defined, #pragma include and #endif.\nParsing \u0026lsquo;#if defined\u0026rsquo; When we encounter the Hash token within the glsl part, we need to parse further to understand the other keywords.\n#if defined is the most important directive for us, because it will tell the parser which shader stage we are parsing currently and thus where to direct the text!\nIt starts from a common/shared stage, for shared code, and when encounters a #if defined it can signal a stage specific code.\nNamely when parsing the following line in HFX:\n// HFX #(Here!)if defined VERTEX  The parser needs to check 2 other identifiers. Remember that the parser is currently AFTER the Hash token, as beautifully written in the previous snippet!\nLet\u0026rsquo;s look at the code:\n// C++ inline void directiveIdentifier( Parser* parser, const Token\u0026amp; token, CodeFragment\u0026amp; code_fragment ) { Token new_token; for ( uint32_t i = 0; i \u0026lt; token.text.length; ++i ) { char c = *(token.text.text + i); switch ( c ) { case 'i': { // Search for the pattern 'if defined' if ( expectKeyword( token.text, 2, \u0026quot;if\u0026quot; ) ) { nextToken( parser-\u0026gt;lexer, new_token ); if ( expectKeyword( new_token.text, 7, \u0026quot;defined\u0026quot; ) ) { nextToken( parser-\u0026gt;lexer, new_token ); // Use 0 as not set value for the ifdef depth. ++code_fragment.ifdef_depth; if ( expectKeyword( new_token.text, 6, \u0026quot;VERTEX\u0026quot; ) ) { code_fragment.stage_ifdef_depth[CodeFragment::Vertex] = code_fragment.ifdef_depth; code_fragment.current_stage = CodeFragment::Vertex; } else if ( expectKeyword( new_token.text, 8, \u0026quot;FRAGMENT\u0026quot; ) ) { code_fragment.stage_ifdef_depth[CodeFragment::Fragment] = code_fragment.ifdef_depth; code_fragment.current_stage = CodeFragment::Fragment; } else if ( expectKeyword( new_token.text, 7, \u0026quot;COMPUTE\u0026quot; ) ) { code_fragment.stage_ifdef_depth[CodeFragment::Compute] = code_fragment.ifdef_depth; code_fragment.current_stage = CodeFragment::Compute; } } return; } break; }  Let\u0026rsquo;s dissect this code!\nStarting from the current token, just after the #(Hash), we need to check the correct composition of the keywords.\nWe expect \u0026lsquo;if\u0026rsquo;, and then if found we go to the next token:\nif ( expectKeyword( token.text, 2, \u0026quot;if\u0026quot; ) ) { nextToken( parser-\u0026gt;lexer, new_token );  We search for the \u0026lsquo;defined\u0026rsquo; identifier and if found we go to the next identifier:\nif ( expectKeyword( new_token.text, 7, \u0026quot;defined\u0026quot; ) ) { nextToken( parser-\u0026gt;lexer, new_token );  The parser is currently here:\n#if defined (Here!)VERTEX  And thus the last step is to check which shader stage is currently starting. This is done here:\nif ( expectKeyword( new_token.text, 6, \u0026quot;VERTEX\u0026quot; ) ) { code_fragment.stage_ifdef_depth[CodeFragment::Vertex] = code_fragment.ifdef_depth; code_fragment.current_stage = CodeFragment::Vertex; }  In this central piece of code, we set the current stage to Vertex (because we found the keyword \u0026lsquo;VERTEX\u0026rsquo;) and we save the current ifdef depth.\nWhy that ? Because when we will parse #endif, we will do the same for the open/close braces depth in the main glsl parser: we want to be sure that the defines are paired correctly and we are saving the per-stage code in the correct way!\nThis will be more clear when we see the #endif parsing.\nMoving on, we will do the same for all the other keywords (\u0026lsquo;FRAGMENT\u0026rsquo; and \u0026lsquo;COMPUTE\u0026rsquo; for now):\nelse if ( expectKeyword( new_token.text, 8, \u0026quot;FRAGMENT\u0026quot; ) ) { code_fragment.stage_ifdef_depth[CodeFragment::Fragment] = code_fragment.ifdef_depth; code_fragment.current_stage = CodeFragment::Fragment; } else if ( expectKeyword( new_token.text, 7, \u0026quot;COMPUTE\u0026quot; ) ) { code_fragment.stage_ifdef_depth[CodeFragment::Compute] = code_fragment.ifdef_depth; code_fragment.current_stage = CodeFragment::Compute; }  And the parsing of #if defined is over!\nParsing \u0026lsquo;#pragma include\u0026rsquo; In HFX we are parsing the following:\n// HFX #pragma include \u0026quot;Platform.h\u0026quot;  With the following code (inside directiveIdentifier method):\n// C++ case 'p': { if ( expectKeyword( token.text, 6, \u0026quot;pragma\u0026quot; ) ) { nextToken( parser-\u0026gt;lexer, new_token ); if ( expectKeyword( new_token.text, 7, \u0026quot;include\u0026quot; ) ) { nextToken( parser-\u0026gt;lexer, new_token ); code_fragment.includes.emplace_back( new_token.text ); code_fragment.includes_stage.emplace_back( code_fragment.current_stage ); } return; } break; }  This is simply saving the filename after the include, that being surrounded by \u0026ldquo;\u0026rdquo; is classified as string, and is using the current stage to know which stage should include that file!\nParsing \u0026lsquo;#endif\u0026rsquo; Final part is the #endif identifier:\ncase 'e': { if ( expectKeyword( token.text, 5, \u0026quot;endif\u0026quot; ) ) { if ( code_fragment.stage_ifdef_depth[CodeFragment::Vertex] == code_fragment.ifdef_depth ) { code_fragment.stage_ifdef_depth[CodeFragment::Vertex] = 0xffffffff; code_fragment.current_stage = CodeFragment::Common; } else if ( code_fragment.stage_ifdef_depth[CodeFragment::Fragment] == code_fragment.ifdef_depth ) { code_fragment.stage_ifdef_depth[CodeFragment::Fragment] = 0xffffffff; code_fragment.current_stage = CodeFragment::Common; } else if ( code_fragment.stage_ifdef_depth[CodeFragment::Compute] == code_fragment.ifdef_depth ) { code_fragment.stage_ifdef_depth[CodeFragment::Compute] = 0xffffffff; code_fragment.current_stage = CodeFragment::Common; } --code_fragment.ifdef_depth; return; } break; }  This is mirroring the #if defined and simply goes back to set the current stage to common/shared and reset the per-stage ifdef depth.\nWe can now proceed to the final part of the parsing, the passes!\nThis is the glue to generate the different files from the code fragments.\nParsing \u0026lsquo;pass\u0026rsquo; Reading the HFX file, we are now in the final part of the file:\n// HFX pass ToScreen { vertex = ToScreen fragment = ToScreen }  A pass is simply a collection of code fragments associated with each shader stage (vertex, fragment, compute).\nWhen we parsed the fragments, we saved them in the parser to be retrieved.\nTo refresh our memory, this is the actual Pass struct in C++:\n// C++ struct Pass { StringRef name; const CodeFragment* vs = nullptr; const CodeFragment* fs = nullptr; const CodeFragment* cs = nullptr; }; // struct Pass  Going back to the main directive method, we call the declarationPass method when we encounter the \u0026lsquo;pass\u0026rsquo; identifier.\nWe will parse the following line:\n// HFX pass ToScreen {  With the following code (similar to everything else, it should be easier to read now):\n// C++ inline void declarationPass( Parser* parser ) { Token token; if ( !expectToken( parser-\u0026gt;lexer, token, Token::Token_Identifier ) ) { return; } Pass pass = {}; // Cache name string pass.name = token.text; if ( !expectToken( parser-\u0026gt;lexer, token, Token::Token_OpenBrace ) ) { return; }  After we saved the pass name we can start reading the individual stages using the passIdentifier method:\n while ( !equalToken( parser-\u0026gt;lexer, token, Token::Token_CloseBrace ) ) { passIdentifier( parser, token, pass ); }  And then save the newly parsed pass.\n parser-\u0026gt;passes.emplace_back( pass ); }  For each identifier now, we will check which stage we are parsing.\nCurrently we are here, after the open brace and all the whitespace:\n// HFX pass ToScreen { (Here!)vertex = ToScreen fragment = ToScreen }  What is next is thus checking the identifier and filling the corresponding shader stage of the pass.\nI will post all the code of the method, because is similar to most code we seen and should be straightforward:\n// C++ inline void passIdentifier( Parser* parser, const Token\u0026amp; token, Pass\u0026amp; pass ) { // Scan the name to know which stage we are parsing for ( uint32_t i = 0; i \u0026lt; token.text.length; ++i ) { char c = *(token.text.text + i); switch ( c ) { case 'c': { if ( expectKeyword( token.text, 7, \u0026quot;compute\u0026quot;) ) { declarationShaderStage( parser, \u0026amp;pass.cs ); return; } break; } case 'v': { if ( expectKeyword( token.text, 6, \u0026quot;vertex\u0026quot; ) ) { declarationShaderStage( parser, \u0026amp;pass.vs ); return; } break; } case 'f': { if ( expectKeyword( token.text, 8, \u0026quot;fragment\u0026quot; ) ) { declarationShaderStage( parser, \u0026amp;pass.fs ); return; } break; } } } }  The real \u0026lsquo;magic\u0026rsquo; here is the \u0026lsquo;declarationShaderStage\u0026rsquo; method.\nThis method parses the couple \u0026lsquo;identifier\u0026rsquo; \u0026lsquo;=\u0026rsquo; \u0026lsquo;identifier\u0026rsquo;, and searches the code fragment with the same name:\ninline void declarationShaderStage( Parser* parser, const CodeFragment** out_fragment ) { Token token; if ( !expectToken( parser-\u0026gt;lexer, token, Token::Token_Equals ) ) { return; } if ( !expectToken( parser-\u0026gt;lexer, token, Token::Token_Identifier ) ) { return; } *out_fragment = findCodeFragment( parser, token.text ); }  After all the stages of the current pass are parsed, we save the pass and finish parsing the file!\nShader Permutation Generation The final step of this amazing journey is the simplest, and it is actually to generate the single files we need.\nIn our case another specific class, CodeGenerator, will generate the different files from the parsed HFX file.\nAfter we\u0026rsquo;ve done with the parsing, we can call the generateShaderPermutations method that will generate files for each shader stage in each pass:\nvoid generateShaderPermutations( CodeGenerator* code_generator, const char* path ) { code_generator-\u0026gt;string_buffer_0.clear(); code_generator-\u0026gt;string_buffer_1.clear(); code_generator-\u0026gt;string_buffer_2.clear(); // For each pass and for each pass generate permutation file. const uint32_t pass_count = (uint32_t)code_generator-\u0026gt;parser-\u0026gt;passes.size(); for ( uint32_t i = 0; i \u0026lt; pass_count; i++ ) { // Create one file for each code fragment const Pass\u0026amp; pass = code_generator-\u0026gt;parser-\u0026gt;passes[i]; if ( pass.cs ) { outputCodeFragment( code_generator, path, CodeFragment::Compute, pass.cs ); } if ( pass.fs ) { outputCodeFragment( code_generator, path, CodeFragment::Fragment, pass.fs ); } if ( pass.vs ) { outputCodeFragment( code_generator, path, CodeFragment::Vertex, pass.vs ); } } }  The code should be straightforward, and the real action happens into the outputCodeFragment method.\nLet\u0026rsquo;s have a look at the code.\nFirst we define some data, like the file extensions for each shader stage or the defines to compile the code:\n// Additional data to be added to output shaders. static const char* s_shader_file_extension[CodeFragment::Count] = { \u0026quot;.vert\u0026quot;, \u0026quot;.frag\u0026quot;, \u0026quot;.compute\u0026quot;, \u0026quot;.h\u0026quot; }; static const char* s_shader_stage_defines[CodeFragment::Count] = { \u0026quot;#define VERTEX\\r\\n\u0026quot;, \u0026quot;#define FRAGMENT\\r\\n\u0026quot;, \u0026quot;#define COMPUTE\\r\\n\u0026quot;, \u0026quot;\u0026quot; };  Then we start to write the file.\nWe will use the string_buffer_0 to dynamically generate the path of the file without allocating memory:\nvoid outputCodeFragment( CodeGenerator* code_generator, const char* path, CodeFragment::Stage stage, const CodeFragment* code_fragment ) { // Create file FILE* output_file; code_generator-\u0026gt;string_buffer_0.clear(); code_generator-\u0026gt;string_buffer_0.append( path ); code_generator-\u0026gt;string_buffer_0.append( code_fragment-\u0026gt;name ); code_generator-\u0026gt;string_buffer_0.append( s_shader_file_extension[stage] ); fopen_s( \u0026amp;output_file, code_generator-\u0026gt;string_buffer_0.data, \u0026quot;wb\u0026quot; ); if ( !output_file ) { printf( \u0026quot;Error opening file. Aborting. \\n\u0026quot; ); return; }  And then use string_buffer_1 to instead generate the actual code into the file.\nFirst, and most important, we will add all the includes for this particular stage by opening the file, reading it into memory and adding it into the final code buffer.\nWe will still use string_buffer_0 to generate the path of the file:\n code_generator-\u0026gt;string_buffer_1.clear(); // Append includes for the current stage. for ( size_t i = 0; i \u0026lt; code_fragment-\u0026gt;includes.size(); i++ ) { if ( code_fragment-\u0026gt;includes_stage[i] != stage \u0026amp;\u0026amp; code_fragment-\u0026gt;includes_stage[i] != CodeFragment::Common ) { continue; } // Open and read file code_generator-\u0026gt;string_buffer_0.clear(); code_generator-\u0026gt;string_buffer_0.append( path ); code_generator-\u0026gt;string_buffer_0.append( code_fragment-\u0026gt;includes[i] ); char* include_code = ReadEntireFileIntoMemory( code_generator-\u0026gt;string_buffer_0.data, nullptr ); code_generator-\u0026gt;string_buffer_1.append( include_code ); code_generator-\u0026gt;string_buffer_1.append( \u0026quot;\\r\\n\u0026quot; ); }  After that is done we can copy the define needed for the current shader stage:\n code_generator-\u0026gt;string_buffer_1.append( \u0026quot;\\t\\t\u0026quot; ); code_generator-\u0026gt;string_buffer_1.append( s_shader_stage_defines[stage] );  And finally the actual code:\n code_generator-\u0026gt;string_buffer_1.append( \u0026quot;\\r\\n\\t\\t\u0026quot; ); code_generator-\u0026gt;string_buffer_1.append( code_fragment-\u0026gt;code );  Write to file and close it and we are done!\n fprintf( output_file, \u0026quot;%s\u0026quot;, code_generator-\u0026gt;string_buffer_1.data ); fclose( output_file ); }  And this will generate the shader permutations for each pass with a single file, using the standard GLSL convention for files extensions.\nConclusions and next part We parsed our simple shader language to enhance and embed glsl code fragments into our codebase by generating single files that can be used into any OpenGL based renderer.\nWe also laid out the foundation for a more powerful tool - namely code generation - even though there are some intermediate steps to be taken to arrive there.\nFirst of all, we will need a target rendering library (something like the amazing Sokol), so we can specialize our CPU rendering code. I already wrote something like Sokol but with a more Vulkan/D3D12 interface in mind, and I will use that. Still unsure if I will write a specific post on that.\nIn the next article we will add support for the new graphics library and develop the language more to generate code that will manage Constant buffers, automatically creating a CPU-side class, adding UI to edit it in realtime and possibly load/save the values.\nOf course, any feedback/improvements/suggestions on anything related here (article, code, etc) please let me know.\nStay tuned! Gabriel\n","date":1565111055,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1566011055,"objectID":"2335acd956430a4df447b79b03bb937a","permalink":"/post/writing_shader_effect_language_1/","publishdate":"2019-08-06T13:04:15-04:00","relpermalink":"/post/writing_shader_effect_language_1/","section":"post","summary":"Overview Data Driven Rendering Series: 1. https://jorenjoestar.github.io/post/writing_shader_effect_language_1/ 2. https://jorenjoestar.github.io/post/writing_shader_effect_language_2/ 3. https://jorenjoestar.github.io/post/writing_shader_effect_language_3/ 4. https://jorenjoestar.github.io/post/data_driven_rendering_pipeline/\nIn this article we will create a simple language that can encapsulate shader code (called code fragments) and output different files for each fragment.\nThis is the initial step to switch from an engine that loads single files for each shader stage (vertex, fragment, compute, \u0026hellip;) to one that uses an effect file that contains more than one shader.","tags":[],"title":"Writing a Shader Effect Language Part 1","type":"post"},{"authors":[],"categories":[],"content":"   UI using ImGUI, SDL and the code generated with this article.   Motivation Following my previous article about Flatbuffers and data reflection the quest for Data-Driven Rendering continues!\nIn this article I want to show how to write a very simple code-generator to help you automate writing of code in any language.\nThe code is here:\nhttps://github.com/JorenJoestar/DataDrivenRendering\nThere is a balance that constantly needs to be found between code and data, and having a code-generator in my opinion helps tremendously in focus on the code that is necessary to be written.\nFrom a data perspective, normally the ‘baking’ pipeline is a series of DCC formats as source transformed into very project specific and optimized data.\nCode-wise, depending on the engine/technology you are using, ‘baking’ of the code is more uncommon.\nIn a time in which iteration time has become almost more important than the tech itself, playing with this balance can be the key for any successful software. It could sound exaggerated, but I really believe in that.\nAs always, both ImGui and SDL will be our sword and shields for this adventure.\nThis will be the second step into data-driven rendering: code generation.\nAre we writing a compiler ? Short answer: yes!\nLong answer: we will be writing the simplest possible compiler that reads a source file and transform in a destination file, like Flatbuffers.\nThere are few links on both theory and practice that can help shed some light on the subject: The “Dragon Book” (called because of the dragon in the cover) is still THE to-go in compiler writing as far as I know.\nIt is an intense book and explores writing a full compiler with depth, starting from Automata theory (just reminds me of how everything you study can be useful, I did 2 exams at University about that, wondering when I would use it! Hello prof Di Battista!) to full code examples:\nhttps://www.amazon.com/Compilers-Principles-Techniques-Tools-2nd/dp/0321486811\nThis is for me the best website on the subject, very precise and readable and follows closely what is inside the Dragon Book:\nhttps://craftinginterpreters.com/\nAnd github page:\nhttps://github.com/munificent/craftinginterpreters\nMy interest was rekindled in 2015, when I was following the amazing Casey Muratori and his Handmade Hero.\nHe generates code for introspection purposes, and really show a simple and effective way of generating code that works for you.\nWikipedia itself also contains a lot of good articles on the subject. The more you know about the it, the more you want to know. It is fascinating and very, very deep!\nCompiler 101 A real compiler is a very complex and fascinating subject/software so I will try to get the simplest possible approach giving my (flawed and incomplete) perspective.\nA compiler is a series of transformations applied to data (you can apply this definition to every software actually…).\nThe input data is a text, and normally the output is still text, but with very different meaning.\nThe raw depth of the subject is astonishing, consider that we are defining a grammar and thus a language, and how to express concepts into it.\nThe main steps are the following:\n Lexer/scanner/tokenizer Parser Code generation  We will define the code generator from a custom language called HDF (Hydra Definition Format) to C++. HDF will be a subset of Flatbuffers in this exercise, but once the concepts are clear it can be expanded to more stuff.\nLexer/Scanner/Tokenizer A lexer or scanner (or tokenizer) is a software that translates an input string into a list of Tokens based on Lexemes. A Lexeme is one or more characters that create a Token. Think of a keyword (like ‘if’, ‘class’, ‘static’ …).\nA Token is identified by a unique Lexeme and abstracts the Lexeme itself. It normally contains a type and some attributes, for example it can save where that lexeme is into the input text, the line. The final structure of the token can vary a bit.\nIn trying to find a simple definition for this step:\n The act of Tokenizing is the act of abstracting the input text.\n For example, given the following input text:\nstatic void amazing_method() {};  It will generate the list of tokens ‘keyword, identifier, identifier, open parenthesis, close parenthesis, open brace, close brace, semicolon’.\nThis IS abstracting the text!\nNormally a lexer/scanner is used by the parser to go through the code and retrieve a token and use it in some way. Let’s start seeing what a lexer could be!\nCode Let\u0026rsquo;s see the code used by the lexer.\nFirst thing will be to define the Token:\n// Lexer/Tokenizer code. It is abstract enough so is not grammar specific. // struct Token { enum Type { Token_Unknown, Token_OpenParen, Token_CloseParen, Token_Colon, Token_Semicolon, Token_Asterisk, Token_OpenBracket, Token_CloseBracket, Token_OpenBrace, Token_CloseBrace, Token_OpenAngleBracket, Token_CloseAngleBracket, Token_String, Token_Identifier, Token_Number, Token_EndOfStream, }; // enum Type Type type; StringRef text; }; // struct Token  It is basically a enum with a StringRef.\nA StringRef is basically a substring - used to avoid allocations when parsing by simply saving where the Token is in the parsed text and how long it is.\nNext is the Lexer itself:\n// // The role of the Lexer is to divide the input string into a list of Tokens. struct Lexer { char* position = nullptr; uint32_t line = 0; uint32_t column = 0; bool error = false; uint32_t error_line = 0; }; // struct Lexer  The most important variable is position - it saves where the Lexer is in the current text for parsing.\nFrom now on there will be only methods.\nFirst some character classification that will help the Lexer:\n// // All those methods are to classify a character. // inline bool IsEndOfLine( char c ) { bool Result = ((c == '\\n') || (c == '\\r')); return(Result); } inline bool IsWhitespace( char c ) { bool Result = ((c == ' ') || (c == '\\t') || (c == '\\v') || (c == '\\f') || IsEndOfLine( c )); return(Result); } inline bool IsAlpha( char c ) { bool Result = (((c \u0026gt;= 'a') \u0026amp;\u0026amp; (c \u0026lt;= 'z')) || ((c \u0026gt;= 'A') \u0026amp;\u0026amp; (c \u0026lt;= 'Z'))); return(Result); } inline bool IsNumber( char c ) { bool Result = ((c \u0026gt;= '0') \u0026amp;\u0026amp; (c \u0026lt;= '9')); return(Result); }  These should be quite straightforward.\nThen we have the most important method for the lexer: nextToken.\nThis method will contain all the logic to go to the next token, and we will see it step by step.\nFirst is skipping all the whitespaces (empty characters, tabs, returns, etc) to arrive at the correct character in the text.\n// // This is the main method. Skip whitespaces and get next token. Save also the current position in the input string. // void nextToken( Lexer* lexer, Token\u0026amp; token ) { // Skip all whitespace first so that the token is without them. skipWhitespace( lexer );  The code for skipping the whitespace is pretty straight-forward. First it checks if it is a pure whitespace:\nvoid skipWhitespace( Lexer* lexer ) { // Scan text until whitespace is finished. for ( ;; ) { // Check if it is a pure whitespace first. if ( IsWhitespace( lexer-\u0026gt;position[0] ) ) { // Handle change of line if ( IsEndOfLine( lexer-\u0026gt;position[0] ) ) ++lexer-\u0026gt;line; // Advance to next character ++lexer-\u0026gt;position;  Then it checks if it is a single line comment:\n } // Check for single line comments (\u0026quot;//\u0026quot;) else if ( (lexer-\u0026gt;position[0] == '/') \u0026amp;\u0026amp; (lexer-\u0026gt;position[1] == '/') ) { lexer-\u0026gt;position += 2; while ( lexer-\u0026gt;position[0] \u0026amp;\u0026amp; !IsEndOfLine( lexer-\u0026gt;position[0] ) ) { ++lexer-\u0026gt;position; }  And last it checks for c-style multiline comments:\n } // Check for c-style multi-lines comments else if ( (lexer-\u0026gt;position[0] == '/') \u0026amp;\u0026amp; (lexer-\u0026gt;position[1] == '*') ) { lexer-\u0026gt;position += 2; // Advance until the string is closed. Remember to check if line is changed. while ( !((lexer-\u0026gt;position[0] == '*') \u0026amp;\u0026amp; (lexer-\u0026gt;position[1] == '/')) ) { // Handle change of line if ( IsEndOfLine( lexer-\u0026gt;position[0] ) ) ++lexer-\u0026gt;line; // Advance to next character ++lexer-\u0026gt;position; } if ( lexer-\u0026gt;position[0] == '*' ) { lexer-\u0026gt;position += 2; } } else { break; } } }  After skipped all the whitespaces, we initialize the new token:\n // Initialize token token.type = Token::Token_Unknown; token.text.text = lexer-\u0026gt;position; token.text.length = 1; token.line = lexer-\u0026gt;line;  We get the current character and advance the position, so we can analize it.\n char c = lexer-\u0026gt;position[0]; ++lexer-\u0026gt;position;  Here comes the character analisys using a simple switch.\n switch ( c ) { case '\\0': { token.type = Token::Token_EndOfStream; } break; case '(': { token.type = Token::Token_OpenParen; } break; case ')': { token.type = Token::Token_CloseParen; } break; case ':': { token.type = Token::Token_Colon; } break; case ';': { token.type = Token::Token_Semicolon; } break; case '*': { token.type = Token::Token_Asterisk; } break; case '[': { token.type = Token::Token_OpenBracket; } break; case ']': { token.type = Token::Token_CloseBracket; } break; case '{': { token.type = Token::Token_OpenBrace; } break; case '}': { token.type = Token::Token_CloseBrace; } break;  There are some special cases left.\nFirst parsing a string starting from a \u0026lsquo;\u0026ldquo;\u0026rsquo; character.\nIt requires to scan the text until it finds another \u0026lsquo;\u0026ldquo;\u0026rsquo; to indicate the end of the string.\nIt also supports multiple-line strings with the characters \u0026ldquo;\\\u0026rdquo; (double back-slash)\n case '\u0026quot;': { token.type = Token::Token_String; token.text.text = lexer-\u0026gt;position; while ( lexer-\u0026gt;position[0] \u0026amp;\u0026amp; lexer-\u0026gt;position[0] != '\u0026quot;' ) { if ( (lexer-\u0026gt;position[0] == '\\\\') \u0026amp;\u0026amp; lexer-\u0026gt;position[1] ) { ++lexer-\u0026gt;position; } ++lexer-\u0026gt;position; } // Saves total string length token.text.length = lexer-\u0026gt;position - token.text.text; if ( lexer-\u0026gt;position[0] == '\u0026quot;' ) { ++lexer-\u0026gt;position; } } break;  Then the final classification step: first is checking if the token is an identifier (a string literal that starts with a character and is followed by characters, underscores or numbers).\nIf not a identifier, check to see if it is a number. This should be expanded to correctly parse numbers, but for now is not used.\n. If everything else fails, than we don\u0026rsquo;t recognize the token.\n default: { // Identifier/keywords if ( IsAlpha( c ) ) { token.type = Token::Token_Identifier; while ( IsAlpha( lexer-\u0026gt;position[0] ) || IsNumber( lexer-\u0026gt;position[0] ) || (lexer-\u0026gt;position[0] == '_') ) { ++lexer-\u0026gt;position; } token.text.length = lexer-\u0026gt;position - token.text.text; } // Numbers else if ( IsNumber( c ) ) { token.type = Token::Token_Number; } else { token.type = Token::Token_Unknown; } } break; } }  With this code we already have a working Lexer!\nI like to use the lexer in an abstract way - not knowing anything about the underlying language - so that it can be reused for different custom languages (Dr.Wily eyebrows movement goes here).\nIf you want to dive deeper into this, the amazing Crafting Interpreters contains a great page on scanning:\nhttps://www.craftinginterpreters.com/scanning.html\nAlso, some c-style parsing can be found here from the amazing Niklas Frykohlm:\nhttps://github.com/niklasfrykholm/nflibs/blob/master/nf_json_parser.c\nAnd another amazing parser from STB:\nhttps://github.com/nothings/stb/blob/master/stb_c_lexer.h\nParser So far we have abstracted the input text into a list of Tokens, and now we need to generate some more information before arriving at generating new code.\nAs far as I understood it, a parser reads the tokens and generates an Abstract Syntax Tree.\nSometimes, and in simpler parsers, the act of parsing itself can generates a new code if the language we are targeting is simple. Again, I prefer to separate Lexer and Parser to reuse the Lexer for different languages and separate the responsabilities!\n Given a list of tokens and a grammar, a parser generates an Abstract Syntax Tree.\nIt gives meaning to the input text, and is responsible to check the syntax correctness.\n A simple definition for a grammar is the following:\n A grammar is a set of production rules that transforms a series of non-terminals into terminals.\n Putting everything in the perspective of data and transformations we can define:\n Terminals are finalized data Non-terminals are data that must be transformed Production rules are transformations of non-terminals to terminals  Another definition of a parser than it could be :\n A parser is a software that transforms non-terminals in terminals following production rules.\n Grammar It is time to write the formal grammar (a context-free grammar) and see how it maps to code.\nIt will be very simple — much simpler than many examples you find around — but it is a starting point.\nWe will not deal with any expression, statements and such, not in the context of this code generator. I will point out some examples for more complex stuff, but I want to study more the subject for that to be more precise about the subject.\nEach line will be a production rule (a transformation), with the left-side being always a non-terminal.\nWe are using regular expressions syntax here:\n alphabet → [a-zA-z] number →[0–9] identifier → alphabet (alphabet | number | “_”)* variable_declaration → identifier identifier “;” struct_declaration → “struct” identifier “{“ (variable_declaration)+ “}” “;” enum_declaration → “enum” identifier “{“ (identifier)+ “}” module → (struct_declaration | enum_declaration)+*  First we define what an identifier is — a sequence of alpha-numerical characters that can contains also the underscore character.\nNotice that with the identifier production rule, the identifier cannot start with an underscore.\nA variable then is declared simply by two identifiers: the first for the type and the second for the name, following a semicolon.\nA struct is simply a list of variable declarations. Notice the “+” in the rule — this means that at least one element must be present.\nEnums are literally a name for the enum and a list of identifiers in curly braces.\nFinally the module is the root of our grammar. It will contain all the declarations we describe. See it as the data file we are writing to generate the code — one file is one module.\nNow that we defined a simple grammar, we can move to the theory behind the parser.\nPredictive Recursive Descent Parser The grammar we defined is a context-free-grammar.\nDepending on the type of grammar we can write different parsers.\nOne of the most common type of parser (and easier to start with) is the Predictive Recursive Descent Parser, and that is what we will write given our grammar. You can dive into all the details of writing a context-free grammar, writing a Left-to-right Leftmost-derivation grammar (LL(k)) and such and be amazed by all the concepts behind.\nAgain, I am personally starting on this subject, so my knowledge is not deep.\nBack to the parser, the main characteristics of this parser are:\n Descent = top-down. Start from root and generate the Abstract Syntax Tree. Recursive = the parser has mutually recursive methods, one for each non-terminal. Predictive = no backtracking needed. For our simple grammar we do not need any backtracking.  So the parser will start from the root (module non-terminal) and by sequentially reading all the tokens will generate a tree that represent our syntax.\nLet’s see some code!\nCode The central piece of code is the Parser.\nIt uses the Lexer and saves the Types by parsing the input text.\n// // The Parser parses Tokens using the Lexer and generate an Abstract Syntax Tree. struct Parser { Lexer* lexer = nullptr; ast::Type* types = nullptr; uint32_t types_count = 0; uint32_t types_max = 0; }; // struct Parser  Let\u0026rsquo;s have a look at the class Type.\nThis class will let us identify correctly primitive types, enums, struct and commands - a special keyword I create to show a concept that can be used away from the canonical C/C++ languages.\nBy saving a list of names and types we can successfully parse all the types listed above.\n// // Define the language specific structures. namespace ast { struct Type { enum Types { Types_Primitive, Types_Enum, Types_Struct, Types_Command, Types_None }; enum PrimitiveTypes { Primitive_Int32, Primitive_Uint32, Primitive_Int16, Primitive_Uint16, Primitive_Int8, Primitive_Uint8, Primitive_Int64, Primitive_Uint64, Primitive_Float, Primitive_Double, Primitive_Bool, Primitive_None }; Types type; PrimitiveTypes primitive_type; StringRef name; std::vector\u0026lt;StringRef\u0026gt; names; std::vector\u0026lt;const Type*\u0026gt; types; bool exportable = true; }; // struct Type } // namespace ast  And now the actual code making the magic happens!\nEntry point for the parsing is generateAST.\nIt simply goes through ALL the tokens until it reaches the end of the file.\nAt this level of parsing, we parse only identifiers (keywords like \u0026lsquo;struct\u0026rsquo;, \u0026lsquo;enum\u0026rsquo;, \u0026hellip;).\nvoid generateAST( Parser* parser ) { // Read source text until the end. // The main body can be a list of declarations. bool parsing = true; while ( parsing ) { Token token; nextToken( parser-\u0026gt;lexer, token ); switch ( token.type ) { case Token::Token_Identifier: { identifier( parser, token ); break; } case Token::Type::Token_EndOfStream: { parsing = false; break; } } } }  The method \u0026lsquo;identifier\u0026rsquo; searches for the language keywords and acts accordingly.\nThe method \u0026lsquo;expectKeyword\u0026rsquo; simply checks that the keywords are the same.\ninline void identifier( Parser* parser, const Token\u0026amp; token ) { // Scan the name to know which for ( uint32_t i = 0; i \u0026lt; token.text.length; ++i ) { char c = *(token.text.text + i); switch ( c ) { case 's': { if ( expectKeyword( token.text, 6, \u0026quot;struct\u0026quot; ) ) { declarationStruct( parser ); return; } break; } case 'e': { if ( expectKeyword( token.text, 4, \u0026quot;enum\u0026quot; ) ) { declarationEnum( parser ); return; } break; } case 'c': { if ( expectKeyword( token.text, 7, \u0026quot;command\u0026quot; ) ) { declarationCommand( parser ); return; } break; } } } }  The next methods are the real core of parsing a language. When declaring a struct, the token we have are:\n Identifier \u0026lsquo;struct\u0026rsquo; (parsed already by generateAST method) Name of the struct Open braces Zero or more variables  The method expectToken checks the presence of the expected token and saves the line if an error occurs.\ninline void declarationStruct( Parser* parser ) { // name Token token; if ( !expectToken( parser-\u0026gt;lexer, token, Token::Token_Identifier ) ) { return; } // Cache name string StringRef name = token.text; if ( !expectToken( parser-\u0026gt;lexer, token, Token::Token_OpenBrace ) ) { return; } // Add new type ast::Type\u0026amp; type = parser-\u0026gt;types[parser-\u0026gt;types_count++]; type.name = name; type.type = ast::Type::Types_Struct; type.exportable = true; // Parse struct internals while ( !equalToken( parser-\u0026gt;lexer, token, Token::Token_CloseBrace ) ) { if ( token.type == Token::Token_Identifier ) { declarationVariable( parser, token.text, type ); } } }  The parsing of a variable is even simpler, just a type followed by the name. When reading the type, it searches through the list of all types saved until then.\ninline void declarationVariable( Parser* parser, const StringRef\u0026amp; type_name, ast::Type\u0026amp; type ) { const ast::Type* variable_type = findType( parser, type_name ); Token token; // Name if ( !expectToken( parser-\u0026gt;lexer, token, Token::Token_Identifier ) ) { return; } // Cache name string StringRef name = token.text; if ( !expectToken( parser-\u0026gt;lexer, token, Token::Token_Semicolon ) ) { return; } type.types.emplace_back( variable_type ); type.names.emplace_back( name ); }  The parsing of the enum is:\n \u0026lsquo;enum\u0026rsquo; keyword Enum name (optional) Semicolon and type, taken from Flatbuffers syntax Open brace List of identifiers that corresponds to the enum values  \n inline void declarationEnum( Parser* parser ) { Token token; // Name if ( !expectToken( parser-\u0026gt;lexer, token, Token::Token_Identifier ) ) { return; } // Cache name string StringRef name = token.text; // Optional ': type' for the enum nextToken( parser-\u0026gt;lexer, token ); if ( token.type == Token::Token_Colon ) { // Skip to open brace nextToken( parser-\u0026gt;lexer, token ); // Token now contains type_name nextToken( parser-\u0026gt;lexer, token ); // Token now contains open brace. } if ( token.type != Token::Token_OpenBrace ) { return; } // Add new type ast::Type\u0026amp; type = parser-\u0026gt;types[parser-\u0026gt;types_count++]; type.name = name; type.type = ast::Type::Types_Enum; type.exportable = true; // Parse struct internals while ( !equalToken( parser-\u0026gt;lexer, token, Token::Token_CloseBrace ) ) { if ( token.type == Token::Token_Identifier ) { type.names.emplace_back( token.text ); } } }  A command is a special construct that I use in my code, normally with a CommandBuffer, and with the current syntax from HDF:\ncommand WindowEvents { Click { int16 x; int16 y; int16 button; } Move { int16 x; int16 y; } Wheel { int16 z; } };  And this is the parsing of the command.\nI think this can be the best example of mapping between the language and the parsing.\nParsing is:\n Name Open brace Scan of identifiers until close brace For each identifier, add a type and scan for internal variables.  \ninline void declarationCommand( Parser* parser ) { // name Token token; if ( !expectToken( parser-\u0026gt;lexer, token, Token::Token_Identifier ) ) { return; } // Cache name string StringRef name = token.text; if ( !expectToken( parser-\u0026gt;lexer, token, Token::Token_OpenBrace ) ) { return; } // Add new type ast::Type\u0026amp; command_type = parser-\u0026gt;types[parser-\u0026gt;types_count++]; command_type.name = name; command_type.type = ast::Type::Types_Command; command_type.exportable = true; // Parse struct internals while ( !equalToken( parser-\u0026gt;lexer, token, Token::Token_CloseBrace ) ) { if ( token.type == Token::Token_Identifier ) { // Create a new type for each command // Add new type ast::Type\u0026amp; type = parser-\u0026gt;types[parser-\u0026gt;types_count++]; type.name = token.text; type.type = ast::Type::Types_Struct; type.exportable = false; while ( !equalToken( parser-\u0026gt;lexer, token, Token::Token_CloseBrace ) ) { if ( token.type == Token::Token_Identifier ) { declarationVariable( parser, token.text, type ); } } command_type.names.emplace_back( type.name ); command_type.types.emplace_back( \u0026amp;type ); } } }  Abstract Syntax Tree We choose to simply have data definitions, and I’ve decided that the nodes of the tree will be types.\nA type can be a primitive type, a container of variables (like a Struct in C, but without methods) enums and commands.\nCommands are just a way of showing the creation of a construct that I use and requires some boilerplate code, but I don’t want to write that code.\nIf we remember the definition of the class Type from the code before, it all boils down to a name,a list of names and optionally types.\nWith this simple definition I can express primitive types, structs and enums all in one!\nFor enums, I save the anme of the enum and in the name list all the different values. That is enough to later generate the code.\nFor structs, again the name is saved, and then the variables. A variable is a tuple of identifiers ‘type, name’. When parsing them, the type is searched in the registered ones.\nA trick here is to initialize the parser with primitive types, and then add each type (both struct and enums) when parsing them.\nCode Generation The last stage will generate the files in the language that we want, using the informations from the AST.\nThis part will literally write the code for us, the all purpose of this code.\nThe most fundamental question is: “what code do I want to generate?”.\nA simple but deep question.\nWe are trying to remove the writing of boilerplate code from or lives, so anything that you consider boilerplate and easy to automate goes here. Even if until here we wrote in C++, the final output can be any language.\nThis means that you can define data and translate it to multiple languages!\nFor our example, we will output C++ code and add UI using ImGui, similar to the Flatbuffers example I wrote before.\nLet’s see the three different construct we can output with our language.\nEnum We defined an enum as a name and a list of named values. For the simplicity of this example, we are not assigning manual values to the enum, but it is something easily changeable, and I will do it in the future. Given the enum in HDF:\nenum BlendOperation : byte { Add, Subtract, RevSubtract, Min, Max }  Which code do we want to generate ?\nWhen I write enums, I almost always need the stringed version of the values. Also I want to add a last value, Count, so that I can use it if I need to allocate anything based on the enum.\nAs a bonus, I can create a second enum with the bit shifts — called mask — for some use cases.\nAll of this will be automatically done by the code generator, starting with a simple enum!\nIn this piece of code, I will use three different streams for the different parts of the enum (enum itself, value names and mask) and combine them into the final generated file.\nAlso to note that the strings here are ‘String Ref’ — basically a string that points to the input source code and stores the length of the string, so that there is no need to allocate it newly.\nI will use a temporary buffer to null terminate it and write into the output file.\nThis will be the generated code:\nnamespace BlendOperation { enum Enum { Add, Subtract, RevSubtract, Min, Max, Count }; enum Mask { Add_mask = 1 \u0026lt;\u0026lt; 0, Subtract_mask = 1 \u0026lt;\u0026lt; 1, RevSubtract_mask = 1 \u0026lt;\u0026lt; 2, Min_mask = 1 \u0026lt;\u0026lt; 3, Max_mask = 1 \u0026lt;\u0026lt; 4, Count_mask = 1 \u0026lt;\u0026lt; 5 }; static const char* s_value_names[] = { \u0026quot;Add\u0026quot;, \u0026quot;Subtract\u0026quot;, \u0026quot;RevSubtract\u0026quot;, \u0026quot;Min\u0026quot;, \u0026quot;Max\u0026quot;, \u0026quot;Count\u0026quot; }; static const char* ToString( Enum e ) { return s_value_names[(int)e]; } } // namespace BlendOperation  The enum itself (inside a namespace), a mask and the string version for debugging purposes.\nAll generated from that one line!\nLet\u0026rsquo;s go into a step by step review of the code.\nFirst there is the initialization of some auxiliary buffers to handle dynamic strings without allocating memory.\nThese are the usages:\n Values will contain all the enum comma separated values Value_names will contain the string version of the values Value_masks will contain an optional bitmask for the values. void outputCPPEnum( CodeGenerator* code_generator, FILE* output, const ast::Type\u0026amp; type ) { // Empty enum: skip output. if ( type.names.size() == 0 ) return; code_generator-\u0026gt;string_buffer_0.clear(); code_generator-\u0026gt;string_buffer_1.clear(); code_generator-\u0026gt;string_buffer_2.clear(); StringBuffer\u0026amp; values = code_generator-\u0026gt;string_buffer_0; StringBuffer\u0026amp; value_names = code_generator-\u0026gt;string_buffer_1; StringBuffer\u0026amp; value_masks = code_generator-\u0026gt;string_buffer_2;   We start by adding the character \u0026lsquo;\u0026ldquo;\u0026rsquo; in the names - they will be C strings!\nThen we have a couple of options, just as demonstration: add mask (for the bitmask) and add max, that adds a last element to the generated enum.\n value_names.append( \u0026quot;\\\u0026quot;\u0026quot; ); bool add_max = true; bool add_mask = true;  Next step is the core: go through all the names saved in the enum ast::Type during the parsing phase, and add the literal as is in the enum, the literal in string version and optional mask.\nWe also need to take care of the enum with 1 values, they behave in a different way.\n char name_buffer[256]; // Enums with more than 1 values if ( type.names.size() \u0026gt; 1 ) { const uint32_t max_values = type.names.size() - 1; for ( uint32_t v = 0; v \u0026lt; max_values; ++v ) { if ( add_mask ) { value_masks.append( type.names[v] ); value_masks.append( \u0026quot;_mask = 1 \u0026lt;\u0026lt; \u0026quot; ); value_masks.append( _itoa( v, name_buffer, 10 ) ); value_masks.append( \u0026quot;, \u0026quot; ); } values.append( type.names[v] ); values.append( \u0026quot;, \u0026quot; ); value_names.append( type.names[v] ); value_names.append( \u0026quot;\\\u0026quot;, \\\u0026quot;\u0026quot; ); } if ( add_mask ) { value_masks.append( type.names[max_values] ); value_masks.append( \u0026quot;_mask = 1 \u0026lt;\u0026lt; \u0026quot; ); value_masks.append( _itoa( max_values, name_buffer, 10 ) ); } values.append( type.names[max_values] ); value_names.append( type.names[max_values] ); value_names.append( \u0026quot;\\\u0026quot;\u0026quot; ); } else { if ( add_mask ) { value_masks.append( type.names[0] ); value_masks.append( \u0026quot;_mask = 1 \u0026lt;\u0026lt; \u0026quot; ); value_masks.append( _itoa( 0, name_buffer, 10 ) ); } values.append( type.names[0] ); value_names.append( type.names[0] ); value_names.append( \u0026quot;\\\u0026quot;\u0026quot; ); }  After writing all the values we can add the optional max value in the output:\n if ( add_max ) { values.append( \u0026quot;, Count\u0026quot; ); value_names.append( \u0026quot;, \\\u0026quot;Count\\\u0026quot;\u0026quot; ); if ( add_mask ) { value_masks.append( \u0026quot;, Count_mask = 1 \u0026lt;\u0026lt; \u0026quot; ); value_masks.append( _itoa( type.names.size(), name_buffer, 10 ) ); } }  Until now we just saved all those values in the StringBuffers, but still not in the file.\nThe final piece of code output to file the enum with all the additional data:\n copy( type.name, name_buffer, 256 ); fprintf( output, \u0026quot;namespace %s {\\n\u0026quot;, name_buffer ); fprintf( output, \u0026quot;\\tenum Enum {\\n\u0026quot; ); fprintf( output, \u0026quot;\\t\\t%s\\n\u0026quot;, values.data ); fprintf( output, \u0026quot;\\t};\\n\u0026quot; ); // Write the mask if ( add_mask ) { fprintf( output, \u0026quot;\\n\\tenum Mask {\\n\u0026quot; ); fprintf( output, \u0026quot;\\t\\t%s\\n\u0026quot;, value_masks.data ); fprintf( output, \u0026quot;\\t};\\n\u0026quot; ); } // Write the string values fprintf( output, \u0026quot;\\n\\tstatic const char* s_value_names[] = {\\n\u0026quot; ); fprintf( output, \u0026quot;\\t\\t%s\\n\u0026quot;, value_names.data ); fprintf( output, \u0026quot;\\t};\\n\u0026quot; ); fprintf( output, \u0026quot;\\n\\tstatic const char* ToString( Enum e ) {\\n\u0026quot; ); fprintf( output, \u0026quot;\\t\\treturn s_value_names[(int)e];\\n\u0026quot; ); fprintf( output, \u0026quot;\\t}\\n\u0026quot; ); fprintf( output, \u0026quot;} // namespace %s\\n\\n\u0026quot;, name_buffer ); }  Struct Structs are the bread-and-butter of data definition. In this simple example we do not handle pointers or references, so it is pretty straight-forward, but as a start in coding generation this could already be powerful for many cases. Let’s start with a definition for our dream Data-Driven-Rendering:\n// file.hdf struct RenderTarget { uint16 width; uint16 height; float scale_x; float scale_y; TextureFormat format; }; struct RenderPass { RenderTarget rt0; };  We want to generate both the ready to use header in C++ and UI using ImGui.\nThe output for this struct will be obtained by simply iterating through all its members and, based on the type of the member, write some code.\nFor primitive types there is a translation that must be done to the C++ language — thus we saved a list of c++ primitive types keyword into the code.\nFor the UI area we will define two methods: reflectMembers, that simply adds the ImGui commands needed, and reflectUI, that embeds the members into a Window. This is done so that when starting from a root type I can create a window that let me edit its value, and recursively it can add other member’s UI if they are coming from another struct.\nThis is shown with the RenderPass struct.\nThis will be the generated code, that includes ImGui too:\n// CodeGenerated.h struct RenderTarget { uint16_t width; uint16_t height; float scale_x; float scale_y; TextureFormat::Enum format; void reflectMembers() { ImGui::InputScalar( \u0026quot;width\u0026quot;, ImGuiDataType_U16, \u0026amp;width ); ImGui::InputScalar( \u0026quot;height\u0026quot;, ImGuiDataType_U16, \u0026amp;height ); ImGui::InputScalar( \u0026quot;scale_x\u0026quot;, ImGuiDataType_Float, \u0026amp;scale_x ); ImGui::InputScalar( \u0026quot;scale_y\u0026quot;, ImGuiDataType_Float, \u0026amp;scale_y ); ImGui::Combo( \u0026quot;format\u0026quot;, (int32_t*)\u0026amp;format, TextureFormat::s_value_names, TextureFormat::Count ); } void reflectUI() { ImGui::Begin(\u0026quot;RenderTarget\u0026quot;); reflectMembers(); ImGui::End(); } }; // struct RenderTarget  Now let\u0026rsquo;s have a look at the code that will generate that.\nFirst some init steps: clear and alias the StringBuffer, allocate some char buffers on the stack, copy the StringRef into the name buffer:\n void outputCPPStruct( CodeGenerator* code_generator, FILE* output, const ast::Type\u0026amp; type ) { const char* tabs = \u0026quot;\u0026quot;; code_generator-\u0026gt;string_buffer_0.clear(); StringBuffer\u0026amp; ui_code = code_generator-\u0026gt;string_buffer_0; char name_buffer[256], member_name_buffer[256], member_type_buffer[256]; copy( type.name, name_buffer, 256 );  Next is already a powerful piece of code.\nOutputting the UI code and iterating through each member.\n if ( code_generator-\u0026gt;generate_imgui ) { ui_code.append( \u0026quot;\\n\\tvoid reflectMembers() {\\n\u0026quot; ); } fprintf( output, \u0026quot;%sstruct %s {\\n\\n\u0026quot;, tabs, name_buffer ); for ( int i = 0; i \u0026lt; type.types.size(); ++i ) { const ast::Type\u0026amp; member_type = *type.types[i]; const StringRef\u0026amp; member_name = type.names[i]; copy( member_name, member_name_buffer, 256 );  We are in the middle of the loop, and we want to check if the current member type is a primitive one, then it needs some work to do.\nFirst, output the language specific primitive type keyword (using the s_primitive_type_cpp array).\nSecond, add some ImGui code to edit the field directly.\n // Translate type name based on output language. switch ( member_type.type ) { case ast::Type::Types_Primitive: { strcpy_s( member_type_buffer, 256, s_primitive_type_cpp[member_type.primitive_type] ); fprintf( output, \u0026quot;%s\\t%s %s;\\n\u0026quot;, tabs, member_type_buffer, member_name_buffer ); if ( code_generator-\u0026gt;generate_imgui ) { switch ( member_type.primitive_type ) { case ast::Type::Primitive_Int8: case ast::Type::Primitive_Uint8: case ast::Type::Primitive_Int16: case ast::Type::Primitive_Uint16: case ast::Type::Primitive_Int32: case ast::Type::Primitive_Uint32: case ast::Type::Primitive_Int64: case ast::Type::Primitive_Uint64: case ast::Type::Primitive_Float: case ast::Type::Primitive_Double: { ui_code.append( \u0026quot;\\t\\tImGui::InputScalar( \\\u0026quot;%s\\\u0026quot;, %s, \u0026amp;%s );\\n\u0026quot;, member_name_buffer, s_primitive_type_imgui[member_type.primitive_type], member_name_buffer ); break; } case ast::Type::Primitive_Bool: { ui_code.append( \u0026quot;\\t\\tImGui::Checkbox( \\\u0026quot;%s\\\u0026quot;, \u0026amp;%s );\\n\u0026quot;, member_name_buffer, member_name_buffer ); break; } } } break; }  In case of a struct as a member, use the typename as is and call the \u0026lsquo;reflectMembers\u0026rsquo; method for the UI generation:\n case ast::Type::Types_Struct: { copy( member_type.name, member_type_buffer, 256 ); fprintf( output, \u0026quot;%s\\t%s %s;\\n\u0026quot;, tabs, member_type_buffer, member_name_buffer ); if ( code_generator-\u0026gt;generate_imgui ) { ui_code.append( \u0026quot;\\t\\tImGui::Text(\\\u0026quot;%s\\\u0026quot;);\\n\u0026quot;, member_name_buffer ); ui_code.append( \u0026quot;\\t\\t%s.reflectMembers();\\n\u0026quot;, member_name_buffer ); } break; }  For enums use the format namespace::Enum that comes with the generated code (and can be anything else) and add a Combo for ImGui. The combo is using the string array generated previously! This is powerful!\n case ast::Type::Types_Enum: { copy( member_type.name, member_type_buffer, 256 ); fprintf( output, \u0026quot;%s\\t%s::Enum %s;\\n\u0026quot;, tabs, member_type_buffer, member_name_buffer ); if ( code_generator-\u0026gt;generate_imgui ) { ui_code.append( \u0026quot;\\t\\tImGui::Combo( \\\u0026quot;%s\\\u0026quot;, (int32_t*)\u0026amp;%s, %s::s_value_names, %s::Count );\\n\u0026quot;, member_name_buffer, member_name_buffer, member_type_buffer, member_type_buffer ); } break; }  To finish up simlpy add the reflectUI method, that embed the members reflection in a window and finish.\n default: { break; } } } ui_code.append( \u0026quot;\\t}\u0026quot; ); ui_code.append( \u0026quot;\\n\\n\\tvoid reflectUI() {\\n\\t\\tImGui::Begin(\\\u0026quot;%s\\\u0026quot;);\\n\\t\\treflectMembers();\\n\\t\\tImGui::End();\\n\\t}\\n\u0026quot;, name_buffer ); fprintf( output, \u0026quot;%s\\n\u0026quot;, ui_code.data ); fprintf( output, \u0026quot;\\n%s}; // struct %s\\n\\n\u0026quot;, tabs, name_buffer ); }  Command I wanted to include an example of something that does not exist in any language, but it shows the power of removing boilerplate code.\nI define commands as little structs with a type used anytime I need to do some command parsing, normally from a ring buffer.\nThe command should have an enum with all the types already, and each struct should have its type assigned. The type is normally used to cycle through the commands and do something accordingly.\nIt will output structs because of the need to allocate them in the ring buffer, thus must be simple.\nFirst let\u0026rsquo;s see the HDF file. The example are window events commands:\ncommand WindowEvents { Click { int16 x; int16 y; int16 button; } Move { int16 x; int16 y; } Wheel { int16 z; } };  The generated code will be:\nnamespace WindowEvents { enum Type { Type_Click, Type_Move, Type_Wheel }; struct Click { int16_t x; int16_t y; int16_t button; static Type GetType() { return Type_Click; } }; // struct Wheel struct Move { int16_t x; int16_t y; static Type GetType() { return Type_Move; } }; // struct Wheel struct Wheel { int16_t z; static Type GetType() { return Type_Wheel; } }; // struct Wheel }; // namespace WindowEvents  And finally the C++ code that generates the output.\nThe output starts with an enum with all the types, that I normally use to switch commands:\nvoid outputCPPCommand( CodeGenerator* code_generator, FILE* output, const ast::Type\u0026amp; type ) { char name_buffer[256], member_name_buffer[256], member_type_buffer[256]; copy( type.name, name_buffer, 256 ); fprintf( output, \u0026quot;namespace %s {\\n\u0026quot;, name_buffer ); // Add enum with all types fprintf( output, \u0026quot;\\tenum Type {\\n\u0026quot; ); fprintf( output, \u0026quot;\\t\\t\u0026quot; ); for ( int i = 0; i \u0026lt; type.types.size() - 1; ++i ) { const ast::Type\u0026amp; command_type = *type.types[i]; copy( command_type.name, name_buffer, 256 ); fprintf( output, \u0026quot;Type_%s, \u0026quot;, name_buffer ); } const ast::Type* last_type = type.types[type.types.size() - 1]; copy( last_type-\u0026gt;name, name_buffer, 256 ); fprintf( output, \u0026quot;Type_%s\u0026quot;, name_buffer ); fprintf( output, \u0026quot;\\n\\t};\\n\\n\u0026quot; );  Then we output all the command structs (like Click, Move, \u0026hellip;).\nFor each command type we output a struct with all its members. This is similar to the output of the structs:\n const char* tabs = \u0026quot;\\t\u0026quot;; for ( int i = 0; i \u0026lt; type.types.size(); ++i ) { const ast::Type\u0026amp; command_type = *type.types[i]; copy( command_type.name, member_type_buffer, 256 ); fprintf( output, \u0026quot;%sstruct %s {\\n\\n\u0026quot;, tabs, member_type_buffer ); for ( int i = 0; i \u0026lt; command_type.types.size(); ++i ) { const ast::Type\u0026amp; member_type = *command_type.types[i]; const StringRef\u0026amp; member_name = command_type.names[i]; copy( member_name, member_name_buffer, 256 ); // Translate type name based on output language. switch ( member_type.type ) { case ast::Type::Types_Primitive: { strcpy_s( member_type_buffer, 256, s_primitive_type_cpp[member_type.primitive_type] ); fprintf( output, \u0026quot;%s\\t%s %s;\\n\u0026quot;, tabs, member_type_buffer, member_name_buffer ); break; } case ast::Type::Types_Struct: { copy( member_type.name, member_type_buffer, 256 ); fprintf( output, \u0026quot;%s\\t%s %s;\\n\u0026quot;, tabs, member_type_buffer, member_name_buffer ); break; } case ast::Type::Types_Enum: { copy( member_type.name, member_type_buffer, 256 ); fprintf( output, \u0026quot;%s\\t%s::Enum %s;\\n\u0026quot;, tabs, member_type_buffer, member_name_buffer ); break; } default: { break; } } } copy( command_type.name, member_type_buffer, 256 ); fprintf( output, \u0026quot;\\n%s\\tstatic Type GetType() { return Type_%s; }\\n\u0026quot;, tabs, member_type_buffer ); fprintf( output, \u0026quot;\\n%s}; // struct %s\\n\\n\u0026quot;, tabs, name_buffer ); } copy( type.name, name_buffer, 256 ); fprintf( output, \u0026quot;}; // namespace %s\\n\\n\u0026quot;, name_buffer ); }  Conclusions We learnt how to write a complete Code Generator, an incredible tool that can speed up the development if used correctly and remove most boilerplate code possible.\nThe usage of the command keyword was an example of something I use and I don’t want to write code, something that is custom enough and hopefully will give you more ideas on how you can break free from languages constriction when you write…your own language!\nIn the quest for data-driven rendering, the next step will be to use the knowledge from code generation to create a shader effect language, that can generate both CPU and GPU code for you.\nThis article is the longest and more code-heavy I have ever written. There are many concepts that I am beginning to be familiar with, but still not so used to.\nSo please comment, give feedback, share! Thank you for reading!\n","date":1564267563,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1565131563,"objectID":"3b9e1a648d0f65843a8cdecb32355e6c","permalink":"/post/writing_a_simple_code_generator/","publishdate":"2019-07-27T18:46:03-04:00","relpermalink":"/post/writing_a_simple_code_generator/","section":"post","summary":"UI using ImGUI, SDL and the code generated with this article.   Motivation Following my previous article about Flatbuffers and data reflection the quest for Data-Driven Rendering continues!\nIn this article I want to show how to write a very simple code-generator to help you automate writing of code in any language.\nThe code is here:\nhttps://github.com/JorenJoestar/DataDrivenRendering\nThere is a balance that constantly needs to be found between code and data, and having a code-generator in my opinion helps tremendously in focus on the code that is necessary to be written.","tags":[],"title":"Writing a simple Code Generator","type":"post"},{"authors":[],"categories":[],"content":"   Some of the UI for the Hydra NES emulator, using ImGUI.   Writing an emulator is an incredibly fun learning experience.\nIt is an exquisite exercise in reverse-engineering from both documentation and code.\nIn this post I want to share some tips on how and where to start based on my experience on the NES emulator I am writing.\nInformation The gathering of information is the most important (and hard!) process that will live through all the writing process.\nLuckily for use there are many websites that are coming to rescue us:\nhttps://wiki.nesdev.com/w/index.php/NES_reference_guide\nhttp://forums.nesdev.com/\nhttp://obelisk.me.uk/6502/reference.html\nhttp://www.oxyron.de/html/opcodes02.html\nIt is paramount to create a list of websites and resources (maybe through some notes, like in Evernote or such) about different topics regarding the hardware to be emulated.\nHaving a central hub is powerful and counteract the sparseness of the different informations (some in txt files, different websites, forum blogposts, …).\nI can’t stress enough how important it is.\nLuckily for us the amazing NesDev Wiki is the hub you need!\nAlmost every possible information you need is there.\nArchitecture Next step is to understand the architecture.\nWrite diagrams, take notes, search for the relationships of the component.\nWhat does every hardware component do ?\nWhat can that specific hardware piece access to ?\nAs you will see, writing the emulator is an iterative process of improving each component until you have something that works very well, and then refine for an infinite amount of time.\nOn a very basic level, there should be a CPU, some form of GPU (PPU, Picture Processing Unit), some audio chip, some input peripheral and cartridge/disc/rom.\nNES architecture The NES is a beautiful machine equipped with the following:\nCPU : Ricoh RP2A03 (NTSC) / RP2A07 (PAL) 8 bit processor that contains both CPU and APU (audio) hardware. The addresses are 16 bit, but the data is 8. It contains only specific registers: 2 indices, accumulator, stack pointer, program counter and status.\nPPU : Ricoh RP2C02 (NTSC) / RP2C07 (PAL) This is what today would be called GPU. It outputs to a 256x240 pixels buffer, it has 2kib or RAM, 32 bytes for palette RAM and 288 bytes for sprite RAM. The PPU is tile based and it takes 8 PPU cycles to load a line of a background tile. Sprites are sent through DMA and background is filled during Vertical Blank state normally. A frame lasts more scanline that the one visible, so that the game can upload data to the PPU when not rendering.\nAPU : Ricoh RP2A03 (NTSC) / RP2A07 (PAL) (Contained in the CPU itself.) The sound is analogic and it comes from 5 different channels: 2 pulse, 1 triangle, 1 noise and 1 DMC. All the channels aside from the DMC create signals that are combined to output the sounds and music. The DMC loads samples using the DMA.\nCartridge/Mappers : This is a very unique topic strict to the NES as far as I know. Cartridges had unique hardware and they were used to swap banks of memory in realtime to access different parts of the cartridge. There are hundred of mappers that have unique behaviours! The biggest gist of the mappers is how they switch banks: by WRITING to the address where the execution code is it triggers the bank-switching logic. There can be internal batteries and working RAMs too, but they are very rare.\nMemory mapped I/O The different hardware access using ‘memory mapped I/O’, that is a way of saying that when you read or write to a specific address it could be memory or it could be an hardware-component.\nExamples: reading from address 0x4016 gives you the gamepad status, while reading from 0x1000 reads from the CPU ram.\nHaving clear these accesses will help in understanding even better the machine.\nBoth CPU and PPU have different memory maps. Let\u0026rsquo;s see them, it will help in understanding the internal of the NES better.\nCPU Memory Map    The CPU can access basically every hardware component in the NES.\nPPU, APU, gamepads, both read and write.\nIt reads the ROM part of a cartridge (called PRG) and executes its instructions.\nThrough PPU registers it can instruct the PPU to read graphical informations from the CHR part of the cartridge.\nIt can upload sprites on the PPU Sprite Memory through DMA, upload data to the APU, or manage its internal RAM.\nFrom the source code, this is a working example of CPU Reading method:\nuint8 Nes::MemoryController::CpuRead( uint16 address ) { if ( address \u0026lt; 0x2000 ) { return cpu-\u0026gt;ram[address \u0026amp; 0x7FF]; } else if ( address \u0026lt; 0x4000 ) { return ppu-\u0026gt;CpuRead( address ); } else if ( address \u0026lt; 0x4014 ) { return apu-\u0026gt;CpuRead( address ); } else if ( address \u0026gt;= 0x4018 ) { return mapper-\u0026gt;PrgRead( address ); } switch ( address ) { case 0x4015: { return apu-\u0026gt;ReadStatus(); break; } case 0x4016: { return controllers-\u0026gt;ReadState(); break; } case 0x4017: { return 0x40; break; } } return 0; }  And CPU Write:\nvoid Nes::MemoryController::CpuWrite( uint16 address, uint8 data ) { if ( address \u0026lt; 0x2000 ) { cpu-\u0026gt;ram[address \u0026amp; 0x7FF] = data; } else if ( address \u0026lt; 0x4000 ) { ppu-\u0026gt;CpuWrite( address, data ); return; } else if ( address \u0026lt; 0x4014 ) { return apu-\u0026gt;CpuWrite( address, data ); } else if ( address \u0026gt;= 0x4018 ) { mapper-\u0026gt;PrgWrite( address, data ); return; } switch ( address ) { // Sprite DMA case 0x4014: { cpu-\u0026gt;ExecuteSpriteDMA( data ); return; break; } case 0x4015: case 0x4017: { apu-\u0026gt;CpuWrite( address, data ); return; break; } case 0x4016: { controllers-\u0026gt;WriteState( data ); return; break; } } }  The pattern is always the same: check the address of the instruction and choose which hardware component to interact with.\nHopefully its clear that based on the address different components can be accessed. Let\u0026rsquo;s have a look at the PPU too.\nPPU Memory Map    Similar to the CPU, reading and writing on the PPU access different components, even though they are far less.\nThe PPU either accesses its 2 rams (palette and nametable, normally from the CPU) or reads the CHR (that is the graphical data stored in the cartridge) memory.\nReading:\nuint8 Nes::MemoryController::PpuRead( uint16 address ) { address \u0026amp;= 0X3FFF; if ( address \u0026lt;= 0x1FFF ) { return mapper-\u0026gt;ChrRead( address ); } else if ( address \u0026lt;= 0x3EFF ) { return ppu-\u0026gt;nametableRam[NameTableMirroring( address, mapper-\u0026gt;mirroring )]; } else if ( address \u0026lt;= 0x3FFF ) { // Palette mirroring is handled in the write code. return ppu-\u0026gt;paletteRam[address \u0026amp; 0x1F] \u0026amp; ((ppu-\u0026gt;mask \u0026amp; Nes::Ppu::MaskFlag_GreyScale ? 0x30 : 0xFF)); } return 0; }  On the writing side, there the code shows the intricancy of emulation. When writing to the paletter ram, there is a mirroring mechanism happening in the hardware that is emulated with a lookup table. Something to look out to: writing to CHR is 99% of the time useless, unless there is an additional RAM in the cartdige.\nvoid Nes::MemoryController::PpuWrite( uint16 address, uint8 data ) { address \u0026amp;= 0X3FFF; if ( address \u0026lt;= 0x1FFF ) { mapper-\u0026gt;ChrWrite( address, data ); return; } else if ( address \u0026lt;= 0x3EFF ) { ppu-\u0026gt;nametableRam[NameTableMirroring( address, mapper-\u0026gt;mirroring )] = data; return; } else if ( address \u0026lt;= 0x3FFF ) { static uint8 const palette_write_mirror[0x20] = { 0x10, 0x01, 0x02, 0x03, 0x14, 0x05, 0x06, 0x07, 0x18, 0x09, 0x0A, 0x0B, 0x1C, 0x0D, 0x0E, 0x0F, 0x00, 0x11, 0x12, 0x13, 0x04, 0x15, 0x16, 0x17, 0x08, 0x19, 0x1A, 0x1B, 0x0C, 0x1D, 0x1E, 0x1F }; ppu-\u0026gt;paletteRam[palette_write_mirror[address \u0026amp; 0x1F]] = data; return; } }  Takeaways I created the memory controller as the main dispatcher of data between hardware components, to separate the duties better. We can see the following relationships based on that:\n CPU can access PPU, APU, controllers and cartridge (PRG) PPU can access screen, its own rams and cartridge (CHR) memory controller is the hub that connects everything  I am not sure this is the best emulator architecture, but that is what I figured out.\nTest roms A fundamental approach to create a robust emulator is to have some tests to rely on.\nSadly it is not common for all hardware, but again the NES provide plenty of roms that tests almost every aspect of your emulator!\nIt quickly becomes a test-driven development.\nNES test roms link\nFind roms, read the source code and try to understand what they are doing and why.\nCoding start If you are writing your first emulator, I suggest to focus mostly on the emulation part.\nWhat do I mean by that ?\nAvoid trying too many things at once!\nFocus your energies towards the emulation.\nUse libraries that are reliable and simple and that you know.\nGLFW, SDL2, etc are your friends here.\nYou want to eliminate most unknowns unknowns before hand.\nOf course, if you are brave enough, you can also write an emulator in a new language.\nBut for me, I preferred to concentrate on the emulation side first, in C++, using my core library, especially knowing that I could dedicate some night-time here and there, No surprises (not really true, still some happened!).\nI will possibly port the emulator to use SDL if needed, but right now the emulation code is the most important.\nThis is the mantra that helped me concentrate only on the emulation code. Again, writing-wise I am not happy about the code quality. But what I am learning from different perspectives is invaluable!\nNES coding start The quintessential basic steps to start a NES emulator coding are:\n Write CPU basics (fetch/decode/execute loop, registers) Basic memory bus (read/write to/from memory and registers) Load a rom and start executing instruction step by step.  It is already a lot, and it will require to read multiple times the different wiki pages and forum posts.\nFor a typical console, the main loop (simplified) can be something like this:\nvoid CpuTick() { uint8_t opcode = Read(program_counter++); uint8_t operand = FetchOperand(opcode); ExecuteOpcode(opcode, operand); } void ExecuteFrame() { uint32_t cycles_per_frame = … while (cycles_per_frame — ) { CpuTick(); } }  To jumpstart your NES emulator you can use the majestic rom nestest.nes and its log file: it gives you a test of all instructions of the CPU and prints the status of the CPU after each one.\nAlso it does not require any PPU rendering: compare the status of your CPU with the text file line by line and its done!\nYou can see some ugly but useful code in MainState::ExecuteCpuTest in my emulator for an idea.\nA line from the nestest.log file looks like this:\n// C000 4C F5 C5 JMP $C5F5 A:00 X:00 Y:00 P:24 SP:FD PPU: 0, 0 CYC:7  it gives you the ProgramCounter (C000), byte code (1, 2 or 3 bytes depending on the instructions), human-readable-instruction (JMP) , the CPU register contents (A, X, Y, P, SP) and the theorethical PPU scanline, pixel and clock cycle.\nThere are two interesting points:\n The ProgramCounter before execution should be set to C000 for this rom only and only when logging. The CPU cycles STARTS at 7. In a power-up/reset method there is some work done BEFORE executing any code. This is needed only if you want to have a precise cycle-to-cycle comparison.  You can create a simple test method like this:\nvoid TestEmulatorCPU() { Reset(); while(true) { CpuTick(); CompareCpuStatusWithLog(); } }  and catch the problems in your CPU instructions implementation!\nConclusion This is a little help in understanding how to start with an emulator.\nIt is a beautiful journey, but it is full of trial and errors.\nI am myself far from over with my emulator, and also far from being happy on HOW I write the emulator itself.\nThere are emulators of much more complex machines out there (almost every machine you can imagine!) and it blows my mind to know there are people that can emulate such complex hardware.\nThe ideal situation would be to being able of not being lost in visual emulation of the circuitry, but for now that is out of my league.\nI am thinking of creating some a series of videos and code associated starting from scratch, if anyone is interested. Please leave a comment/feedback on the article, the source code, anything!\nI hope it will help.\n","date":1564267535,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564267535,"objectID":"33334c3b94bfe395ca48dde1b71dc142","permalink":"/post/emulation_where_to_start/","publishdate":"2019-07-27T18:45:35-04:00","relpermalink":"/post/emulation_where_to_start/","section":"post","summary":"Some of the UI for the Hydra NES emulator, using ImGUI.   Writing an emulator is an incredibly fun learning experience.\nIt is an exquisite exercise in reverse-engineering from both documentation and code.\nIn this post I want to share some tips on how and where to start based on my experience on the NES emulator I am writing.\nInformation The gathering of information is the most important (and hard!","tags":[],"title":"Emulation: where to start? A use case.","type":"post"},{"authors":[],"categories":[],"content":"   Auto generated UI from Flatbuffers files.   Motivation Finding a good balance between code and data in Rendering.\nWhat is the necessary code that should be written ?\nWhy ?\nIn rendering many areas can be described in a fast and robust way using data.\nA pipeline (in D3D12/Vulkan lingo) for example is a collection of different states: depth stencil, alpha blend, rasterizer, shaders, etc.\nAll those state can be hard-coded or defined in data.\nMoving them to data can help with the visibility of them, that instead of being buried somewhere into the code can be retrieved before even running the application.\nAs a bigger-scope example, a frame-graph can be implicitly defined inside the code, if different areas, or in data.\nRecent posts about it started raising attention to the problem, especially after the introduction of lower-level APIs like D3D12 and Vulkan and their resource barriers.\nI’ve personally used something like json (xml back in the day) since 2009, after asking myself the very silly question:\n what is the biggest dependency in rendering?\nRender Targets!\n Since then I saw only in the Codemasters postprocess system (since Dirt 2) a similar approach, and have never being able to advocate towards it.\nThe only full use case I have is my personal indie game (a full deferred rendering pipeline with many different rendering needs) all defined in a json file (render_pipeline.json).\nAnyway, a couple of examples of this data-driven mentality can be found here:\n  FrameGraph: Extensible Rendering Architecture in Frostbite  from Electronic Arts / DICE \nhttp://bitsquid.blogspot.com/2017/03/stingray-renderer-walkthrough-7-data.html\nI chose to see what is a good way of describing low-level rendering resources, the bricks towards data-driven rendering.\nI’ve already tried defining them in a json file, but wanted something more direct — something I can copy easily with minimal parsing.\nI found 4 possible approaches:\n Custom data language Already existing data language Json (already used) Hard-coding everything  In this experiment I’ve chosen Flatbuffers for the easy of use, the good performances and the feature set that seems complete.\nAs an exercise, I wanted to create some UI based on the data coming from Flatbuffers without having to write too much code.\nFlatbuffers Flatbuffers is a serialization library developer by Google used by many companies.\nhttps://google.github.io/flatbuffers/\nCompared to Protocol Buffers (still developed by Google) it tries to go towards a very simple parsing/unpacking (actually ABSENT in Flatbuffers, so much faster to read/write) and serialization speed.\nFlatbuffers is mainly a compiler that accepts .fbs (FlatBuffers Schema) files and can generate code for serialization purposes.\nThe advantage is that it automatically generates the parsing files in the language you prefer (C++, Java, C#, Go, C, Lua, Javascript, Rust) without you needing to write the always tedious serialize/deserialize methods.\nIt is largely based on either simple c-structs or tables with offsets for more complex object.\nThe objective here will be to create a schema file, define a couple of resources (like textures) and use those to automatically generate UI.\nI will be using the SDL + ImGUI sample from the amazing ImGUI as a base.\nThe flow will be the following:\n Write schema files Generate reflection informations Parse schemas Generate UI  Schema Files Let’s write our first schema file. A bigger version (that I am using for my low-level renderer) is included in the github repository.\nnamespace rendering; enum TextureFormat : ushort { UNKNOWN, R32G32B32A32_TYPELESS, R32G32B32A32_FLOAT, R32G32B32A32_UINT, R32G32B32A32_SINT, R32G32B32_TYPELESS, R32G32B32_FLOAT, R32G32B32_UINT, R32G32B32_SINT, R16G16B16A16_TYPELESS, R16G16B16A16_FLOAT, R16G16B16A16_UNORM, R16G16B16A16_UINT, R16G16B16A16_SNORM, R16G16B16A16_SINT, R32G32_TYPELESS, R32G32_FLOAT, R32G32_UINT, R32G32_SINT, R10G10B10A2_TYPELESS, R10G10B10A2_UNORM, R10G10B10A2_UINT, R11G11B10_FLOAT, R8G8B8A8_TYPELESS, R8G8B8A8_UNORM, R8G8B8A8_UNORM_SRGB, R8G8B8A8_UINT, R8G8B8A8_SNORM, R8G8B8A8_SINT, R16G16_TYPELESS, R16G16_FLOAT, R16G16_UNORM, R16G16_UINT, R16G16_SNORM, R16G16_SINT, R32_TYPELESS, R32_FLOAT, R32_UINT, R32_SINT, R8G8_TYPELESS, R8G8_UNORM, R8G8_UINT, R8G8_SNORM, R8G8_SINT, R16_TYPELESS, R16_FLOAT, R16_UNORM, R16_UINT, R16_SNORM, R16_SINT, R8_TYPELESS, R8_UNORM, R8_UINT, R8_SNORM, R8_SINT, R9G9B9E5_SHAREDEXP, D32_FLOAT_S8X24_UINT, D32_FLOAT, D24_UNORM_S8_UINT, D24_UNORM_X8_UINT, D16_UNORM, S8_UINT, BC1_TYPELESS, BC1_UNORM, BC1_UNORM_SRGB, BC2_TYPELESS, BC2_UNORM, BC2_UNORM_SRGB, BC3_TYPELESS, BC3_UNORM, BC3_UNORM_SRGB, BC4_TYPELESS, BC4_UNORM, BC4_SNORM, BC5_TYPELESS, BC5_UNORM, BC5_SNORM, B5G6R5_UNORM, B5G5R5A1_UNORM, B8G8R8A8_UNORM, B8G8R8X8_UNORM, R10G10B10_XR_BIAS_A2_UNORM, B8G8R8A8_TYPELESS, B8G8R8A8_UNORM_SRGB, B8G8R8X8_TYPELESS, B8G8R8X8_UNORM_SRGB, BC6H_TYPELESS, BC6H_UF16, BC6H_SF16, BC7_TYPELESS, BC7_UNORM, BC7_UNORM_SRGB, FORCE_UINT } attribute \u0026quot;ui\u0026quot;; struct RenderTarget { width : ushort (ui: \u0026quot;min:1, max:16384\u0026quot;); height : ushort; scale_x : float; scale_y : float; format : TextureFormat; }  There are few things here to discuss.\n Enums. Flatbuffers can generate enums with string version of each values and conversions between enum and string. Struct. It is exactly like C/C++: a simple struct that can be memcopied. Different than a Table (that can point to other structs and Tables). Attributes. This can be used to define custom parsable attributes linked to a member of a struct/table. They can be used, for example, to drive the UI generation.  Generating Reflection Informations After we generated the schema file, we can serialize it and load/save it from disk. But we need reflection data to be able to automatically generate the UI we need! There are two main reflection mechanisms in Flatbuffers: mini-reflection and full-reflection. We will use both to generate a UI using ImGUI and see the differences.\nMini-Reflection This is the simplest of the two and works by generating an additional header file for each .fbs file we use. The command line is the following:\nflatc --cpp RenderDefinitions.fbs --reflect-names  This will generate the RenderDefinitions_Generated.h file that must be included in your application and has the downside of needing you to recompile every time you change the data.\nAlso, and this is the biggest downside, I could not find any way to parse custom per-member attributes.\nI hope I am wrong, but could not find any documentation on the topic: everything seems to point towards the full reflection mechanism.\nSo why bothering with the mini-reflection ?\nMini-reflection generates code, and this became useful for one of the most tedious C/C++ code to write: enums!\nI can’t count how many times I wrote an enum, I wanted the string with the same value for it (for example to read from a json file and get the proper enum value) and every time an enum is changed is painful.\nSo a lesson from the mini-reflection is to have a code-generator for enums for C/C++, and I will show an example soon in another article.\nBack to the enums, Flatbuffers generates:\n Enum Name array Value array Enum to name method  A nice property of the generated code for the enum is that it is easy to copy-paste in any c++ file — no Flatbuffers involved!\nThis is my first choice now when I want to write an enum in any c++ application.\nFull-reflection This is the most used (or at least documented) form of reflection in Flatbuffers.\nIt use a very elegant solution, totally data-driven: it reads a reflection schema file that can parse…ANY other schema!\nThis very Inception-esque mechanism gives the full access to all the types, including Attributes.\nBy executing this command:\nflatc.exe -b --schema reflection.fbs RenderDefinitions.fbs  the RenderDefinitions.bfbs (binary fbs) file is generated.\nThis is the file that needs to be read to fully reflect the types inside the .fbs file. The order of operations is the following:\n Generate a binary fbs with flatc (with the command line shown) Load the bfbs file generated Load the schema from the bfbs Reflect  The fbfs file contains all the informations from the schema: types, enums, attributes.\nParsing schemas and Generating UI For both reflection mechanisms the objective is the same: given a type (RenderTarget) generate an editor that can edit properties and potentially load/save them.\nMini-Reflection The UI generation is pretty straightforward with mini-reflection.\nEach type defined in the .fbs file contains a type_name-TypeTable() method that gives accent to a TypeTable.\nThis contains a list of per-member type, name and default values.\nWhat is really missing here is the attributes, that could be used to generate custom UI in a more specific way (eg. adding a min/max/step to a slider).\nThe code doing this is in the github sample.\nThere are few interesting points here.\nImGui usability In order to use ImGui to modify a struct, I had to create the class FlatBuffersReflectionTable to instantiate a struct with a similar layout than the Flatbuffers struct.\nThis is annoying but I could not find a way around different than this.\nWith this in-place, a ImGUI slider can point to a memory area that can be used to save/load the data. Let’s begin by retrieving the TypeTable:\nconst TypeTable* rt_table = rendering::RenderTargetTypeTable();  The TypeTable is what is included in the generated header and contains the reflection informations. Listing the members and their type is pretty straight-forward:\nfor ( uint32_t i = 0; i \u0026lt; type_table.num_elems; ++i ) { const flatbuffers::TypeCode\u0026amp; type_code = type_table.type_codes[i]; ImGui::Text( \u0026quot;%s: %s\u0026quot;, type_table.names[i], flatbuffers::ElementaryTypeNames()[type_code.base_type] ); sprintf_s( s_string_buffer, 128, \u0026quot;%s\u0026quot;, type_table.names[i] ); if ( type_code.sequence_ref == 0 ) { if ( type_table.type_refs[type_code.sequence_ref] ) { const flatbuffers::TypeTable* enum_type = type_table.type_refs[type_code.sequence_ref](); ImGui::Combo( s_string_buffer, (int32_t*)reflection_table.GetData( i ), enum_type-\u0026gt;names, enum_type-\u0026gt;num_elems ); } } else { switch ( type_code.base_type ) { case flatbuffers::ET_BOOL: { ImGui::Checkbox( s_string_buffer, (bool*)reflection_table.GetData( i ) ); break; } } } }  The interesting parts:\nflatbuffers::TypeCode* contains the reflection information for a type.\nGiven a type_code, sequence_ref can be used to check if it is an enum, pointer, or primitive type. In this case is used for enum, showing a combo with all the selectable values.\nBase_type contains instead the primitive type. In this example a bool can be mapped to a checkbox. This uses the custom reflection_table class to have a memory area for ImGUI.\nFor mini-reflection this is basically it.\nFull-reflection Code here is longer but it follows the 4 steps highlighted before.\nAll the code is inside the ReflectUIFull method.\nHere the binary fbs file and its corresponding schema are loaded.\n// 1. Obtain the schema from the binary fbs generated std::string bfbsfile; flatbuffers::LoadFile(\u0026quot;..\\\\data\\\\RenderDefinitions.bfbs\u0026quot;, true, \u0026amp;bfbsfile ); const reflection::Schema\u0026amp; schema = *reflection::GetSchema( bfbsfile.c_str() );  The schema can be used to list the types:\n// 2. List all the types present in the fbs. auto types = schema.objects(); for ( size_t i = 0; i \u0026lt; types-\u0026gt;Length(); i++ ) { const reflection::Object* type = types-\u0026gt;Get( i ); ImGui::Text( \u0026quot; %s\u0026quot;, type-\u0026gt;name()-\u0026gt;c_str() ); }  (Using the auto here because I am lazy. The type is some multiple templates of offsets…) We can also list all the enums:\nauto enums = schema.enums(); for ( size_t i = 0; i \u0026lt; enums-\u0026gt;Length(); i++ ) { const reflection::Enum* enum_ = enums-\u0026gt;Get( i ); ImGui::Text( \u0026quot; %s\u0026quot;, enum_-\u0026gt;name()-\u0026gt;c_str() ); }  A problem I found (with a workaround in the code) is that enums do not have an easily to access array of string values.\nSo I generated one for the sake of example, but I am far from happy with the solution!\nGoing forward, we can get the type we want to reflect (notice the full namespace.type):\nauto render_target_type = types-\u0026gt;LookupByKey( \u0026quot;rendering.RenderTarget\u0026quot; ); and begin the work on each field: auto fields = render_target_type-\u0026gt;fields(); if ( fields ) { // 5.1. List all the fields for ( size_t i = 0; i \u0026lt; fields-\u0026gt;Length(); i++ ) { auto field = fields-\u0026gt;Get( i ); ...  and the UI can be generated.\nFor each field, the primitive type can be accessed with the following:\nreflection::BaseType field_base_type = field-\u0026gt;type()-\u0026gt;base_type();  and again, I found a workaround to know if a type is primitive or an enum.\nLast piece of the puzzle: attributes!\nauto field_attributes = field-\u0026gt;attributes(); if ( field_attributes ) { auto ui = field_attributes-\u0026gt;LookupByKey( \u0026quot;ui\u0026quot; ); if ( ui ) { ImGui::Text(\u0026quot;UI attribute: %s\u0026quot;, ui-\u0026gt;value()-\u0026gt;c_str()); } }  These can be parsed as strings and can be used to drive UI code (like a slider with min, max and steps).\nConclusions In the end, I’ve managed to generate UI based on a type without too much code.\nThere was some reverse-engineering to do because I could not find proper documentation (I possibly miss some links to a in-depth example of reflection!) but nothing major.\nThe full source code:\n(https://github.com/JorenJoestar/FlatbuffersReflection)\n","date":1564141046,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564141046,"objectID":"afba9f8775578a3383382dfbe5a617c4","permalink":"/post/flatbuffers_reflection_data_driven_rendering/","publishdate":"2019-07-26T07:37:26-04:00","relpermalink":"/post/flatbuffers_reflection_data_driven_rendering/","section":"post","summary":"Auto generated UI from Flatbuffers files.   Motivation Finding a good balance between code and data in Rendering.\nWhat is the necessary code that should be written ?\nWhy ?\nIn rendering many areas can be described in a fast and robust way using data.\nA pipeline (in D3D12/Vulkan lingo) for example is a collection of different states: depth stencil, alpha blend, rasterizer, shaders, etc.\nAll those state can be hard-coded or defined in data.","tags":[],"title":"Flatbuffers, Reflection and Data-Driven Rendering","type":"post"},{"authors":[],"categories":[],"content":"   Legend of Zelda emulated plus debugging windows.   Hello everyone!\nToday I release the source code of my bare-bone NES emulator, written in C++.\nI had the idea to write an emulator of one of my favorite console (after the SNES) years ago, and started in 2015 to write the first code (actually in 2008, but it was too daunting even to start). Then I concentrated on my other big project (still ongoing) and left all the NES code on a side. Years passed and finally last winter I decided to give it a go to arrive at a ‘usable’ emulator level and release the source code.\nHere it is! (https://github.com/JorenJoestar/HydraNes)\nMotivation Main motivation both to write and to share this code is knowledge.\nI shamelessly wrote bad code just with the purpose of seeing something on screen as fast as I could. And I am very honest about that: not happy for the form, but happy for the knowledge I gained! Also, I think that this code is compact enough to be followed and to understand the basics of NES emulation coding.\nThe code The NES code lives in the Nes.h/.cpp pair of files. The APU is implemented using Blargg’s implementation: when I’ll have other time I will attemp to finish my own implementation, but for now it is ok like that.\nThe flow is the following:\n NES is initialized After loading a rom (from the Cartridge window) the mapper will be selected and memory copied to local buffers. CPU starts its continuous emulation. CPU will execute until a frame is produced. This is checked by the PPU frame changing. PPU execution is bound to memory accesses, both read and write. Each CPU memory access corresponds to 3 PPU cycles (in NTSC, the only region emulated). After the frame is ended the APU emulation is advanced.  Interesting spots There are different areas of the code that are interesting, but I would like to highlight some.\nCpu::Step() This is where all the CPU instructions are executed. I opted for a macro based approach instead of tables of function pointers.\nFor each cpu cycle:\n Fetch the instruction opcode Calculate the operand address (called ‘effectiveAddress’) Execute the operation  All the operations and addressing modes are in the Nes.h file. Addressing modes are the way the NES gets its operand for each operation. Operations are the instruction themselves — using those operands.\nPpu::Step() PPU by itself is the most difficult part to emulate (APU is easier on the channels, but harder on the mix and signal generation!).\nI will make a post about that soon, but in the meantime here the code is and implements the behaviours described here:\nhttps://wiki.nesdev.com/w/index.php/File:Ntsc_timing.png\nThe PPU draws in tiles of 8x8 pixels, so for each pixels created on the screen there will be a gathering of all the data necessary to calculate the final color.\nThe rendering is divided in background and sprites.\nBackground is just 8x8 pixel per tile choosen from the nametable (a screen table of which tiles are visible) and sprites are either 8x8 or 8x16 rectangles coming from a different memory area (uploaded using DMA).\nThere are many quirks and uniqueness about the PPU, like the pattern table (a 16x16 grid storing the higher 2 bits of all the underlying background pixels), or the vertical blank period, or the open bus.\nPpu::DrawPixel() The color of a pixel comes from one of the 16 entries of the palette VRAM, and to do so 4 bits must be calculated for background and for sprites.\nFor background tiles, 2 pixels comes from the ‘texture’ (CHR-ROM) and 2 from the attribute table. Sprites contains all those informations together.\nThe output is a silly SSBO that contains RGBA colors to be used in a compute shader that outputs to the screen.\nCpuRead/Write, PpuRead/Write All those methods are essential because the NES uses memory mapping i/o to access the different hardware.\nFor example the PPU access the cartridge through the mapper in the memory controller to read drawing informations, the CPU writes to the PPU using address $2007, etc.\nEnding notes I will prepare more detailed posts about the NES architecture and emulation, even though there are still some concepts that are not clear to me and require a deeper investigation.\nSo far this is the most satisfactory personal project I’ve done, and one of the few that arrived at a usable level.\nIn the future I want to improve this emulator and use the knowledge to explore the writing of a SNES emulator!\nAny question or comment please let me know!\nGabriel\n","date":1563861890,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1563861890,"objectID":"96109d55d54d12572b76d4542ac35062","permalink":"/post/releasing_nes_emulator_source/","publishdate":"2019-07-23T02:04:50-04:00","relpermalink":"/post/releasing_nes_emulator_source/","section":"post","summary":"Legend of Zelda emulated plus debugging windows.   Hello everyone!\nToday I release the source code of my bare-bone NES emulator, written in C++.\nI had the idea to write an emulator of one of my favorite console (after the SNES) years ago, and started in 2015 to write the first code (actually in 2008, but it was too daunting even to start). Then I concentrated on my other big project (still ongoing) and left all the NES code on a side.","tags":[],"title":"Releasing NES Emulator Source","type":"post"}]