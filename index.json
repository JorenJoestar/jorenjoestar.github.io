[{"authors":["admin"],"categories":null,"content":"Video-games Lover. Guitar enthusiast. Life-surfer.\nPassion, mistakes and curiosity.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"Video-games Lover. Guitar enthusiast. Life-surfer.\nPassion, mistakes and curiosity.","tags":null,"title":"Gabriel Sassone","type":"authors"},{"authors":[],"categories":[],"content":" Overview In this article we will create a simple language that can encapsulate shader code (called code fragments) and output different files for each fragment.\nThis is the initial step to switch from an engine that loads single files for each shader stage (vertex, fragment, compute, \u0026hellip;) to one that uses an effect file that contains more than one shader.\nWe will start by motivation, then will define the language itself (very simple), then we will look at the Parser and last the Code Generator.\nHave a good read!\nMotivation In the incredible quest of data-driven rendering, after we defeated the dragon of code generation another multiple headed dragon arises: an hydra! We have different options here: be the brave warrior in shiny armor that tries to cut all the heads of the hydra, built some machines that can fight for us and send them, or both built the machines AND fight.\nOur code is invaluable, like our energies fighting the hydra. We need to carefully balance them and see how can we use for the BEST.\nWriting manual code is good, it is generally what is done, but it is slow and error prone. Going data-driven can be fast, but can give you a sense of losing control (not personally, but I heard few people saying that). Only generating code can quickly become a recipe for disaster: so many particular use cases need attention, that the code could be come a different kind of mess.\nWe will try to go down the route of code generation mixed with data-driven. As I wrote in my previous articles, it is a fine line and can be good to know when to go in which direction!\nI will divide the article in 2 parts. The first part (this one) will contain the new Shader Code Generator to generate shader permutations and add include support to GLSL. The second will require a low-level rendering library and will show Code Generation of more CPU areas of Rendering, the real goal of all these articles!\nThe code is available here:\nhttps://github.com/JorenJoestar/DataDrivenRendering\nEffect file structure Looking at effects, the first thing to do is to define a file that will represent our shaders. My choice is to create a simple language to embed shaders code and generate the CPU code necessary to render it.\nWhy not using Json ? While it is an amazing data-format, I still want a bigger degree of control of what to parse and what to generate. The decision is based on the fact that by writing a parser for the language, I can automate some code-generation that would be more intricate with Json. Also, this series itself is a personal exploration on the topic, so using Json was not an option for this level of complexity.\nThe HFX Format HFX (Hydra Effects) is a new language we will define to write out shaders. The first iteration will be barebone - it will simply be a shader permutation generator - but it will be the foundation to extensions that will allow us to write CPU rendering code that we want to automate.\nIn defining the format, there will be few keywords that will be defined, but the general architecture will make straightforward to copy-paste shader code fragments from any language into the HFX language. We will use the following keywords (and concepts).\nShader The root of a shader effect. It will contain everything we are writing.\nGlsl/Hlsl These will define the actual shader code, enclosed fragments. Fragments can be composed and reused. For Glsl in particular, code fragments needs to be embedded in defines for each stage. More on that later.\nPass, Technique, Variant This is the central part for the effects to work. I\u0026rsquo;ve researched a bit, between Microsoft effects, Unity effects, Godot and Bungie and the concepts are very similar, but they seem to differ a little and also each implementation becomes very engine-specific of course.\nThe presentation by Bungie is amazing and their system is by far the more extensive and complex, we will work on a much simpler shader effect system.\nLet\u0026rsquo;s define a pass as a combination of shader code for at least one stage of the shader pipeline. For example a single compute shader or a couple vertex-fragment shader.\nVariants and techniques are loose concept to help separating shader paths. For example a variant could be a different post-process shader, like different implementations of SSAO.\nA technique could be a whole set of passes that target a specific platform.\nNot having my mind set on those still, I will omit them for now, as they are concepts that are less central than the code generation, and can be very subjective opinion-wise. Possibly I\u0026rsquo;ll get them in part 2.\nProperties Final piece of the puzzle. This will define the resources used by the shader effect on a per-effect level. Keeping an eye on the newer rendering APIs (DX12 and Vulkan) this defines also the layout of the resources and how they are used. Possibly the most intense part from an automation possibility (and thus code-generation). We will define this in part 2 of this article.\nHigh level workflow From a high level perspective what will happen in all this code is enclosed in this code:\ntext = ReadEntireFileIntoMemory( \u0026quot;..\\\\data\\\\SimpleFullscreen.hfx\u0026quot;, nullptr ); initLexer( \u0026amp;lexer, (char*)text ); hfx::Parser effect_parser; hfx::initParser( \u0026amp;effect_parser, \u0026amp;lexer ); hfx::generateAST( \u0026amp;effect_parser ); hfx::CodeGenerator hfx_code_generator; hfx::initCodeGenerator( \u0026amp;hfx_code_generator, \u0026amp;effect_parser, 4096 ); hfx::generateShaderPermutations( \u0026amp;hfx_code_generator, \u0026quot;..\\\\data\\\\\u0026quot; );  We separated the Lexer from the Parser so we can reuse the lexer functionalities, thus we can reuse it from the previous example (parsing the HydraDataFormat files).\nThen we initialize the Parser and generate the AST. This will save all the passes and code fragments we defined in the HFX file.\nFinally we will get the parsing informations and give them to the code generator, that will write out the files for each pass and stage.\nLet\u0026rsquo;s dig into the example!\nParser: welcome HFX! In most rendering-API (OpenGL, Vulkan, Direct3D12, \u0026hellip;) shaders are compiled by compiling the individual stages (vertex, fragment, compute, geometry, \u0026hellip;) and in some APIs (especially the newer ones) are compiled into a Shader State.\nAs first step of this shader language, single shader files will be created by the shader generation method in our code.\nWe will define a simple fullscreen HFX with code fragments and passes.\nFirst, we define the root shader (SimpleFullscreen.hfx, under folder \u0026lsquo;data\u0026rsquo;):\nshader SimpleFullscreen {  This is simply the container for all the code and passes that will define the shader effect.\nNow we need some actual code, so we can define a shader fragment.\nThe keyword used in our language is glsl followed by a name and an open brace:\nglsl ToScreen {  This will define a code fragment named ToScreen, that can be referenced from the passes.\nNext we use a glsl trick to signal our parser to use includes:\n#pragma include \u0026quot;Platform.h\u0026quot;  This #pragma is actually ignored by the compiler, but will be used by the parser to actually add the include!\nBEWARE: this code will be included in BOTH vertex and fragment program!\nAnything outside of the VERTEX/FRAGMENT/COMPUTE macros will be, and this is done on purpose, like defining an interpolator struct only once or for common includes.\nNext we define the vertex program.\nBEWARE: vertex only code must be enclosed in VERTEX define!\n#if defined VERTEX out vec4 vTexCoord; void main() { vTexCoord.xy = vec2((gl_VertexID \u0026lt;\u0026lt; 1) \u0026amp; 2, gl_VertexID \u0026amp; 2); vTexCoord.zw = vTexCoord.xy; gl_Position = vec4(vTexCoord.xy * 2.0f + -1.0f, 0.0f, 1.0f); } #endif // VERTEX  This code is a simple fullscreen triangle that does not require any vertex buffer, but uses the vertex id to draw. Nothing fancy.\nNext is the fragment program, and again enclosed in FRAGMENT define:\n#if defined FRAGMENT in vec4 vTexCoord; out vec4 outColor; layout(binding=0) uniform sampler2D input_texture; void main() { vec3 color = texture2D(input_texture, vTexCoord.xy).xyz; outColor = vec4(color, 1); } #endif // FRAGMENT } // glsl ToScreen  This code simply reads a texture and outputs it to the screen.\nWe defined the code fragment ToScreen, containing both a vertex and a fragment program, and now we can actually generate the permutation that we need.\nThe code for this in our effect file is:\npass ToScreen { vertex = ToScreen fragment = ToScreen }  We are simply defining a pass with the vertex and fragment program defined in the ToScreen code fragment (yes I don\u0026rsquo;t like this term too).\nRunning the code generator on this simple effect file will generate the two files ToScreen.vert and ToScreen.frag.\nThese can be read directly into your favourite OpenGL renderer and used as is!\nThe Parser Now that we have defined the effect and we know what is the outcome of generating code from the effect file, let\u0026rsquo;s look into the different component of the parser and code generator needed.\nBy design, we chose the Lexer to know nothing about the language, so that we can use it between different languages. The entry point to parse the effect is the method generateAST:\nvoid generateAST( Parser* parser ) { // Read source text until the end. // The main body can be a list of declarations. bool parsing = true; while ( parsing ) { Token token; nextToken( parser-\u0026gt;lexer, token ); switch ( token.type ) { case Token::Token_Identifier: { identifier( parser, token ); break; } case Token::Type::Token_EndOfStream: { parsing = false; break; } } } }  This code simply process the file - using the lexer - until the end of it, and reads only identifiers.\nIt is the same as the previous article and the previous parser. What changes drastically is the identifier method!\nWe will have 3 different set of identifiers, usable in different parts of the HFX file:\n Main identifiers, \u0026lsquo;shader\u0026rsquo;, \u0026lsquo;glsl\u0026rsquo;, \u0026lsquo;pass\u0026rsquo; Pass identifiers, \u0026lsquo;compute\u0026rsquo;, \u0026lsquo;vertex\u0026rsquo;, \u0026lsquo;fragment\u0026rsquo; Directive identifiers, \u0026lsquo;if defined\u0026rsquo;, \u0026lsquo;pragma include\u0026rsquo;, \u0026lsquo;endif\u0026rsquo;  Let\u0026rsquo;s have a look at the code for parsing the main identifiers:\ninline void identifier( Parser* parser, const Token\u0026amp; token ) { // Scan the name to know which for ( uint32_t i = 0; i \u0026lt; token.text.length; ++i ) { char c = *(token.text.text + i); switch ( c ) { case 's': { if ( expectKeyword( token.text, 6, \u0026quot;shader\u0026quot; ) ) { declarationShader( parser ); return; } break; } case 'g': { if ( expectKeyword( token.text, 4, \u0026quot;glsl\u0026quot; ) ) { declarationGlsl( parser ); return; } break; } case 'p': { if ( expectKeyword( token.text, 4, \u0026quot;pass\u0026quot; ) ) { declarationPass( parser ); return; } break; } } } }  This code simply defers the parsing of a particular identifier using the declaration method corresponding to the identifier. We will look into detail on each method.\nParsing \u0026lsquo;shader\u0026rsquo; We are parsing now the following part from the HFX file:\n// HFX shader SimpleFullscreen {  This is the entry point of the effect itself.\nWhat should the parser do here ?\nSimply iterate through the main identifiers, \u0026lsquo;glsl\u0026rsquo; and \u0026lsquo;pass\u0026rsquo;.\nTechnically I could have separated the methods to have one with parsing shader only and the others parsing \u0026lsquo;glsl\u0026rsquo; and \u0026lsquo;pass\u0026rsquo;, but did not want to complicate the code further.\nLet\u0026rsquo;s look at how we parse the identifier \u0026lsquo;shader\u0026rsquo;:\n// C++ inline void declarationShader( Parser* parser ) { // Parse name Token token; if ( !expectToken( parser-\u0026gt;lexer, token, Token::Token_Identifier ) ) { return; } // Cache name string StringRef name = token.text; if ( !expectToken( parser-\u0026gt;lexer, token, Token::Token_OpenBrace ) ) { return; } while ( !equalToken( parser-\u0026gt;lexer, token, Token::Token_CloseBrace ) ) { identifier( parser, token ); } }  As the previous article\u0026rsquo;s code, this will get the tokens from the lexer and generate data if the syntax is correct.\nWhen we enter the method the Lexer will be just at the beginning of the name (SimpleFullscreen), so the code will parse the name, the open brace, and parse everything else until it encounter the close brace.\nThe method identifier will parse also identifiers \u0026lsquo;glsl\u0026rsquo; and \u0026lsquo;pass\u0026rsquo;.\nParsing \u0026lsquo;glsl\u0026rsquo; This is the most complex parsing in the code.\nI will put both the HFX part and C++ code so hopefully it will be clearer what the parser is doing and why.\nAs a refresh and reference, this is the code fragment ToScreen defined in SimpleFullscreen.hfx:\n// HFX glsl ToScreen { #pragma include \u0026quot;Platform.h\u0026quot; #if defined VERTEX out vec4 vTexCoord; void main() { vTexCoord.xy = vec2((gl_VertexID \u0026lt;\u0026lt; 1) \u0026amp; 2, gl_VertexID \u0026amp; 2); vTexCoord.zw = vTexCoord.xy; gl_Position = vec4(vTexCoord.xy * 2.0f + -1.0f, 0.0f, 1.0f); } #endif // VERTEX #if defined FRAGMENT in vec4 vTexCoord; out vec4 outColor; layout(binding=0) uniform sampler2D input_texture; void main() { vec3 color = texture2D(input_texture, vTexCoord.xy).xyz; outColor = vec4(1, 1, 0, 1); outColor = vec4(color, 1); } #endif // FRAGMENT }  Let\u0026rsquo;s start from the beginning.\nWhen the parser finds the \u0026lsquo;glsl\u0026rsquo; keyword in the identifier method:\n// C++ case 'g': { if ( expectKeyword( token.text, 4, \u0026quot;glsl\u0026quot; ) ) { declarationGlsl( parser ); return; } break; }  It calls the method void declarationGlsl( Parser* parser ).\nThe lexer reading the HFX is after the glsl keyword when entering the method, just before the ToScreen identifier:\n// HFX glsl (Here!)ToScreen {  Let\u0026rsquo;s see the C++ code step by step.\nFirst parsing the name \u0026lsquo;ToScreen\u0026rsquo;:\n// C++ inline void declarationGlsl( Parser* parser ) { // Parse name Token token; if ( !expectToken( parser-\u0026gt;lexer, token, Token::Token_Identifier ) ) { return; }  as seen in other methods as well.\nWe are defining a new code fragment, thus we need to initialize it. There is tracking of the #ifdef depths to manage when some code must be included in a code fragment and when not:\n CodeFragment code_fragment = {}; // Cache name string code_fragment.name = token.text; for ( size_t i = 0; i \u0026lt; CodeFragment::Count; i++ ) { code_fragment.stage_ifdef_depth[i] = 0xffffffff; } if ( !expectToken( parser-\u0026gt;lexer, token, Token::Token_OpenBrace ) ) { return; }  Next is simply arriving at the first token that contains all the glsl code:\n // Advance token and cache the starting point of the code. nextToken( parser-\u0026gt;lexer, token ); code_fragment.code = token.text;  And now some more parsing craftmanship.\nWe cannot use anymore the simple check to end parsing when encountering a closed brace, because there can be different structs defined that will break that mechanism.\nInstead we track the number of open braces and when we close the last one, we consider finished the parsing of the code fragment!\n uint32_t open_braces = 1; // Scan until close brace token while ( open_braces ) { if ( token.type == Token::Token_OpenBrace ) ++open_braces; else if ( token.type == Token::Token_CloseBrace ) --open_braces;  The only token that we care inside the code fragment is the hash, signalling either an include or a define, used for separating per-stage code.\nThe parsing of the hash token will be done inside the directiveIdentifier method:\n // Parse hash for includes and defines if ( token.type == Token::Token_Hash ) { // Get next token and check which directive is nextToken( parser-\u0026gt;lexer, token ); directiveIdentifier( parser, token, code_fragment ); }  Before diving deep into the directive identifiers, let\u0026rsquo;s finish the main parsing routine.\nWe advance to the next token until we close all the braces, and then save the text length of all the code fragment:\n nextToken( parser-\u0026gt;lexer, token ); } // Calculate code string length code_fragment.code.length = token.text.text - code_fragment.code.text;  Final step is to save the newly parsed code fragment into the parser data:\n parser-\u0026gt;code_fragments.emplace_back( code_fragment ); }  We can now dive deep into the parsing of directives, namely #if defined, #pragma include and #endif.\nParsing \u0026lsquo;#if defined\u0026rsquo; When we encounter the Hash token within the glsl part, we need to parse further to understand the other keywords.\n#if defined is the most important directive for us, because it will tell the parser which shader stage we are parsing currently and thus where to direct the text!\nIt starts from a common/shared stage, for shared code, and when encounters a #if defined it can signal a stage specific code.\nNamely when parsing the following line in HFX:\n// HFX #(Here!)if defined VERTEX  The parser needs to check 2 other identifiers. Remember that the parser is currently AFTER the Hash token, as beautifully written in the previous snippet!\nLet\u0026rsquo;s look at the code:\n// C++ inline void directiveIdentifier( Parser* parser, const Token\u0026amp; token, CodeFragment\u0026amp; code_fragment ) { Token new_token; for ( uint32_t i = 0; i \u0026lt; token.text.length; ++i ) { char c = *(token.text.text + i); switch ( c ) { case 'i': { // Search for the pattern 'if defined' if ( expectKeyword( token.text, 2, \u0026quot;if\u0026quot; ) ) { nextToken( parser-\u0026gt;lexer, new_token ); if ( expectKeyword( new_token.text, 7, \u0026quot;defined\u0026quot; ) ) { nextToken( parser-\u0026gt;lexer, new_token ); // Use 0 as not set value for the ifdef depth. ++code_fragment.ifdef_depth; if ( expectKeyword( new_token.text, 6, \u0026quot;VERTEX\u0026quot; ) ) { code_fragment.stage_ifdef_depth[CodeFragment::Vertex] = code_fragment.ifdef_depth; code_fragment.current_stage = CodeFragment::Vertex; } else if ( expectKeyword( new_token.text, 8, \u0026quot;FRAGMENT\u0026quot; ) ) { code_fragment.stage_ifdef_depth[CodeFragment::Fragment] = code_fragment.ifdef_depth; code_fragment.current_stage = CodeFragment::Fragment; } else if ( expectKeyword( new_token.text, 7, \u0026quot;COMPUTE\u0026quot; ) ) { code_fragment.stage_ifdef_depth[CodeFragment::Compute] = code_fragment.ifdef_depth; code_fragment.current_stage = CodeFragment::Compute; } } return; } break; }  Let\u0026rsquo;s dissect this code!\nStarting from the current token, just after the #(Hash), we need to check the correct composition of the keywords.\nWe expect \u0026lsquo;if\u0026rsquo;, and then if found we go to the next token:\nif ( expectKeyword( token.text, 2, \u0026quot;if\u0026quot; ) ) { nextToken( parser-\u0026gt;lexer, new_token );  We search for the \u0026lsquo;defined\u0026rsquo; identifier and if found we go to the next identifier:\nif ( expectKeyword( new_token.text, 7, \u0026quot;defined\u0026quot; ) ) { nextToken( parser-\u0026gt;lexer, new_token );  The parser is currently here:\n#if defined (Here!)VERTEX  And thus the last step is to check which shader stage is currently starting. This is done here:\nif ( expectKeyword( new_token.text, 6, \u0026quot;VERTEX\u0026quot; ) ) { code_fragment.stage_ifdef_depth[CodeFragment::Vertex] = code_fragment.ifdef_depth; code_fragment.current_stage = CodeFragment::Vertex; }  In this central piece of code, we set the current stage to Vertex (because we found the keyword \u0026lsquo;VERTEX\u0026rsquo;) and we save the current ifdef depth.\nWhy that ? Because when we will parse #endif, we will do the same for the open/close braces depth in the main glsl parser: we want to be sure that the defines are paired correctly and we are saving the per-stage code in the correct way!\nThis will be more clear when we see the #endif parsing.\nMoving on, we will do the same for all the other keywords (\u0026lsquo;FRAGMENT\u0026rsquo; and \u0026lsquo;COMPUTE\u0026rsquo; for now):\nelse if ( expectKeyword( new_token.text, 8, \u0026quot;FRAGMENT\u0026quot; ) ) { code_fragment.stage_ifdef_depth[CodeFragment::Fragment] = code_fragment.ifdef_depth; code_fragment.current_stage = CodeFragment::Fragment; } else if ( expectKeyword( new_token.text, 7, \u0026quot;COMPUTE\u0026quot; ) ) { code_fragment.stage_ifdef_depth[CodeFragment::Compute] = code_fragment.ifdef_depth; code_fragment.current_stage = CodeFragment::Compute; }  And the parsing of #if defined is over!\nParsing \u0026lsquo;#pragma include\u0026rsquo; In HFX we are parsing the following:\n// HFX #pragma include \u0026quot;Platform.h\u0026quot;  With the following code (inside directiveIdentifier method):\n// C++ case 'p': { if ( expectKeyword( token.text, 6, \u0026quot;pragma\u0026quot; ) ) { nextToken( parser-\u0026gt;lexer, new_token ); if ( expectKeyword( new_token.text, 7, \u0026quot;include\u0026quot; ) ) { nextToken( parser-\u0026gt;lexer, new_token ); code_fragment.includes.emplace_back( new_token.text ); code_fragment.includes_stage.emplace_back( code_fragment.current_stage ); } return; } break; }  This is simply saving the filename after the include, that being surrounded by \u0026ldquo;\u0026rdquo; is classified as string, and is using the current stage to know which stage should include that file!\nParsing \u0026lsquo;#endif\u0026rsquo; Final part is the #endif identifier:\ncase 'e': { if ( expectKeyword( token.text, 5, \u0026quot;endif\u0026quot; ) ) { if ( code_fragment.stage_ifdef_depth[CodeFragment::Vertex] == code_fragment.ifdef_depth ) { code_fragment.stage_ifdef_depth[CodeFragment::Vertex] = 0xffffffff; code_fragment.current_stage = CodeFragment::Common; } else if ( code_fragment.stage_ifdef_depth[CodeFragment::Fragment] == code_fragment.ifdef_depth ) { code_fragment.stage_ifdef_depth[CodeFragment::Fragment] = 0xffffffff; code_fragment.current_stage = CodeFragment::Common; } else if ( code_fragment.stage_ifdef_depth[CodeFragment::Compute] == code_fragment.ifdef_depth ) { code_fragment.stage_ifdef_depth[CodeFragment::Compute] = 0xffffffff; code_fragment.current_stage = CodeFragment::Common; } --code_fragment.ifdef_depth; return; } break; }  This is mirroring the #if defined and simply goes back to set the current stage to common/shared and reset the per-stage ifdef depth.\nWe can now proceed to the final part of the parsing, the passes!\nThis is the glue to generate the different files from the code fragments.\nParsing \u0026lsquo;pass\u0026rsquo; Reading the HFX file, we are now in the final part of the file:\n// HFX pass ToScreen { vertex = ToScreen fragment = ToScreen }  A pass is simply a collection of code fragments associated with each shader stage (vertex, fragment, compute).\nWhen we parsed the fragments, we saved them in the parser to be retrieved.\nTo refresh our memory, this is the actual Pass struct in C++:\n// C++ struct Pass { StringRef name; const CodeFragment* vs = nullptr; const CodeFragment* fs = nullptr; const CodeFragment* cs = nullptr; }; // struct Pass  Going back to the main directive method, we call the declarationPass method when we encounter the \u0026lsquo;pass\u0026rsquo; identifier.\nWe will parse the following line:\n// HFX pass ToScreen {  With the following code (similar to everything else, it should be easier to read now):\n// C++ inline void declarationPass( Parser* parser ) { Token token; if ( !expectToken( parser-\u0026gt;lexer, token, Token::Token_Identifier ) ) { return; } Pass pass = {}; // Cache name string pass.name = token.text; if ( !expectToken( parser-\u0026gt;lexer, token, Token::Token_OpenBrace ) ) { return; }  After we saved the pass name we can start reading the individual stages using the passIdentifier method:\n while ( !equalToken( parser-\u0026gt;lexer, token, Token::Token_CloseBrace ) ) { passIdentifier( parser, token, pass ); }  And then save the newly parsed pass.\n parser-\u0026gt;passes.emplace_back( pass ); }  For each identifier now, we will check which stage we are parsing.\nCurrently we are here, after the open brace and all the whitespace:\n// HFX pass ToScreen { (Here!)vertex = ToScreen fragment = ToScreen }  What is next is thus checking the identifier and filling the corresponding shader stage of the pass.\nI will post all the code of the method, because is similar to most code we seen and should be straightforward:\n// C++ inline void passIdentifier( Parser* parser, const Token\u0026amp; token, Pass\u0026amp; pass ) { // Scan the name to know which stage we are parsing for ( uint32_t i = 0; i \u0026lt; token.text.length; ++i ) { char c = *(token.text.text + i); switch ( c ) { case 'c': { if ( expectKeyword( token.text, 7, \u0026quot;compute\u0026quot;) ) { declarationShaderStage( parser, \u0026amp;pass.cs ); return; } break; } case 'v': { if ( expectKeyword( token.text, 6, \u0026quot;vertex\u0026quot; ) ) { declarationShaderStage( parser, \u0026amp;pass.vs ); return; } break; } case 'f': { if ( expectKeyword( token.text, 8, \u0026quot;fragment\u0026quot; ) ) { declarationShaderStage( parser, \u0026amp;pass.fs ); return; } break; } } } }  The real \u0026lsquo;magic\u0026rsquo; here is the \u0026lsquo;declarationShaderStage\u0026rsquo; method.\nThis method parses the couple \u0026lsquo;identifier\u0026rsquo; \u0026lsquo;=\u0026rsquo; \u0026lsquo;identifier\u0026rsquo;, and searches the code fragment with the same name:\ninline void declarationShaderStage( Parser* parser, const CodeFragment** out_fragment ) { Token token; if ( !expectToken( parser-\u0026gt;lexer, token, Token::Token_Equals ) ) { return; } if ( !expectToken( parser-\u0026gt;lexer, token, Token::Token_Identifier ) ) { return; } *out_fragment = findCodeFragment( parser, token.text ); }  After all the stages of the current pass are parsed, we save the pass and finish parsing the file!\nShader Permutation Generation The final step of this amazing journey is the simplest, and it is actually to generate the single files we need.\nIn our case another specific class, CodeGenerator, will generate the different files from the parsed HFX file.\nAfter we\u0026rsquo;ve done with the parsing, we can call the generateShaderPermutations method that will generate files for each shader stage in each pass:\nvoid generateShaderPermutations( CodeGenerator* code_generator, const char* path ) { code_generator-\u0026gt;string_buffer_0.clear(); code_generator-\u0026gt;string_buffer_1.clear(); code_generator-\u0026gt;string_buffer_2.clear(); // For each pass and for each pass generate permutation file. const uint32_t pass_count = (uint32_t)code_generator-\u0026gt;parser-\u0026gt;passes.size(); for ( uint32_t i = 0; i \u0026lt; pass_count; i++ ) { // Create one file for each code fragment const Pass\u0026amp; pass = code_generator-\u0026gt;parser-\u0026gt;passes[i]; if ( pass.cs ) { outputCodeFragment( code_generator, path, CodeFragment::Compute, pass.cs ); } if ( pass.fs ) { outputCodeFragment( code_generator, path, CodeFragment::Fragment, pass.fs ); } if ( pass.vs ) { outputCodeFragment( code_generator, path, CodeFragment::Vertex, pass.vs ); } } }  The code should be straightforward, and the real action happens into the outputCodeFragment method.\nLet\u0026rsquo;s have a look at the code.\nFirst we define some data, like the file extensions for each shader stage or the defines to compile the code:\n// Additional data to be added to output shaders. static const char* s_shader_file_extension[CodeFragment::Count] = { \u0026quot;.vert\u0026quot;, \u0026quot;.frag\u0026quot;, \u0026quot;.compute\u0026quot;, \u0026quot;.h\u0026quot; }; static const char* s_shader_stage_defines[CodeFragment::Count] = { \u0026quot;#define VERTEX\\r\\n\u0026quot;, \u0026quot;#define FRAGMENT\\r\\n\u0026quot;, \u0026quot;#define COMPUTE\\r\\n\u0026quot;, \u0026quot;\u0026quot; };  Then we start to write the file.\nWe will use the string_buffer_0 to dynamically generate the path of the file without allocating memory:\nvoid outputCodeFragment( CodeGenerator* code_generator, const char* path, CodeFragment::Stage stage, const CodeFragment* code_fragment ) { // Create file FILE* output_file; code_generator-\u0026gt;string_buffer_0.clear(); code_generator-\u0026gt;string_buffer_0.append( path ); code_generator-\u0026gt;string_buffer_0.append( code_fragment-\u0026gt;name ); code_generator-\u0026gt;string_buffer_0.append( s_shader_file_extension[stage] ); fopen_s( \u0026amp;output_file, code_generator-\u0026gt;string_buffer_0.data, \u0026quot;wb\u0026quot; ); if ( !output_file ) { printf( \u0026quot;Error opening file. Aborting. \\n\u0026quot; ); return; }  And then use string_buffer_1 to instead generate the actual code into the file.\nFirst, and most important, we will add all the includes for this particular stage by opening the file, reading it into memory and adding it into the final code buffer.\nWe will still use string_buffer_0 to generate the path of the file:\n code_generator-\u0026gt;string_buffer_1.clear(); // Append includes for the current stage. for ( size_t i = 0; i \u0026lt; code_fragment-\u0026gt;includes.size(); i++ ) { if ( code_fragment-\u0026gt;includes_stage[i] != stage \u0026amp;\u0026amp; code_fragment-\u0026gt;includes_stage[i] != CodeFragment::Common ) { continue; } // Open and read file code_generator-\u0026gt;string_buffer_0.clear(); code_generator-\u0026gt;string_buffer_0.append( path ); code_generator-\u0026gt;string_buffer_0.append( code_fragment-\u0026gt;includes[i] ); char* include_code = ReadEntireFileIntoMemory( code_generator-\u0026gt;string_buffer_0.data, nullptr ); code_generator-\u0026gt;string_buffer_1.append( include_code ); code_generator-\u0026gt;string_buffer_1.append( \u0026quot;\\r\\n\u0026quot; ); }  After that is done we can copy the define needed for the current shader stage:\n code_generator-\u0026gt;string_buffer_1.append( \u0026quot;\\t\\t\u0026quot; ); code_generator-\u0026gt;string_buffer_1.append( s_shader_stage_defines[stage] );  And finally the actual code:\n code_generator-\u0026gt;string_buffer_1.append( \u0026quot;\\r\\n\\t\\t\u0026quot; ); code_generator-\u0026gt;string_buffer_1.append( code_fragment-\u0026gt;code );  Write to file and close it and we are done!\n fprintf( output_file, \u0026quot;%s\u0026quot;, code_generator-\u0026gt;string_buffer_1.data ); fclose( output_file ); }  And this will generate the shader permutations for each pass with a single file, using the standard GLSL convention for files extensions.\nConclusions and next part We parsed our simple shader language to enhance and embed glsl code fragments into our codebase by generating single files that can be used into any OpenGL based renderer.\nWe also laid out the foundation for a more powerful tool - namely code generation - even though there are some intermediate steps to be taken to arrive there.\nFirst of all, we will need a target rendering library (something like the amazing Sokol), so we can specialize our CPU rendering code. I already wrote something like Sokol but with a more Vulkan/D3D12 interface in mind, and I will use that. Still unsure if I will write a specific post on that.\nIn the next article we will add support for the new graphics library and develop the language more to generate code that will manage Constant buffers, automatically creating a CPU-side class, adding UI to edit it in realtime and possibly load/save the values.\nOf course, any feedback/improvements/suggestions on anything related here (article, code, etc) please let me know.\nStay tuned! Gabriel\n","date":1565111055,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1565111055,"objectID":"2335acd956430a4df447b79b03bb937a","permalink":"/post/writing_shader_effect_language_1/","publishdate":"2019-08-06T13:04:15-04:00","relpermalink":"/post/writing_shader_effect_language_1/","section":"post","summary":"Overview In this article we will create a simple language that can encapsulate shader code (called code fragments) and output different files for each fragment.\nThis is the initial step to switch from an engine that loads single files for each shader stage (vertex, fragment, compute, \u0026hellip;) to one that uses an effect file that contains more than one shader.\nWe will start by motivation, then will define the language itself (very simple), then we will look at the Parser and last the Code Generator.","tags":[],"title":"Writing a Shader Effect Language Part 1","type":"post"},{"authors":[],"categories":[],"content":"   UI using ImGUI, SDL and the code generated with this article.   Motivation Following my previous article about Flatbuffers and data reflection the quest for Data-Driven Rendering continues!\nIn this article I want to show how to write a very simple code-generator to help you automate writing of code in any language.\nThe code is here:\nhttps://github.com/JorenJoestar/DataDrivenRendering\nThere is a balance that constantly needs to be found between code and data, and having a code-generator in my opinion helps tremendously in focus on the code that is necessary to be written.\nFrom a data perspective, normally the ‘baking’ pipeline is a series of DCC formats as source transformed into very project specific and optimized data.\nCode-wise, depending on the engine/technology you are using, ‘baking’ of the code is more uncommon.\nIn a time in which iteration time has become almost more important than the tech itself, playing with this balance can be the key for any successful software. It could sound exaggerated, but I really believe in that.\nAs always, both ImGui and SDL will be our sword and shields for this adventure.\nThis will be the second step into data-driven rendering: code generation.\nAre we writing a compiler ? Short answer: yes!\nLong answer: we will be writing the simplest possible compiler that reads a source file and transform in a destination file, like Flatbuffers.\nThere are few links on both theory and practice that can help shed some light on the subject: The “Dragon Book” (called because of the dragon in the cover) is still THE to-go in compiler writing as far as I know.\nIt is an intense book and explores writing a full compiler with depth, starting from Automata theory (just reminds me of how everything you study can be useful, I did 2 exams at University about that, wondering when I would use it! Hello prof Di Battista!) to full code examples:\nhttps://www.amazon.com/Compilers-Principles-Techniques-Tools-2nd/dp/0321486811\nThis is for me the best website on the subject, very precise and readable and follows closely what is inside the Dragon Book:\nhttps://craftinginterpreters.com/\nAnd github page:\nhttps://github.com/munificent/craftinginterpreters\nMy interest was rekindled in 2015, when I was following the amazing Casey Muratori and his Handmade Hero.\nHe generates code for introspection purposes, and really show a simple and effective way of generating code that works for you.\nWikipedia itself also contains a lot of good articles on the subject. The more you know about the it, the more you want to know. It is fascinating and very, very deep!\nCompiler 101 A real compiler is a very complex and fascinating subject/software so I will try to get the simplest possible approach giving my (flawed and incomplete) perspective.\nA compiler is a series of transformations applied to data (you can apply this definition to every software actually…).\nThe input data is a text, and normally the output is still text, but with very different meaning.\nThe raw depth of the subject is astonishing, consider that we are defining a grammar and thus a language, and how to express concepts into it.\nThe main steps are the following:\n Lexer/scanner/tokenizer Parser Code generation  We will define the code generator from a custom language called HDF (Hydra Definition Format) to C++. HDF will be a subset of Flatbuffers in this exercise, but once the concepts are clear it can be expanded to more stuff.\nLexer/Scanner/Tokenizer A lexer or scanner (or tokenizer) is a software that translates an input string into a list of Tokens based on Lexemes. A Lexeme is one or more characters that create a Token. Think of a keyword (like ‘if’, ‘class’, ‘static’ …).\nA Token is identified by a unique Lexeme and abstracts the Lexeme itself. It normally contains a type and some attributes, for example it can save where that lexeme is into the input text, the line. The final structure of the token can vary a bit.\nIn trying to find a simple definition for this step:\n The act of Tokenizing is the act of abstracting the input text.\n For example, given the following input text:\nstatic void amazing_method() {};  It will generate the list of tokens ‘keyword, identifier, identifier, open parenthesis, close parenthesis, open brace, close brace, semicolon’.\nThis IS abstracting the text!\nNormally a lexer/scanner is used by the parser to go through the code and retrieve a token and use it in some way. Let’s start seeing what a lexer could be!\nCode Let\u0026rsquo;s see the code used by the lexer.\nFirst thing will be to define the Token:\n// Lexer/Tokenizer code. It is abstract enough so is not grammar specific. // struct Token { enum Type { Token_Unknown, Token_OpenParen, Token_CloseParen, Token_Colon, Token_Semicolon, Token_Asterisk, Token_OpenBracket, Token_CloseBracket, Token_OpenBrace, Token_CloseBrace, Token_OpenAngleBracket, Token_CloseAngleBracket, Token_String, Token_Identifier, Token_Number, Token_EndOfStream, }; // enum Type Type type; StringRef text; }; // struct Token  It is basically a enum with a StringRef.\nA StringRef is basically a substring - used to avoid allocations when parsing by simply saving where the Token is in the parsed text and how long it is.\nNext is the Lexer itself:\n// // The role of the Lexer is to divide the input string into a list of Tokens. struct Lexer { char* position = nullptr; uint32_t line = 0; uint32_t column = 0; bool error = false; uint32_t error_line = 0; }; // struct Lexer  The most important variable is position - it saves where the Lexer is in the current text for parsing.\nFrom now on there will be only methods.\nFirst some character classification that will help the Lexer:\n// // All those methods are to classify a character. // inline bool IsEndOfLine( char c ) { bool Result = ((c == '\\n') || (c == '\\r')); return(Result); } inline bool IsWhitespace( char c ) { bool Result = ((c == ' ') || (c == '\\t') || (c == '\\v') || (c == '\\f') || IsEndOfLine( c )); return(Result); } inline bool IsAlpha( char c ) { bool Result = (((c \u0026gt;= 'a') \u0026amp;\u0026amp; (c \u0026lt;= 'z')) || ((c \u0026gt;= 'A') \u0026amp;\u0026amp; (c \u0026lt;= 'Z'))); return(Result); } inline bool IsNumber( char c ) { bool Result = ((c \u0026gt;= '0') \u0026amp;\u0026amp; (c \u0026lt;= '9')); return(Result); }  These should be quite straightforward.\nThen we have the most important method for the lexer: nextToken.\nThis method will contain all the logic to go to the next token, and we will see it step by step.\nFirst is skipping all the whitespaces (empty characters, tabs, returns, etc) to arrive at the correct character in the text.\n// // This is the main method. Skip whitespaces and get next token. Save also the current position in the input string. // void nextToken( Lexer* lexer, Token\u0026amp; token ) { // Skip all whitespace first so that the token is without them. skipWhitespace( lexer );  The code for skipping the whitespace is pretty straight-forward. First it checks if it is a pure whitespace:\nvoid skipWhitespace( Lexer* lexer ) { // Scan text until whitespace is finished. for ( ;; ) { // Check if it is a pure whitespace first. if ( IsWhitespace( lexer-\u0026gt;position[0] ) ) { // Handle change of line if ( IsEndOfLine( lexer-\u0026gt;position[0] ) ) ++lexer-\u0026gt;line; // Advance to next character ++lexer-\u0026gt;position;  Then it checks if it is a single line comment:\n } // Check for single line comments (\u0026quot;//\u0026quot;) else if ( (lexer-\u0026gt;position[0] == '/') \u0026amp;\u0026amp; (lexer-\u0026gt;position[1] == '/') ) { lexer-\u0026gt;position += 2; while ( lexer-\u0026gt;position[0] \u0026amp;\u0026amp; !IsEndOfLine( lexer-\u0026gt;position[0] ) ) { ++lexer-\u0026gt;position; }  And last it checks for c-style multiline comments:\n } // Check for c-style multi-lines comments else if ( (lexer-\u0026gt;position[0] == '/') \u0026amp;\u0026amp; (lexer-\u0026gt;position[1] == '*') ) { lexer-\u0026gt;position += 2; // Advance until the string is closed. Remember to check if line is changed. while ( !((lexer-\u0026gt;position[0] == '*') \u0026amp;\u0026amp; (lexer-\u0026gt;position[1] == '/')) ) { // Handle change of line if ( IsEndOfLine( lexer-\u0026gt;position[0] ) ) ++lexer-\u0026gt;line; // Advance to next character ++lexer-\u0026gt;position; } if ( lexer-\u0026gt;position[0] == '*' ) { lexer-\u0026gt;position += 2; } } else { break; } } }  After skipped all the whitespaces, we initialize the new token:\n // Initialize token token.type = Token::Token_Unknown; token.text.text = lexer-\u0026gt;position; token.text.length = 1; token.line = lexer-\u0026gt;line;  We get the current character and advance the position, so we can analize it.\n char c = lexer-\u0026gt;position[0]; ++lexer-\u0026gt;position;  Here comes the character analisys using a simple switch.\n switch ( c ) { case '\\0': { token.type = Token::Token_EndOfStream; } break; case '(': { token.type = Token::Token_OpenParen; } break; case ')': { token.type = Token::Token_CloseParen; } break; case ':': { token.type = Token::Token_Colon; } break; case ';': { token.type = Token::Token_Semicolon; } break; case '*': { token.type = Token::Token_Asterisk; } break; case '[': { token.type = Token::Token_OpenBracket; } break; case ']': { token.type = Token::Token_CloseBracket; } break; case '{': { token.type = Token::Token_OpenBrace; } break; case '}': { token.type = Token::Token_CloseBrace; } break;  There are some special cases left.\nFirst parsing a string starting from a \u0026lsquo;\u0026ldquo;\u0026rsquo; character.\nIt requires to scan the text until it finds another \u0026lsquo;\u0026ldquo;\u0026rsquo; to indicate the end of the string.\nIt also supports multiple-line strings with the characters \u0026ldquo;\\\u0026rdquo; (double back-slash)\n case '\u0026quot;': { token.type = Token::Token_String; token.text.text = lexer-\u0026gt;position; while ( lexer-\u0026gt;position[0] \u0026amp;\u0026amp; lexer-\u0026gt;position[0] != '\u0026quot;' ) { if ( (lexer-\u0026gt;position[0] == '\\\\') \u0026amp;\u0026amp; lexer-\u0026gt;position[1] ) { ++lexer-\u0026gt;position; } ++lexer-\u0026gt;position; } // Saves total string length token.text.length = lexer-\u0026gt;position - token.text.text; if ( lexer-\u0026gt;position[0] == '\u0026quot;' ) { ++lexer-\u0026gt;position; } } break;  Then the final classification step: first is checking if the token is an identifier (a string literal that starts with a character and is followed by characters, underscores or numbers).\nIf not a identifier, check to see if it is a number. This should be expanded to correctly parse numbers, but for now is not used.\n. If everything else fails, than we don\u0026rsquo;t recognize the token.\n default: { // Identifier/keywords if ( IsAlpha( c ) ) { token.type = Token::Token_Identifier; while ( IsAlpha( lexer-\u0026gt;position[0] ) || IsNumber( lexer-\u0026gt;position[0] ) || (lexer-\u0026gt;position[0] == '_') ) { ++lexer-\u0026gt;position; } token.text.length = lexer-\u0026gt;position - token.text.text; } // Numbers else if ( IsNumber( c ) ) { token.type = Token::Token_Number; } else { token.type = Token::Token_Unknown; } } break; } }  With this code we already have a working Lexer!\nI like to use the lexer in an abstract way - not knowing anything about the underlying language - so that it can be reused for different custom languages (Dr.Wily eyebrows movement goes here).\nIf you want to dive deeper into this, the amazing Crafting Interpreters contains a great page on scanning:\nhttps://www.craftinginterpreters.com/scanning.html\nAlso, some c-style parsing can be found here from the amazing Niklas Frykohlm:\nhttps://github.com/niklasfrykholm/nflibs/blob/master/nf_json_parser.c\nAnd another amazing parser from STB:\nhttps://github.com/nothings/stb/blob/master/stb_c_lexer.h\nParser So far we have abstracted the input text into a list of Tokens, and now we need to generate some more information before arriving at generating new code.\nAs far as I understood it, a parser reads the tokens and generates an Abstract Syntax Tree.\nSometimes, and in simpler parsers, the act of parsing itself can generates a new code if the language we are targeting is simple. Again, I prefer to separate Lexer and Parser to reuse the Lexer for different languages and separate the responsabilities!\n Given a list of tokens and a grammar, a parser generates an Abstract Syntax Tree.\nIt gives meaning to the input text, and is responsible to check the syntax correctness.\n A simple definition for a grammar is the following:\n A grammar is a set of production rules that transforms a series of non-terminals into terminals.\n Putting everything in the perspective of data and transformations we can define:\n Terminals are finalized data Non-terminals are data that must be transformed Production rules are transformations of non-terminals to terminals  Another definition of a parser than it could be :\n A parser is a software that transforms non-terminals in terminals following production rules.\n Grammar It is time to write the formal grammar (a context-free grammar) and see how it maps to code.\nIt will be very simple — much simpler than many examples you find around — but it is a starting point.\nWe will not deal with any expression, statements and such, not in the context of this code generator. I will point out some examples for more complex stuff, but I want to study more the subject for that to be more precise about the subject.\nEach line will be a production rule (a transformation), with the left-side being always a non-terminal.\nWe are using regular expressions syntax here:\n alphabet → [a-zA-z] number →[0–9] identifier → alphabet (alphabet | number | “_”)* variable_declaration → identifier identifier “;” struct_declaration → “struct” identifier “{“ (variable_declaration)+ “}” “;” enum_declaration → “enum” identifier “{“ (identifier)+ “}” module → (struct_declaration | enum_declaration)+*  First we define what an identifier is — a sequence of alpha-numerical characters that can contains also the underscore character.\nNotice that with the identifier production rule, the identifier cannot start with an underscore.\nA variable then is declared simply by two identifiers: the first for the type and the second for the name, following a semicolon.\nA struct is simply a list of variable declarations. Notice the “+” in the rule — this means that at least one element must be present.\nEnums are literally a name for the enum and a list of identifiers in curly braces.\nFinally the module is the root of our grammar. It will contain all the declarations we describe. See it as the data file we are writing to generate the code — one file is one module.\nNow that we defined a simple grammar, we can move to the theory behind the parser.\nPredictive Recursive Descent Parser The grammar we defined is a context-free-grammar.\nDepending on the type of grammar we can write different parsers.\nOne of the most common type of parser (and easier to start with) is the Predictive Recursive Descent Parser, and that is what we will write given our grammar. You can dive into all the details of writing a context-free grammar, writing a Left-to-right Leftmost-derivation grammar (LL(k)) and such and be amazed by all the concepts behind.\nAgain, I am personally starting on this subject, so my knowledge is not deep.\nBack to the parser, the main characteristics of this parser are:\n Descent = top-down. Start from root and generate the Abstract Syntax Tree. Recursive = the parser has mutually recursive methods, one for each non-terminal. Predictive = no backtracking needed. For our simple grammar we do not need any backtracking.  So the parser will start from the root (module non-terminal) and by sequentially reading all the tokens will generate a tree that represent our syntax.\nLet’s see some code!\nCode The central piece of code is the Parser.\nIt uses the Lexer and saves the Types by parsing the input text.\n// // The Parser parses Tokens using the Lexer and generate an Abstract Syntax Tree. struct Parser { Lexer* lexer = nullptr; ast::Type* types = nullptr; uint32_t types_count = 0; uint32_t types_max = 0; }; // struct Parser  Let\u0026rsquo;s have a look at the class Type.\nThis class will let us identify correctly primitive types, enums, struct and commands - a special keyword I create to show a concept that can be used away from the canonical C/C++ languages.\nBy saving a list of names and types we can successfully parse all the types listed above.\n// // Define the language specific structures. namespace ast { struct Type { enum Types { Types_Primitive, Types_Enum, Types_Struct, Types_Command, Types_None }; enum PrimitiveTypes { Primitive_Int32, Primitive_Uint32, Primitive_Int16, Primitive_Uint16, Primitive_Int8, Primitive_Uint8, Primitive_Int64, Primitive_Uint64, Primitive_Float, Primitive_Double, Primitive_Bool, Primitive_None }; Types type; PrimitiveTypes primitive_type; StringRef name; std::vector\u0026lt;StringRef\u0026gt; names; std::vector\u0026lt;const Type*\u0026gt; types; bool exportable = true; }; // struct Type } // namespace ast  And now the actual code making the magic happens!\nEntry point for the parsing is generateAST.\nIt simply goes through ALL the tokens until it reaches the end of the file.\nAt this level of parsing, we parse only identifiers (keywords like \u0026lsquo;struct\u0026rsquo;, \u0026lsquo;enum\u0026rsquo;, \u0026hellip;).\nvoid generateAST( Parser* parser ) { // Read source text until the end. // The main body can be a list of declarations. bool parsing = true; while ( parsing ) { Token token; nextToken( parser-\u0026gt;lexer, token ); switch ( token.type ) { case Token::Token_Identifier: { identifier( parser, token ); break; } case Token::Type::Token_EndOfStream: { parsing = false; break; } } } }  The method \u0026lsquo;identifier\u0026rsquo; searches for the language keywords and acts accordingly.\nThe method \u0026lsquo;expectKeyword\u0026rsquo; simply checks that the keywords are the same.\ninline void identifier( Parser* parser, const Token\u0026amp; token ) { // Scan the name to know which for ( uint32_t i = 0; i \u0026lt; token.text.length; ++i ) { char c = *(token.text.text + i); switch ( c ) { case 's': { if ( expectKeyword( token.text, 6, \u0026quot;struct\u0026quot; ) ) { declarationStruct( parser ); return; } break; } case 'e': { if ( expectKeyword( token.text, 4, \u0026quot;enum\u0026quot; ) ) { declarationEnum( parser ); return; } break; } case 'c': { if ( expectKeyword( token.text, 7, \u0026quot;command\u0026quot; ) ) { declarationCommand( parser ); return; } break; } } } }  The next methods are the real core of parsing a language. When declaring a struct, the token we have are:\n Identifier \u0026lsquo;struct\u0026rsquo; (parsed already by generateAST method) Name of the struct Open braces Zero or more variables  The method expectToken checks the presence of the expected token and saves the line if an error occurs.\ninline void declarationStruct( Parser* parser ) { // name Token token; if ( !expectToken( parser-\u0026gt;lexer, token, Token::Token_Identifier ) ) { return; } // Cache name string StringRef name = token.text; if ( !expectToken( parser-\u0026gt;lexer, token, Token::Token_OpenBrace ) ) { return; } // Add new type ast::Type\u0026amp; type = parser-\u0026gt;types[parser-\u0026gt;types_count++]; type.name = name; type.type = ast::Type::Types_Struct; type.exportable = true; // Parse struct internals while ( !equalToken( parser-\u0026gt;lexer, token, Token::Token_CloseBrace ) ) { if ( token.type == Token::Token_Identifier ) { declarationVariable( parser, token.text, type ); } } }  The parsing of a variable is even simpler, just a type followed by the name. When reading the type, it searches through the list of all types saved until then.\ninline void declarationVariable( Parser* parser, const StringRef\u0026amp; type_name, ast::Type\u0026amp; type ) { const ast::Type* variable_type = findType( parser, type_name ); Token token; // Name if ( !expectToken( parser-\u0026gt;lexer, token, Token::Token_Identifier ) ) { return; } // Cache name string StringRef name = token.text; if ( !expectToken( parser-\u0026gt;lexer, token, Token::Token_Semicolon ) ) { return; } type.types.emplace_back( variable_type ); type.names.emplace_back( name ); }  The parsing of the enum is:\n \u0026lsquo;enum\u0026rsquo; keyword Enum name (optional) Semicolon and type, taken from Flatbuffers syntax Open brace List of identifiers that corresponds to the enum values  \n inline void declarationEnum( Parser* parser ) { Token token; // Name if ( !expectToken( parser-\u0026gt;lexer, token, Token::Token_Identifier ) ) { return; } // Cache name string StringRef name = token.text; // Optional ': type' for the enum nextToken( parser-\u0026gt;lexer, token ); if ( token.type == Token::Token_Colon ) { // Skip to open brace nextToken( parser-\u0026gt;lexer, token ); // Token now contains type_name nextToken( parser-\u0026gt;lexer, token ); // Token now contains open brace. } if ( token.type != Token::Token_OpenBrace ) { return; } // Add new type ast::Type\u0026amp; type = parser-\u0026gt;types[parser-\u0026gt;types_count++]; type.name = name; type.type = ast::Type::Types_Enum; type.exportable = true; // Parse struct internals while ( !equalToken( parser-\u0026gt;lexer, token, Token::Token_CloseBrace ) ) { if ( token.type == Token::Token_Identifier ) { type.names.emplace_back( token.text ); } } }  A command is a special construct that I use in my code, normally with a CommandBuffer, and with the current syntax from HDF:\ncommand WindowEvents { Click { int16 x; int16 y; int16 button; } Move { int16 x; int16 y; } Wheel { int16 z; } };  And this is the parsing of the command.\nI think this can be the best example of mapping between the language and the parsing.\nParsing is:\n Name Open brace Scan of identifiers until close brace For each identifier, add a type and scan for internal variables.  \ninline void declarationCommand( Parser* parser ) { // name Token token; if ( !expectToken( parser-\u0026gt;lexer, token, Token::Token_Identifier ) ) { return; } // Cache name string StringRef name = token.text; if ( !expectToken( parser-\u0026gt;lexer, token, Token::Token_OpenBrace ) ) { return; } // Add new type ast::Type\u0026amp; command_type = parser-\u0026gt;types[parser-\u0026gt;types_count++]; command_type.name = name; command_type.type = ast::Type::Types_Command; command_type.exportable = true; // Parse struct internals while ( !equalToken( parser-\u0026gt;lexer, token, Token::Token_CloseBrace ) ) { if ( token.type == Token::Token_Identifier ) { // Create a new type for each command // Add new type ast::Type\u0026amp; type = parser-\u0026gt;types[parser-\u0026gt;types_count++]; type.name = token.text; type.type = ast::Type::Types_Struct; type.exportable = false; while ( !equalToken( parser-\u0026gt;lexer, token, Token::Token_CloseBrace ) ) { if ( token.type == Token::Token_Identifier ) { declarationVariable( parser, token.text, type ); } } command_type.names.emplace_back( type.name ); command_type.types.emplace_back( \u0026amp;type ); } } }  Abstract Syntax Tree We choose to simply have data definitions, and I’ve decided that the nodes of the tree will be types.\nA type can be a primitive type, a container of variables (like a Struct in C, but without methods) enums and commands.\nCommands are just a way of showing the creation of a construct that I use and requires some boilerplate code, but I don’t want to write that code.\nIf we remember the definition of the class Type from the code before, it all boils down to a name,a list of names and optionally types.\nWith this simple definition I can express primitive types, structs and enums all in one!\nFor enums, I save the anme of the enum and in the name list all the different values. That is enough to later generate the code.\nFor structs, again the name is saved, and then the variables. A variable is a tuple of identifiers ‘type, name’. When parsing them, the type is searched in the registered ones.\nA trick here is to initialize the parser with primitive types, and then add each type (both struct and enums) when parsing them.\nCode Generation The last stage will generate the files in the language that we want, using the informations from the AST.\nThis part will literally write the code for us, the all purpose of this code.\nThe most fundamental question is: “what code do I want to generate?”.\nA simple but deep question.\nWe are trying to remove the writing of boilerplate code from or lives, so anything that you consider boilerplate and easy to automate goes here. Even if until here we wrote in C++, the final output can be any language.\nThis means that you can define data and translate it to multiple languages!\nFor our example, we will output C++ code and add UI using ImGui, similar to the Flatbuffers example I wrote before.\nLet’s see the three different construct we can output with our language.\nEnum We defined an enum as a name and a list of named values. For the simplicity of this example, we are not assigning manual values to the enum, but it is something easily changeable, and I will do it in the future. Given the enum in HDF:\nenum BlendOperation : byte { Add, Subtract, RevSubtract, Min, Max }  Which code do we want to generate ?\nWhen I write enums, I almost always need the stringed version of the values. Also I want to add a last value, Count, so that I can use it if I need to allocate anything based on the enum.\nAs a bonus, I can create a second enum with the bit shifts — called mask — for some use cases.\nAll of this will be automatically done by the code generator, starting with a simple enum!\nIn this piece of code, I will use three different streams for the different parts of the enum (enum itself, value names and mask) and combine them into the final generated file.\nAlso to note that the strings here are ‘String Ref’ — basically a string that points to the input source code and stores the length of the string, so that there is no need to allocate it newly.\nI will use a temporary buffer to null terminate it and write into the output file.\nThis will be the generated code:\nnamespace BlendOperation { enum Enum { Add, Subtract, RevSubtract, Min, Max, Count }; enum Mask { Add_mask = 1 \u0026lt;\u0026lt; 0, Subtract_mask = 1 \u0026lt;\u0026lt; 1, RevSubtract_mask = 1 \u0026lt;\u0026lt; 2, Min_mask = 1 \u0026lt;\u0026lt; 3, Max_mask = 1 \u0026lt;\u0026lt; 4, Count_mask = 1 \u0026lt;\u0026lt; 5 }; static const char* s_value_names[] = { \u0026quot;Add\u0026quot;, \u0026quot;Subtract\u0026quot;, \u0026quot;RevSubtract\u0026quot;, \u0026quot;Min\u0026quot;, \u0026quot;Max\u0026quot;, \u0026quot;Count\u0026quot; }; static const char* ToString( Enum e ) { return s_value_names[(int)e]; } } // namespace BlendOperation  The enum itself (inside a namespace), a mask and the string version for debugging purposes.\nAll generated from that one line!\nLet\u0026rsquo;s go into a step by step review of the code.\nFirst there is the initialization of some auxiliary buffers to handle dynamic strings without allocating memory.\nThese are the usages:\n Values will contain all the enum comma separated values Value_names will contain the string version of the values Value_masks will contain an optional bitmask for the values. void outputCPPEnum( CodeGenerator* code_generator, FILE* output, const ast::Type\u0026amp; type ) { // Empty enum: skip output. if ( type.names.size() == 0 ) return; code_generator-\u0026gt;string_buffer_0.clear(); code_generator-\u0026gt;string_buffer_1.clear(); code_generator-\u0026gt;string_buffer_2.clear(); StringBuffer\u0026amp; values = code_generator-\u0026gt;string_buffer_0; StringBuffer\u0026amp; value_names = code_generator-\u0026gt;string_buffer_1; StringBuffer\u0026amp; value_masks = code_generator-\u0026gt;string_buffer_2;   We start by adding the character \u0026lsquo;\u0026ldquo;\u0026rsquo; in the names - they will be C strings!\nThen we have a couple of options, just as demonstration: add mask (for the bitmask) and add max, that adds a last element to the generated enum.\n value_names.append( \u0026quot;\\\u0026quot;\u0026quot; ); bool add_max = true; bool add_mask = true;  Next step is the core: go through all the names saved in the enum ast::Type during the parsing phase, and add the literal as is in the enum, the literal in string version and optional mask.\nWe also need to take care of the enum with 1 values, they behave in a different way.\n char name_buffer[256]; // Enums with more than 1 values if ( type.names.size() \u0026gt; 1 ) { const uint32_t max_values = type.names.size() - 1; for ( uint32_t v = 0; v \u0026lt; max_values; ++v ) { if ( add_mask ) { value_masks.append( type.names[v] ); value_masks.append( \u0026quot;_mask = 1 \u0026lt;\u0026lt; \u0026quot; ); value_masks.append( _itoa( v, name_buffer, 10 ) ); value_masks.append( \u0026quot;, \u0026quot; ); } values.append( type.names[v] ); values.append( \u0026quot;, \u0026quot; ); value_names.append( type.names[v] ); value_names.append( \u0026quot;\\\u0026quot;, \\\u0026quot;\u0026quot; ); } if ( add_mask ) { value_masks.append( type.names[max_values] ); value_masks.append( \u0026quot;_mask = 1 \u0026lt;\u0026lt; \u0026quot; ); value_masks.append( _itoa( max_values, name_buffer, 10 ) ); } values.append( type.names[max_values] ); value_names.append( type.names[max_values] ); value_names.append( \u0026quot;\\\u0026quot;\u0026quot; ); } else { if ( add_mask ) { value_masks.append( type.names[0] ); value_masks.append( \u0026quot;_mask = 1 \u0026lt;\u0026lt; \u0026quot; ); value_masks.append( _itoa( 0, name_buffer, 10 ) ); } values.append( type.names[0] ); value_names.append( type.names[0] ); value_names.append( \u0026quot;\\\u0026quot;\u0026quot; ); }  After writing all the values we can add the optional max value in the output:\n if ( add_max ) { values.append( \u0026quot;, Count\u0026quot; ); value_names.append( \u0026quot;, \\\u0026quot;Count\\\u0026quot;\u0026quot; ); if ( add_mask ) { value_masks.append( \u0026quot;, Count_mask = 1 \u0026lt;\u0026lt; \u0026quot; ); value_masks.append( _itoa( type.names.size(), name_buffer, 10 ) ); } }  Until now we just saved all those values in the StringBuffers, but still not in the file.\nThe final piece of code output to file the enum with all the additional data:\n copy( type.name, name_buffer, 256 ); fprintf( output, \u0026quot;namespace %s {\\n\u0026quot;, name_buffer ); fprintf( output, \u0026quot;\\tenum Enum {\\n\u0026quot; ); fprintf( output, \u0026quot;\\t\\t%s\\n\u0026quot;, values.data ); fprintf( output, \u0026quot;\\t};\\n\u0026quot; ); // Write the mask if ( add_mask ) { fprintf( output, \u0026quot;\\n\\tenum Mask {\\n\u0026quot; ); fprintf( output, \u0026quot;\\t\\t%s\\n\u0026quot;, value_masks.data ); fprintf( output, \u0026quot;\\t};\\n\u0026quot; ); } // Write the string values fprintf( output, \u0026quot;\\n\\tstatic const char* s_value_names[] = {\\n\u0026quot; ); fprintf( output, \u0026quot;\\t\\t%s\\n\u0026quot;, value_names.data ); fprintf( output, \u0026quot;\\t};\\n\u0026quot; ); fprintf( output, \u0026quot;\\n\\tstatic const char* ToString( Enum e ) {\\n\u0026quot; ); fprintf( output, \u0026quot;\\t\\treturn s_value_names[(int)e];\\n\u0026quot; ); fprintf( output, \u0026quot;\\t}\\n\u0026quot; ); fprintf( output, \u0026quot;} // namespace %s\\n\\n\u0026quot;, name_buffer ); }  Struct Structs are the bread-and-butter of data definition. In this simple example we do not handle pointers or references, so it is pretty straight-forward, but as a start in coding generation this could already be powerful for many cases. Let’s start with a definition for our dream Data-Driven-Rendering:\n// file.hdf struct RenderTarget { uint16 width; uint16 height; float scale_x; float scale_y; TextureFormat format; }; struct RenderPass { RenderTarget rt0; };  We want to generate both the ready to use header in C++ and UI using ImGui.\nThe output for this struct will be obtained by simply iterating through all its members and, based on the type of the member, write some code.\nFor primitive types there is a translation that must be done to the C++ language — thus we saved a list of c++ primitive types keyword into the code.\nFor the UI area we will define two methods: reflectMembers, that simply adds the ImGui commands needed, and reflectUI, that embeds the members into a Window. This is done so that when starting from a root type I can create a window that let me edit its value, and recursively it can add other member’s UI if they are coming from another struct.\nThis is shown with the RenderPass struct.\nThis will be the generated code, that includes ImGui too:\n// CodeGenerated.h struct RenderTarget { uint16_t width; uint16_t height; float scale_x; float scale_y; TextureFormat::Enum format; void reflectMembers() { ImGui::InputScalar( \u0026quot;width\u0026quot;, ImGuiDataType_U16, \u0026amp;width ); ImGui::InputScalar( \u0026quot;height\u0026quot;, ImGuiDataType_U16, \u0026amp;height ); ImGui::InputScalar( \u0026quot;scale_x\u0026quot;, ImGuiDataType_Float, \u0026amp;scale_x ); ImGui::InputScalar( \u0026quot;scale_y\u0026quot;, ImGuiDataType_Float, \u0026amp;scale_y ); ImGui::Combo( \u0026quot;format\u0026quot;, (int32_t*)\u0026amp;format, TextureFormat::s_value_names, TextureFormat::Count ); } void reflectUI() { ImGui::Begin(\u0026quot;RenderTarget\u0026quot;); reflectMembers(); ImGui::End(); } }; // struct RenderTarget  Now let\u0026rsquo;s have a look at the code that will generate that.\nFirst some init steps: clear and alias the StringBuffer, allocate some char buffers on the stack, copy the StringRef into the name buffer:\n void outputCPPStruct( CodeGenerator* code_generator, FILE* output, const ast::Type\u0026amp; type ) { const char* tabs = \u0026quot;\u0026quot;; code_generator-\u0026gt;string_buffer_0.clear(); StringBuffer\u0026amp; ui_code = code_generator-\u0026gt;string_buffer_0; char name_buffer[256], member_name_buffer[256], member_type_buffer[256]; copy( type.name, name_buffer, 256 );  Next is already a powerful piece of code.\nOutputting the UI code and iterating through each member.\n if ( code_generator-\u0026gt;generate_imgui ) { ui_code.append( \u0026quot;\\n\\tvoid reflectMembers() {\\n\u0026quot; ); } fprintf( output, \u0026quot;%sstruct %s {\\n\\n\u0026quot;, tabs, name_buffer ); for ( int i = 0; i \u0026lt; type.types.size(); ++i ) { const ast::Type\u0026amp; member_type = *type.types[i]; const StringRef\u0026amp; member_name = type.names[i]; copy( member_name, member_name_buffer, 256 );  We are in the middle of the loop, and we want to check if the current member type is a primitive one, then it needs some work to do.\nFirst, output the language specific primitive type keyword (using the s_primitive_type_cpp array).\nSecond, add some ImGui code to edit the field directly.\n // Translate type name based on output language. switch ( member_type.type ) { case ast::Type::Types_Primitive: { strcpy_s( member_type_buffer, 256, s_primitive_type_cpp[member_type.primitive_type] ); fprintf( output, \u0026quot;%s\\t%s %s;\\n\u0026quot;, tabs, member_type_buffer, member_name_buffer ); if ( code_generator-\u0026gt;generate_imgui ) { switch ( member_type.primitive_type ) { case ast::Type::Primitive_Int8: case ast::Type::Primitive_Uint8: case ast::Type::Primitive_Int16: case ast::Type::Primitive_Uint16: case ast::Type::Primitive_Int32: case ast::Type::Primitive_Uint32: case ast::Type::Primitive_Int64: case ast::Type::Primitive_Uint64: case ast::Type::Primitive_Float: case ast::Type::Primitive_Double: { ui_code.append( \u0026quot;\\t\\tImGui::InputScalar( \\\u0026quot;%s\\\u0026quot;, %s, \u0026amp;%s );\\n\u0026quot;, member_name_buffer, s_primitive_type_imgui[member_type.primitive_type], member_name_buffer ); break; } case ast::Type::Primitive_Bool: { ui_code.append( \u0026quot;\\t\\tImGui::Checkbox( \\\u0026quot;%s\\\u0026quot;, \u0026amp;%s );\\n\u0026quot;, member_name_buffer, member_name_buffer ); break; } } } break; }  In case of a struct as a member, use the typename as is and call the \u0026lsquo;reflectMembers\u0026rsquo; method for the UI generation:\n case ast::Type::Types_Struct: { copy( member_type.name, member_type_buffer, 256 ); fprintf( output, \u0026quot;%s\\t%s %s;\\n\u0026quot;, tabs, member_type_buffer, member_name_buffer ); if ( code_generator-\u0026gt;generate_imgui ) { ui_code.append( \u0026quot;\\t\\tImGui::Text(\\\u0026quot;%s\\\u0026quot;);\\n\u0026quot;, member_name_buffer ); ui_code.append( \u0026quot;\\t\\t%s.reflectMembers();\\n\u0026quot;, member_name_buffer ); } break; }  For enums use the format namespace::Enum that comes with the generated code (and can be anything else) and add a Combo for ImGui. The combo is using the string array generated previously! This is powerful!\n case ast::Type::Types_Enum: { copy( member_type.name, member_type_buffer, 256 ); fprintf( output, \u0026quot;%s\\t%s::Enum %s;\\n\u0026quot;, tabs, member_type_buffer, member_name_buffer ); if ( code_generator-\u0026gt;generate_imgui ) { ui_code.append( \u0026quot;\\t\\tImGui::Combo( \\\u0026quot;%s\\\u0026quot;, (int32_t*)\u0026amp;%s, %s::s_value_names, %s::Count );\\n\u0026quot;, member_name_buffer, member_name_buffer, member_type_buffer, member_type_buffer ); } break; }  To finish up simlpy add the reflectUI method, that embed the members reflection in a window and finish.\n default: { break; } } } ui_code.append( \u0026quot;\\t}\u0026quot; ); ui_code.append( \u0026quot;\\n\\n\\tvoid reflectUI() {\\n\\t\\tImGui::Begin(\\\u0026quot;%s\\\u0026quot;);\\n\\t\\treflectMembers();\\n\\t\\tImGui::End();\\n\\t}\\n\u0026quot;, name_buffer ); fprintf( output, \u0026quot;%s\\n\u0026quot;, ui_code.data ); fprintf( output, \u0026quot;\\n%s}; // struct %s\\n\\n\u0026quot;, tabs, name_buffer ); }  Command I wanted to include an example of something that does not exist in any language, but it shows the power of removing boilerplate code.\nI define commands as little structs with a type used anytime I need to do some command parsing, normally from a ring buffer.\nThe command should have an enum with all the types already, and each struct should have its type assigned. The type is normally used to cycle through the commands and do something accordingly.\nIt will output structs because of the need to allocate them in the ring buffer, thus must be simple.\nFirst let\u0026rsquo;s see the HDF file. The example are window events commands:\ncommand WindowEvents { Click { int16 x; int16 y; int16 button; } Move { int16 x; int16 y; } Wheel { int16 z; } };  The generated code will be:\nnamespace WindowEvents { enum Type { Type_Click, Type_Move, Type_Wheel }; struct Click { int16_t x; int16_t y; int16_t button; static Type GetType() { return Type_Click; } }; // struct Wheel struct Move { int16_t x; int16_t y; static Type GetType() { return Type_Move; } }; // struct Wheel struct Wheel { int16_t z; static Type GetType() { return Type_Wheel; } }; // struct Wheel }; // namespace WindowEvents  And finally the C++ code that generates the output.\nThe output starts with an enum with all the types, that I normally use to switch commands:\nvoid outputCPPCommand( CodeGenerator* code_generator, FILE* output, const ast::Type\u0026amp; type ) { char name_buffer[256], member_name_buffer[256], member_type_buffer[256]; copy( type.name, name_buffer, 256 ); fprintf( output, \u0026quot;namespace %s {\\n\u0026quot;, name_buffer ); // Add enum with all types fprintf( output, \u0026quot;\\tenum Type {\\n\u0026quot; ); fprintf( output, \u0026quot;\\t\\t\u0026quot; ); for ( int i = 0; i \u0026lt; type.types.size() - 1; ++i ) { const ast::Type\u0026amp; command_type = *type.types[i]; copy( command_type.name, name_buffer, 256 ); fprintf( output, \u0026quot;Type_%s, \u0026quot;, name_buffer ); } const ast::Type* last_type = type.types[type.types.size() - 1]; copy( last_type-\u0026gt;name, name_buffer, 256 ); fprintf( output, \u0026quot;Type_%s\u0026quot;, name_buffer ); fprintf( output, \u0026quot;\\n\\t};\\n\\n\u0026quot; );  Then we output all the command structs (like Click, Move, \u0026hellip;).\nFor each command type we output a struct with all its members. This is similar to the output of the structs:\n const char* tabs = \u0026quot;\\t\u0026quot;; for ( int i = 0; i \u0026lt; type.types.size(); ++i ) { const ast::Type\u0026amp; command_type = *type.types[i]; copy( command_type.name, member_type_buffer, 256 ); fprintf( output, \u0026quot;%sstruct %s {\\n\\n\u0026quot;, tabs, member_type_buffer ); for ( int i = 0; i \u0026lt; command_type.types.size(); ++i ) { const ast::Type\u0026amp; member_type = *command_type.types[i]; const StringRef\u0026amp; member_name = command_type.names[i]; copy( member_name, member_name_buffer, 256 ); // Translate type name based on output language. switch ( member_type.type ) { case ast::Type::Types_Primitive: { strcpy_s( member_type_buffer, 256, s_primitive_type_cpp[member_type.primitive_type] ); fprintf( output, \u0026quot;%s\\t%s %s;\\n\u0026quot;, tabs, member_type_buffer, member_name_buffer ); break; } case ast::Type::Types_Struct: { copy( member_type.name, member_type_buffer, 256 ); fprintf( output, \u0026quot;%s\\t%s %s;\\n\u0026quot;, tabs, member_type_buffer, member_name_buffer ); break; } case ast::Type::Types_Enum: { copy( member_type.name, member_type_buffer, 256 ); fprintf( output, \u0026quot;%s\\t%s::Enum %s;\\n\u0026quot;, tabs, member_type_buffer, member_name_buffer ); break; } default: { break; } } } copy( command_type.name, member_type_buffer, 256 ); fprintf( output, \u0026quot;\\n%s\\tstatic Type GetType() { return Type_%s; }\\n\u0026quot;, tabs, member_type_buffer ); fprintf( output, \u0026quot;\\n%s}; // struct %s\\n\\n\u0026quot;, tabs, name_buffer ); } copy( type.name, name_buffer, 256 ); fprintf( output, \u0026quot;}; // namespace %s\\n\\n\u0026quot;, name_buffer ); }  Conclusions We learnt how to write a complete Code Generator, an incredible tool that can speed up the development if used correctly and remove most boilerplate code possible.\nThe usage of the command keyword was an example of something I use and I don’t want to write code, something that is custom enough and hopefully will give you more ideas on how you can break free from languages constriction when you write…your own language!\nIn the quest for data-driven rendering, the next step will be to use the knowledge from code generation to create a shader effect language, that can generate both CPU and GPU code for you.\nThis article is the longest and more code-heavy I have ever written. There are many concepts that I am beginning to be familiar with, but still not so used to.\nSo please comment, give feedback, share! Thank you for reading!\n","date":1564267563,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1565131563,"objectID":"3b9e1a648d0f65843a8cdecb32355e6c","permalink":"/post/writing_a_simple_code_generator/","publishdate":"2019-07-27T18:46:03-04:00","relpermalink":"/post/writing_a_simple_code_generator/","section":"post","summary":"UI using ImGUI, SDL and the code generated with this article.   Motivation Following my previous article about Flatbuffers and data reflection the quest for Data-Driven Rendering continues!\nIn this article I want to show how to write a very simple code-generator to help you automate writing of code in any language.\nThe code is here:\nhttps://github.com/JorenJoestar/DataDrivenRendering\nThere is a balance that constantly needs to be found between code and data, and having a code-generator in my opinion helps tremendously in focus on the code that is necessary to be written.","tags":[],"title":"Writing a simple Code Generator","type":"post"},{"authors":[],"categories":[],"content":"   Some of the UI for the Hydra NES emulator, using ImGUI.   Writing an emulator is an incredibly fun learning experience.\nIt is an exquisite exercise in reverse-engineering from both documentation and code.\nIn this post I want to share some tips on how and where to start based on my experience on the NES emulator I am writing.\nInformation The gathering of information is the most important (and hard!) process that will live through all the writing process.\nLuckily for use there are many websites that are coming to rescue us:\nhttps://wiki.nesdev.com/w/index.php/NES_reference_guide\nhttp://forums.nesdev.com/\nhttp://obelisk.me.uk/6502/reference.html\nhttp://www.oxyron.de/html/opcodes02.html\nIt is paramount to create a list of websites and resources (maybe through some notes, like in Evernote or such) about different topics regarding the hardware to be emulated.\nHaving a central hub is powerful and counteract the sparseness of the different informations (some in txt files, different websites, forum blogposts, …).\nI can’t stress enough how important it is.\nLuckily for us the amazing NesDev Wiki is the hub you need!\nAlmost every possible information you need is there.\nArchitecture Next step is to understand the architecture.\nWrite diagrams, take notes, search for the relationships of the component.\nWhat does every hardware component do ?\nWhat can that specific hardware piece access to ?\nAs you will see, writing the emulator is an iterative process of improving each component until you have something that works very well, and then refine for an infinite amount of time.\nOn a very basic level, there should be a CPU, some form of GPU (PPU, Picture Processing Unit), some audio chip, some input peripheral and cartridge/disc/rom.\nNES architecture The NES is a beautiful machine equipped with the following:\nCPU : Ricoh RP2A03 (NTSC) / RP2A07 (PAL) 8 bit processor that contains both CPU and APU (audio) hardware. The addresses are 16 bit, but the data is 8. It contains only specific registers: 2 indices, accumulator, stack pointer, program counter and status.\nPPU : Ricoh RP2C02 (NTSC) / RP2C07 (PAL) This is what today would be called GPU. It outputs to a 256x240 pixels buffer, it has 2kib or RAM, 32 bytes for palette RAM and 288 bytes for sprite RAM. The PPU is tile based and it takes 8 PPU cycles to load a line of a background tile. Sprites are sent through DMA and background is filled during Vertical Blank state normally. A frame lasts more scanline that the one visible, so that the game can upload data to the PPU when not rendering.\nAPU : Ricoh RP2A03 (NTSC) / RP2A07 (PAL) (Contained in the CPU itself.) The sound is analogic and it comes from 5 different channels: 2 pulse, 1 triangle, 1 noise and 1 DMC. All the channels aside from the DMC create signals that are combined to output the sounds and music. The DMC loads samples using the DMA.\nCartridge/Mappers : This is a very unique topic strict to the NES as far as I know. Cartridges had unique hardware and they were used to swap banks of memory in realtime to access different parts of the cartridge. There are hundred of mappers that have unique behaviours! The biggest gist of the mappers is how they switch banks: by WRITING to the address where the execution code is it triggers the bank-switching logic. There can be internal batteries and working RAMs too, but they are very rare.\nMemory mapped I/O The different hardware access using ‘memory mapped I/O’, that is a way of saying that when you read or write to a specific address it could be memory or it could be an hardware-component.\nExamples: reading from address 0x4016 gives you the gamepad status, while reading from 0x1000 reads from the CPU ram.\nHaving clear these accesses will help in understanding even better the machine.\nBoth CPU and PPU have different memory maps. Let\u0026rsquo;s see them, it will help in understanding the internal of the NES better.\nCPU Memory Map    The CPU can access basically every hardware component in the NES.\nPPU, APU, gamepads, both read and write.\nIt reads the ROM part of a cartridge (called PRG) and executes its instructions.\nThrough PPU registers it can instruct the PPU to read graphical informations from the CHR part of the cartridge.\nIt can upload sprites on the PPU Sprite Memory through DMA, upload data to the APU, or manage its internal RAM.\nFrom the source code, this is a working example of CPU Reading method:\nuint8 Nes::MemoryController::CpuRead( uint16 address ) { if ( address \u0026lt; 0x2000 ) { return cpu-\u0026gt;ram[address \u0026amp; 0x7FF]; } else if ( address \u0026lt; 0x4000 ) { return ppu-\u0026gt;CpuRead( address ); } else if ( address \u0026lt; 0x4014 ) { return apu-\u0026gt;CpuRead( address ); } else if ( address \u0026gt;= 0x4018 ) { return mapper-\u0026gt;PrgRead( address ); } switch ( address ) { case 0x4015: { return apu-\u0026gt;ReadStatus(); break; } case 0x4016: { return controllers-\u0026gt;ReadState(); break; } case 0x4017: { return 0x40; break; } } return 0; }  And CPU Write:\nvoid Nes::MemoryController::CpuWrite( uint16 address, uint8 data ) { if ( address \u0026lt; 0x2000 ) { cpu-\u0026gt;ram[address \u0026amp; 0x7FF] = data; } else if ( address \u0026lt; 0x4000 ) { ppu-\u0026gt;CpuWrite( address, data ); return; } else if ( address \u0026lt; 0x4014 ) { return apu-\u0026gt;CpuWrite( address, data ); } else if ( address \u0026gt;= 0x4018 ) { mapper-\u0026gt;PrgWrite( address, data ); return; } switch ( address ) { // Sprite DMA case 0x4014: { cpu-\u0026gt;ExecuteSpriteDMA( data ); return; break; } case 0x4015: case 0x4017: { apu-\u0026gt;CpuWrite( address, data ); return; break; } case 0x4016: { controllers-\u0026gt;WriteState( data ); return; break; } } }  The pattern is always the same: check the address of the instruction and choose which hardware component to interact with.\nHopefully its clear that based on the address different components can be accessed. Let\u0026rsquo;s have a look at the PPU too.\nPPU Memory Map    Similar to the CPU, reading and writing on the PPU access different components, even though they are far less.\nThe PPU either accesses its 2 rams (palette and nametable, normally from the CPU) or reads the CHR (that is the graphical data stored in the cartridge) memory.\nReading:\nuint8 Nes::MemoryController::PpuRead( uint16 address ) { address \u0026amp;= 0X3FFF; if ( address \u0026lt;= 0x1FFF ) { return mapper-\u0026gt;ChrRead( address ); } else if ( address \u0026lt;= 0x3EFF ) { return ppu-\u0026gt;nametableRam[NameTableMirroring( address, mapper-\u0026gt;mirroring )]; } else if ( address \u0026lt;= 0x3FFF ) { // Palette mirroring is handled in the write code. return ppu-\u0026gt;paletteRam[address \u0026amp; 0x1F] \u0026amp; ((ppu-\u0026gt;mask \u0026amp; Nes::Ppu::MaskFlag_GreyScale ? 0x30 : 0xFF)); } return 0; }  On the writing side, there the code shows the intricancy of emulation. When writing to the paletter ram, there is a mirroring mechanism happening in the hardware that is emulated with a lookup table. Something to look out to: writing to CHR is 99% of the time useless, unless there is an additional RAM in the cartdige.\nvoid Nes::MemoryController::PpuWrite( uint16 address, uint8 data ) { address \u0026amp;= 0X3FFF; if ( address \u0026lt;= 0x1FFF ) { mapper-\u0026gt;ChrWrite( address, data ); return; } else if ( address \u0026lt;= 0x3EFF ) { ppu-\u0026gt;nametableRam[NameTableMirroring( address, mapper-\u0026gt;mirroring )] = data; return; } else if ( address \u0026lt;= 0x3FFF ) { static uint8 const palette_write_mirror[0x20] = { 0x10, 0x01, 0x02, 0x03, 0x14, 0x05, 0x06, 0x07, 0x18, 0x09, 0x0A, 0x0B, 0x1C, 0x0D, 0x0E, 0x0F, 0x00, 0x11, 0x12, 0x13, 0x04, 0x15, 0x16, 0x17, 0x08, 0x19, 0x1A, 0x1B, 0x0C, 0x1D, 0x1E, 0x1F }; ppu-\u0026gt;paletteRam[palette_write_mirror[address \u0026amp; 0x1F]] = data; return; } }  Takeaways I created the memory controller as the main dispatcher of data between hardware components, to separate the duties better. We can see the following relationships based on that:\n CPU can access PPU, APU, controllers and cartridge (PRG) PPU can access screen, its own rams and cartridge (CHR) memory controller is the hub that connects everything  I am not sure this is the best emulator architecture, but that is what I figured out.\nTest roms A fundamental approach to create a robust emulator is to have some tests to rely on.\nSadly it is not common for all hardware, but again the NES provide plenty of roms that tests almost every aspect of your emulator!\nIt quickly becomes a test-driven development.\nNES test roms link\nFind roms, read the source code and try to understand what they are doing and why.\nCoding start If you are writing your first emulator, I suggest to focus mostly on the emulation part.\nWhat do I mean by that ?\nAvoid trying too many things at once!\nFocus your energies towards the emulation.\nUse libraries that are reliable and simple and that you know.\nGLFW, SDL2, etc are your friends here.\nYou want to eliminate most unknowns unknowns before hand.\nOf course, if you are brave enough, you can also write an emulator in a new language.\nBut for me, I preferred to concentrate on the emulation side first, in C++, using my core library, especially knowing that I could dedicate some night-time here and there, No surprises (not really true, still some happened!).\nI will possibly port the emulator to use SDL if needed, but right now the emulation code is the most important.\nThis is the mantra that helped me concentrate only on the emulation code. Again, writing-wise I am not happy about the code quality. But what I am learning from different perspectives is invaluable!\nNES coding start The quintessential basic steps to start a NES emulator coding are:\n Write CPU basics (fetch/decode/execute loop, registers) Basic memory bus (read/write to/from memory and registers) Load a rom and start executing instruction step by step.  It is already a lot, and it will require to read multiple times the different wiki pages and forum posts.\nFor a typical console, the main loop (simplified) can be something like this:\nvoid CpuTick() { uint8_t opcode = Read(program_counter++); uint8_t operand = FetchOperand(opcode); ExecuteOpcode(opcode, operand); } void ExecuteFrame() { uint32_t cycles_per_frame = … while (cycles_per_frame — ) { CpuTick(); } }  To jumpstart your NES emulator you can use the majestic rom nestest.nes and its log file: it gives you a test of all instructions of the CPU and prints the status of the CPU after each one.\nAlso it does not require any PPU rendering: compare the status of your CPU with the text file line by line and its done!\nYou can see some ugly but useful code in MainState::ExecuteCpuTest in my emulator for an idea.\nA line from the nestest.log file looks like this:\n// C000 4C F5 C5 JMP $C5F5 A:00 X:00 Y:00 P:24 SP:FD PPU: 0, 0 CYC:7  it gives you the ProgramCounter (C000), byte code (1, 2 or 3 bytes depending on the instructions), human-readable-instruction (JMP) , the CPU register contents (A, X, Y, P, SP) and the theorethical PPU scanline, pixel and clock cycle.\nThere are two interesting points:\n The ProgramCounter before execution should be set to C000 for this rom only and only when logging. The CPU cycles STARTS at 7. In a power-up/reset method there is some work done BEFORE executing any code. This is needed only if you want to have a precise cycle-to-cycle comparison.  You can create a simple test method like this:\nvoid TestEmulatorCPU() { Reset(); while(true) { CpuTick(); CompareCpuStatusWithLog(); } }  and catch the problems in your CPU instructions implementation!\nConclusion This is a little help in understanding how to start with an emulator.\nIt is a beautiful journey, but it is full of trial and errors.\nI am myself far from over with my emulator, and also far from being happy on HOW I write the emulator itself.\nThere are emulators of much more complex machines out there (almost every machine you can imagine!) and it blows my mind to know there are people that can emulate such complex hardware.\nThe ideal situation would be to being able of not being lost in visual emulation of the circuitry, but for now that is out of my league.\nI am thinking of creating some a series of videos and code associated starting from scratch, if anyone is interested. Please leave a comment/feedback on the article, the source code, anything!\nI hope it will help.\n","date":1564267535,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564267535,"objectID":"33334c3b94bfe395ca48dde1b71dc142","permalink":"/post/emulation_where_to_start/","publishdate":"2019-07-27T18:45:35-04:00","relpermalink":"/post/emulation_where_to_start/","section":"post","summary":"Some of the UI for the Hydra NES emulator, using ImGUI.   Writing an emulator is an incredibly fun learning experience.\nIt is an exquisite exercise in reverse-engineering from both documentation and code.\nIn this post I want to share some tips on how and where to start based on my experience on the NES emulator I am writing.\nInformation The gathering of information is the most important (and hard!","tags":[],"title":"Emulation: where to start? A use case.","type":"post"},{"authors":[],"categories":[],"content":"   Auto generated UI from Flatbuffers files.   Motivation Finding a good balance between code and data in Rendering.\nWhat is the necessary code that should be written ?\nWhy ?\nIn rendering many areas can be described in a fast and robust way using data.\nA pipeline (in D3D12/Vulkan lingo) for example is a collection of different states: depth stencil, alpha blend, rasterizer, shaders, etc.\nAll those state can be hard-coded or defined in data.\nMoving them to data can help with the visibility of them, that instead of being buried somewhere into the code can be retrieved before even running the application.\nAs a bigger-scope example, a frame-graph can be implicitly defined inside the code, if different areas, or in data.\nRecent posts about it started raising attention to the problem, especially after the introduction of lower-level APIs like D3D12 and Vulkan and their resource barriers.\nI’ve personally used something like json (xml back in the day) since 2009, after asking myself the very silly question:\n what is the biggest dependency in rendering?\nRender Targets!\n Since then I saw only in the Codemasters postprocess system (since Dirt 2) a similar approach, and have never being able to advocate towards it.\nThe only full use case I have is my personal indie game (a full deferred rendering pipeline with many different rendering needs) all defined in a json file (render_pipeline.json).\nAnyway, a couple of examples of this data-driven mentality can be found here:\n  FrameGraph: Extensible Rendering Architecture in Frostbite  from Electronic Arts / DICE \nhttp://bitsquid.blogspot.com/2017/03/stingray-renderer-walkthrough-7-data.html\nI chose to see what is a good way of describing low-level rendering resources, the bricks towards data-driven rendering.\nI’ve already tried defining them in a json file, but wanted something more direct — something I can copy easily with minimal parsing.\nI found 4 possible approaches:\n Custom data language Already existing data language Json (already used) Hard-coding everything  In this experiment I’ve chosen Flatbuffers for the easy of use, the good performances and the feature set that seems complete.\nAs an exercise, I wanted to create some UI based on the data coming from Flatbuffers without having to write too much code.\nFlatbuffers Flatbuffers is a serialization library developer by Google used by many companies.\nhttps://google.github.io/flatbuffers/\nCompared to Protocol Buffers (still developed by Google) it tries to go towards a very simple parsing/unpacking (actually ABSENT in Flatbuffers, so much faster to read/write) and serialization speed.\nFlatbuffers is mainly a compiler that accepts .fbs (FlatBuffers Schema) files and can generate code for serialization purposes.\nThe advantage is that it automatically generates the parsing files in the language you prefer (C++, Java, C#, Go, C, Lua, Javascript, Rust) without you needing to write the always tedious serialize/deserialize methods.\nIt is largely based on either simple c-structs or tables with offsets for more complex object.\nThe objective here will be to create a schema file, define a couple of resources (like textures) and use those to automatically generate UI.\nI will be using the SDL + ImGUI sample from the amazing ImGUI as a base.\nThe flow will be the following:\n Write schema files Generate reflection informations Parse schemas Generate UI  Schema Files Let’s write our first schema file. A bigger version (that I am using for my low-level renderer) is included in the github repository.\nnamespace rendering; enum TextureFormat : ushort { UNKNOWN, R32G32B32A32_TYPELESS, R32G32B32A32_FLOAT, R32G32B32A32_UINT, R32G32B32A32_SINT, R32G32B32_TYPELESS, R32G32B32_FLOAT, R32G32B32_UINT, R32G32B32_SINT, R16G16B16A16_TYPELESS, R16G16B16A16_FLOAT, R16G16B16A16_UNORM, R16G16B16A16_UINT, R16G16B16A16_SNORM, R16G16B16A16_SINT, R32G32_TYPELESS, R32G32_FLOAT, R32G32_UINT, R32G32_SINT, R10G10B10A2_TYPELESS, R10G10B10A2_UNORM, R10G10B10A2_UINT, R11G11B10_FLOAT, R8G8B8A8_TYPELESS, R8G8B8A8_UNORM, R8G8B8A8_UNORM_SRGB, R8G8B8A8_UINT, R8G8B8A8_SNORM, R8G8B8A8_SINT, R16G16_TYPELESS, R16G16_FLOAT, R16G16_UNORM, R16G16_UINT, R16G16_SNORM, R16G16_SINT, R32_TYPELESS, R32_FLOAT, R32_UINT, R32_SINT, R8G8_TYPELESS, R8G8_UNORM, R8G8_UINT, R8G8_SNORM, R8G8_SINT, R16_TYPELESS, R16_FLOAT, R16_UNORM, R16_UINT, R16_SNORM, R16_SINT, R8_TYPELESS, R8_UNORM, R8_UINT, R8_SNORM, R8_SINT, R9G9B9E5_SHAREDEXP, D32_FLOAT_S8X24_UINT, D32_FLOAT, D24_UNORM_S8_UINT, D24_UNORM_X8_UINT, D16_UNORM, S8_UINT, BC1_TYPELESS, BC1_UNORM, BC1_UNORM_SRGB, BC2_TYPELESS, BC2_UNORM, BC2_UNORM_SRGB, BC3_TYPELESS, BC3_UNORM, BC3_UNORM_SRGB, BC4_TYPELESS, BC4_UNORM, BC4_SNORM, BC5_TYPELESS, BC5_UNORM, BC5_SNORM, B5G6R5_UNORM, B5G5R5A1_UNORM, B8G8R8A8_UNORM, B8G8R8X8_UNORM, R10G10B10_XR_BIAS_A2_UNORM, B8G8R8A8_TYPELESS, B8G8R8A8_UNORM_SRGB, B8G8R8X8_TYPELESS, B8G8R8X8_UNORM_SRGB, BC6H_TYPELESS, BC6H_UF16, BC6H_SF16, BC7_TYPELESS, BC7_UNORM, BC7_UNORM_SRGB, FORCE_UINT } attribute \u0026quot;ui\u0026quot;; struct RenderTarget { width : ushort (ui: \u0026quot;min:1, max:16384\u0026quot;); height : ushort; scale_x : float; scale_y : float; format : TextureFormat; }  There are few things here to discuss.\n Enums. Flatbuffers can generate enums with string version of each values and conversions between enum and string. Struct. It is exactly like C/C++: a simple struct that can be memcopied. Different than a Table (that can point to other structs and Tables). Attributes. This can be used to define custom parsable attributes linked to a member of a struct/table. They can be used, for example, to drive the UI generation.  Generating Reflection Informations After we generated the schema file, we can serialize it and load/save it from disk. But we need reflection data to be able to automatically generate the UI we need! There are two main reflection mechanisms in Flatbuffers: mini-reflection and full-reflection. We will use both to generate a UI using ImGUI and see the differences.\nMini-Reflection This is the simplest of the two and works by generating an additional header file for each .fbs file we use. The command line is the following:\nflatc --cpp RenderDefinitions.fbs --reflect-names  This will generate the RenderDefinitions_Generated.h file that must be included in your application and has the downside of needing you to recompile every time you change the data.\nAlso, and this is the biggest downside, I could not find any way to parse custom per-member attributes.\nI hope I am wrong, but could not find any documentation on the topic: everything seems to point towards the full reflection mechanism.\nSo why bothering with the mini-reflection ?\nMini-reflection generates code, and this became useful for one of the most tedious C/C++ code to write: enums!\nI can’t count how many times I wrote an enum, I wanted the string with the same value for it (for example to read from a json file and get the proper enum value) and every time an enum is changed is painful.\nSo a lesson from the mini-reflection is to have a code-generator for enums for C/C++, and I will show an example soon in another article.\nBack to the enums, Flatbuffers generates:\n Enum Name array Value array Enum to name method  A nice property of the generated code for the enum is that it is easy to copy-paste in any c++ file — no Flatbuffers involved!\nThis is my first choice now when I want to write an enum in any c++ application.\nFull-reflection This is the most used (or at least documented) form of reflection in Flatbuffers.\nIt use a very elegant solution, totally data-driven: it reads a reflection schema file that can parse…ANY other schema!\nThis very Inception-esque mechanism gives the full access to all the types, including Attributes.\nBy executing this command:\nflatc.exe -b --schema reflection.fbs RenderDefinitions.fbs  the RenderDefinitions.bfbs (binary fbs) file is generated.\nThis is the file that needs to be read to fully reflect the types inside the .fbs file. The order of operations is the following:\n Generate a binary fbs with flatc (with the command line shown) Load the bfbs file generated Load the schema from the bfbs Reflect  The fbfs file contains all the informations from the schema: types, enums, attributes.\nParsing schemas and Generating UI For both reflection mechanisms the objective is the same: given a type (RenderTarget) generate an editor that can edit properties and potentially load/save them.\nMini-Reflection The UI generation is pretty straightforward with mini-reflection.\nEach type defined in the .fbs file contains a type_name-TypeTable() method that gives accent to a TypeTable.\nThis contains a list of per-member type, name and default values.\nWhat is really missing here is the attributes, that could be used to generate custom UI in a more specific way (eg. adding a min/max/step to a slider).\nThe code doing this is in the github sample.\nThere are few interesting points here.\nImGui usability In order to use ImGui to modify a struct, I had to create the class FlatBuffersReflectionTable to instantiate a struct with a similar layout than the Flatbuffers struct.\nThis is annoying but I could not find a way around different than this.\nWith this in-place, a ImGUI slider can point to a memory area that can be used to save/load the data. Let’s begin by retrieving the TypeTable:\nconst TypeTable* rt_table = rendering::RenderTargetTypeTable();  The TypeTable is what is included in the generated header and contains the reflection informations. Listing the members and their type is pretty straight-forward:\nfor ( uint32_t i = 0; i \u0026lt; type_table.num_elems; ++i ) { const flatbuffers::TypeCode\u0026amp; type_code = type_table.type_codes[i]; ImGui::Text( \u0026quot;%s: %s\u0026quot;, type_table.names[i], flatbuffers::ElementaryTypeNames()[type_code.base_type] ); sprintf_s( s_string_buffer, 128, \u0026quot;%s\u0026quot;, type_table.names[i] ); if ( type_code.sequence_ref == 0 ) { if ( type_table.type_refs[type_code.sequence_ref] ) { const flatbuffers::TypeTable* enum_type = type_table.type_refs[type_code.sequence_ref](); ImGui::Combo( s_string_buffer, (int32_t*)reflection_table.GetData( i ), enum_type-\u0026gt;names, enum_type-\u0026gt;num_elems ); } } else { switch ( type_code.base_type ) { case flatbuffers::ET_BOOL: { ImGui::Checkbox( s_string_buffer, (bool*)reflection_table.GetData( i ) ); break; } } } }  The interesting parts:\nflatbuffers::TypeCode* contains the reflection information for a type.\nGiven a type_code, sequence_ref can be used to check if it is an enum, pointer, or primitive type. In this case is used for enum, showing a combo with all the selectable values.\nBase_type contains instead the primitive type. In this example a bool can be mapped to a checkbox. This uses the custom reflection_table class to have a memory area for ImGUI.\nFor mini-reflection this is basically it.\nFull-reflection Code here is longer but it follows the 4 steps highlighted before.\nAll the code is inside the ReflectUIFull method.\nHere the binary fbs file and its corresponding schema are loaded.\n// 1. Obtain the schema from the binary fbs generated std::string bfbsfile; flatbuffers::LoadFile(\u0026quot;..\\\\data\\\\RenderDefinitions.bfbs\u0026quot;, true, \u0026amp;bfbsfile ); const reflection::Schema\u0026amp; schema = *reflection::GetSchema( bfbsfile.c_str() );  The schema can be used to list the types:\n// 2. List all the types present in the fbs. auto types = schema.objects(); for ( size_t i = 0; i \u0026lt; types-\u0026gt;Length(); i++ ) { const reflection::Object* type = types-\u0026gt;Get( i ); ImGui::Text( \u0026quot; %s\u0026quot;, type-\u0026gt;name()-\u0026gt;c_str() ); }  (Using the auto here because I am lazy. The type is some multiple templates of offsets…) We can also list all the enums:\nauto enums = schema.enums(); for ( size_t i = 0; i \u0026lt; enums-\u0026gt;Length(); i++ ) { const reflection::Enum* enum_ = enums-\u0026gt;Get( i ); ImGui::Text( \u0026quot; %s\u0026quot;, enum_-\u0026gt;name()-\u0026gt;c_str() ); }  A problem I found (with a workaround in the code) is that enums do not have an easily to access array of string values.\nSo I generated one for the sake of example, but I am far from happy with the solution!\nGoing forward, we can get the type we want to reflect (notice the full namespace.type):\nauto render_target_type = types-\u0026gt;LookupByKey( \u0026quot;rendering.RenderTarget\u0026quot; ); and begin the work on each field: auto fields = render_target_type-\u0026gt;fields(); if ( fields ) { // 5.1. List all the fields for ( size_t i = 0; i \u0026lt; fields-\u0026gt;Length(); i++ ) { auto field = fields-\u0026gt;Get( i ); ...  and the UI can be generated.\nFor each field, the primitive type can be accessed with the following:\nreflection::BaseType field_base_type = field-\u0026gt;type()-\u0026gt;base_type();  and again, I found a workaround to know if a type is primitive or an enum.\nLast piece of the puzzle: attributes!\nauto field_attributes = field-\u0026gt;attributes(); if ( field_attributes ) { auto ui = field_attributes-\u0026gt;LookupByKey( \u0026quot;ui\u0026quot; ); if ( ui ) { ImGui::Text(\u0026quot;UI attribute: %s\u0026quot;, ui-\u0026gt;value()-\u0026gt;c_str()); } }  These can be parsed as strings and can be used to drive UI code (like a slider with min, max and steps).\nConclusions In the end, I’ve managed to generate UI based on a type without too much code.\nThere was some reverse-engineering to do because I could not find proper documentation (I possibly miss some links to a in-depth example of reflection!) but nothing major.\nThe full source code:\n(https://github.com/JorenJoestar/FlatbuffersReflection)\n","date":1564141046,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564141046,"objectID":"afba9f8775578a3383382dfbe5a617c4","permalink":"/post/flatbuffers_reflection_data_driven_rendering/","publishdate":"2019-07-26T07:37:26-04:00","relpermalink":"/post/flatbuffers_reflection_data_driven_rendering/","section":"post","summary":"Auto generated UI from Flatbuffers files.   Motivation Finding a good balance between code and data in Rendering.\nWhat is the necessary code that should be written ?\nWhy ?\nIn rendering many areas can be described in a fast and robust way using data.\nA pipeline (in D3D12/Vulkan lingo) for example is a collection of different states: depth stencil, alpha blend, rasterizer, shaders, etc.\nAll those state can be hard-coded or defined in data.","tags":[],"title":"Flatbuffers, Reflection and Data-Driven Rendering","type":"post"},{"authors":[],"categories":[],"content":"   Legend of Zelda emulated plus debugging windows.   Hello everyone!\nToday I release the source code of my bare-bone NES emulator, written in C++.\nI had the idea to write an emulator of one of my favorite console (after the SNES) years ago, and started in 2015 to write the first code (actually in 2008, but it was too daunting even to start). Then I concentrated on my other big project (still ongoing) and left all the NES code on a side. Years passed and finally last winter I decided to give it a go to arrive at a ‘usable’ emulator level and release the source code.\nHere it is! (https://github.com/JorenJoestar/HydraNes)\nMotivation Main motivation both to write and to share this code is knowledge.\nI shamelessly wrote bad code just with the purpose of seeing something on screen as fast as I could. And I am very honest about that: not happy for the form, but happy for the knowledge I gained! Also, I think that this code is compact enough to be followed and to understand the basics of NES emulation coding.\nThe code The NES code lives in the Nes.h/.cpp pair of files. The APU is implemented using Blargg’s implementation: when I’ll have other time I will attemp to finish my own implementation, but for now it is ok like that.\nThe flow is the following:\n NES is initialized After loading a rom (from the Cartridge window) the mapper will be selected and memory copied to local buffers. CPU starts its continuous emulation. CPU will execute until a frame is produced. This is checked by the PPU frame changing. PPU execution is bound to memory accesses, both read and write. Each CPU memory access corresponds to 3 PPU cycles (in NTSC, the only region emulated). After the frame is ended the APU emulation is advanced.  Interesting spots There are different areas of the code that are interesting, but I would like to highlight some.\nCpu::Step() This is where all the CPU instructions are executed. I opted for a macro based approach instead of tables of function pointers.\nFor each cpu cycle:\n Fetch the instruction opcode Calculate the operand address (called ‘effectiveAddress’) Execute the operation  All the operations and addressing modes are in the Nes.h file. Addressing modes are the way the NES gets its operand for each operation. Operations are the instruction themselves — using those operands.\nPpu::Step() PPU by itself is the most difficult part to emulate (APU is easier on the channels, but harder on the mix and signal generation!).\nI will make a post about that soon, but in the meantime here the code is and implements the behaviours described here:\nhttps://wiki.nesdev.com/w/index.php/File:Ntsc_timing.png\nThe PPU draws in tiles of 8x8 pixels, so for each pixels created on the screen there will be a gathering of all the data necessary to calculate the final color.\nThe rendering is divided in background and sprites.\nBackground is just 8x8 pixel per tile choosen from the nametable (a screen table of which tiles are visible) and sprites are either 8x8 or 8x16 rectangles coming from a different memory area (uploaded using DMA).\nThere are many quirks and uniqueness about the PPU, like the pattern table (a 16x16 grid storing the higher 2 bits of all the underlying background pixels), or the vertical blank period, or the open bus.\nPpu::DrawPixel() The color of a pixel comes from one of the 16 entries of the palette VRAM, and to do so 4 bits must be calculated for background and for sprites.\nFor background tiles, 2 pixels comes from the ‘texture’ (CHR-ROM) and 2 from the attribute table. Sprites contains all those informations together.\nThe output is a silly SSBO that contains RGBA colors to be used in a compute shader that outputs to the screen.\nCpuRead/Write, PpuRead/Write All those methods are essential because the NES uses memory mapping i/o to access the different hardware.\nFor example the PPU access the cartridge through the mapper in the memory controller to read drawing informations, the CPU writes to the PPU using address $2007, etc.\nEnding notes I will prepare more detailed posts about the NES architecture and emulation, even though there are still some concepts that are not clear to me and require a deeper investigation.\nSo far this is the most satisfactory personal project I’ve done, and one of the few that arrived at a usable level.\nIn the future I want to improve this emulator and use the knowledge to explore the writing of a SNES emulator!\nAny question or comment please let me know!\nGabriel\n","date":1563861890,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1563861890,"objectID":"96109d55d54d12572b76d4542ac35062","permalink":"/post/releasing_nes_emulator_source/","publishdate":"2019-07-23T02:04:50-04:00","relpermalink":"/post/releasing_nes_emulator_source/","section":"post","summary":"Legend of Zelda emulated plus debugging windows.   Hello everyone!\nToday I release the source code of my bare-bone NES emulator, written in C++.\nI had the idea to write an emulator of one of my favorite console (after the SNES) years ago, and started in 2015 to write the first code (actually in 2008, but it was too daunting even to start). Then I concentrated on my other big project (still ongoing) and left all the NES code on a side.","tags":[],"title":"Releasing NES Emulator Source","type":"post"}]